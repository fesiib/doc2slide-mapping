• Empirical studies in HCI; Empirical studies in collaborative and social computing;
online communities, career advice, online mentoring interactions, working adults, Q&A, employment
Maria Tomprou, Laura Dabbish, Robert E. Kraut, Fannie Liu. 2019. Career Mentoring in Online Communities: Seeking and Receiving Advice from an Online Community. In CHI Conference on Human Factors in Computing Systems Proceedings (CHI 2019), May 4–9, 2019, Glasgow, Scotland UK. ACM, New York, NY, USA, 12 pages. https: //doi.org/10.1145/3290605.3300883
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4–9, 2019, Glasgow, Scotland UK © 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300883
Managing career development is a major challenge for the working population [10]. Careers have become boundaryless [37], evolving across many different fields [21]. Career mentoring, traditionally conducted in-person, is now widely accessible online to help people navigate these changes. Career mentoring is the relationship between a protégé and a mentor i.e., someone more experienced within or outside an organization who supports the personal and professional growth of the protégé [14]. Seeking and sustaining career mentoring through in-person interactions contributes to learning and career growth [36]. Resources that support "offline mentorship" range from traditional mentoring to mentoring between peers at work [35], to career-focused social networks (i.e., distributed mentoring from different social sources such as peers, friends, and family [27]), to career professionals such as executive coaches [17] and formal mentoring programs.
Despite the benefits of career mentoring [36], many working adults lack access to in-person mentors. For instance, underrepresented groups within a profession have limited career-focused or developmental social networks [29]. Moreover, most of theworking population cannot afford expensive career professionals [5, 22]. Offline career mentoring relationships can also be dysfunctional. People may experience sabotage, envy, harassment or bullying from mentors, which can hamper career success [13, 49, 51]. Online career mentoring offers a unique opportunity to remove some of the burdens and costs of traditional mentoring. In particular, online Q&A forums support a rich variety of knowledge exchange [24, 39, 56], but prior work has not yet examined whether and how these forums support career advice seeking or mentoring functions. For instance, interactions in these forums may be useful for exchanging information, but they tend to be ad hoc, i.e., they lack a previous history of interaction. Thus, they may fail to support the relational aspect of offline mentoring. Nonetheless, understanding these ad hoc dynamics are especially important as new digitally enabled forms of mentoring emerge (e.g., virtual coaches, online communities, and distributed mentoring) [23, 54] that people may rely on for career advice and support.
Paper 653 Page 1
In this paper, we use archival data from an online Q&A forum focused on career support to extend the literature on online career mentorship. We examine the ad hoc dynamics of seeking and receiving career advice. We leverage online community interactions to identify the types of career challenges people face today. We also compare the functions of offline and online mentoring (social support, informational, and role modeling; [11, 35]) and provide implications for what people value as career advice. We differentiate those who seek career advice online into two types: 1) the original requesters who experience a challenge and seek advice through a post, and 2) the third party (external) viewers who may face similar experiences or are interested in learning, i.e., anyone who will search for similar questions online. Our study focuses on three research questions:
• RQ1: What kind of career advice requests do people make in an online community? • RQ2: Do different career advice requests elicit different kind of responses? • RQ3:What kinds of responses to career advice requests are most valued?
We contribute to the CSCW literature in three ways. First, we provide a taxonomy of online career advice that designers may leverage to help users to navigate their questions (if requesters) or to share their expertise (if mentors/contributors). Second, we develop a new scale that allows future research to further examine the effects and functions of online career advice mentoring. Finally, we empirically demonstrate the nature of online career mentoring and the advice that is valued in such contexts.
A number of researchers in HCI have studied different areas of career development and careers in general. One direction of work examines the role of technological interventions in disadvantaged and low resourced workforce [25, 57]. For example, Dillahunt et al. explored how job seekers from low socioeconomic status leverage technology to find jobs [12]. Another direction investigates career skills development, identifying how digital technologies promote learning and communication through online communities [16, 34] and recommendation systems, e.g., Crowd Coach, which facilitates peer coaching while people work [9]. Similarly, research on e-mentoring (mentoring via electronic communications for education purposes [53]) considers interactions organized around professional activities [6, 7]. For example, MentorNet is a structured e-mentoring program that pairs female college students with professionals in engineering and science [32]. Our research contributes to this field by examining the type and value of career advice people seek and receive online.
Career mentoring can come from not only a dedicated mentor, but also professional coaches, peers, friends, and family. Mentoring sources can be formal through assigned or professional mentors or mentoring programs, which is known to have limited impact, or informal through relationships and interactions external to an organization [8]. Mentoring sources can be viewed as a developmental network, i.e., a group of people with an active interest in and action toward advancing one’s career. Career progress is associated with having a series of mentoring relationships or a configuration of mentors over the course of one’s career [27]. E-mentoring is a mentoring source less related to organizational context that can increase mentorship access and provide similar support as offline mentoring [43, 52]. Studies within health and education online communities suggest that e-mentoring can contribute to users’ well-being, learning, and skill acquisition through the feedback and support received [7, 56]. Similar to e-mentoring, career mentoring in online communities may promote users’ careers through support from users with similar experiences, experts, or the crowd in general. However, both offline mentoring and e-mentoring tend to be dyadic and part of ongoing relationships developed within private channels, while career mentoring in online communities enables people to post publicly to a large audience of potential mentors. In our research, we focus on a widely-used source of online career mentoring: Q&A forums.
Online Q&A Forums as a Source of Career Mentoring. Q&A forums are online communities for sharing expertise, where individuals can pose questions and receivemultiple responses from a broad set of individuals [2]. In Q&A forums, the advice seeker may have little previous mentorship interactions. Prior work has examined the content and dynamics of these systems, such as on Yahoo Answers [2], Quora [47, 55], and StackOverflow [39], but has yet to explore the nature of the career mentoring interactions in such environments. Q&A forum interactions differ in nature and structure from offline mentorship. In Q&A forums, questions are public to a relatively unknown and often anonymous audience of many potential respondents [24]. Questions on Q&A forums such as StackOverflow can also receive responses very quickly, often within 12 minutes [39]. These forums rely on a combination of intrinsic and extrinsic motivation to participate, including through visible reputation markers and connections to one’s interests and identities [28]. Responses to questions can benefit the person who originally asked the question as well as the third-party observers. Posted questions can be conversational, discursive, or informational [24]. Question types include: factual (seeking objective data), advice (seeking recommendations), opinion (seeking others’ viewpoints), and non-questions (spam) [28, 39, 44]. While
Paper 653 Page 2
research demonstrates that these question patterns persist in Q&A around career advice, it is unclear what kind of challenges people experience in posting these questions online.
Mentors primarily provide three types of career support: socio-emotional, instrumental, and informational support [35, 51]. Socio-emotional support focuses on personal growth, such as boosting a protégé’s self-confidence. Instrumental support involves helping protégés improve career visibility and offering sponsorship. Informational support involves providing relevant information on specific issues. Some research has reported role modeling as a fourth function of mentoring [11, 40], which refers to individuals’ identification with a senior or an expert acting as the role model.
Although prior work has identified sources and functions of mentoring, little is known about the core issues that people seek help for in their careers [19, 33]. Research has relied on self-reports of career challenges and student samples, which can be affected by memory bias, concerns about anonymity and confidentiality, and limited generalizability to working populations across career stages and contexts. Observing an online community provides a unique opportunity to systematically analyze and identify patterns in a broad range of career advice requests, which typically cannot be accessed in offline career mentoring and closed online groups.
Given the lack of ongoing interpersonal relationships and offline contact, online mentoring may take different forms to help individuals manage career challenges. For example, people may receive confirmation and acceptance, a form of socio-emotional support, from strangers who cannot directly affect their current employment conditions [31]. People may also seek informational support through coaching online, in order to overcome challenges while managing exposure and protecting their careers. At the same time, given the population of strangers, some support may be limited, such as instrumental support through sponsorship. Although people seek career advice in online Q&A forums, it is unclear whether and how interactions in these forums will support key functions of mentorship observed in offline and online dyadic mentoring [35, 43, 51]. The present work aims to better understand how people use online Q&A forums to elicit key functions of mentoring.
What is valued in career advice? People appear to value and appreciate mentoring relationship in its own right, beyond its positive relationship with career outcomes [36]. For example, meta-analyses have showed that both career-focused (e.g., instrumental and informational mentoring) and socio-emotional mentoring relate to satisfaction with mentors [3]. Focusing at the fine-grained level of ad hoc dynamics of career mentoring interactions,
we seek to further understand forms of career advice and what is valued as advice. Valuable advice refers to career advice with an acknowledged value by a person in need or through external viewers (e.g., voting it as an accepted response to a request). We argue that career advice in an online forum may have different implications for people requesting advice and third parties who later view the exchanges. For example, the original requester may appreciate and be more likely to upvote a response that offers advice tailored to a personal situation. Third parties later reading may find general best practices and relevant knowledge more valuable than context-specific advice. Requesters may also appreciate socio-emotional aspects of the advice, such as encouraging language and affirmation similar to traditional mentoring [27, 35]. In contrast, such efforts are less likely to be appreciated by external viewers.
We carried out preliminary qualitative observation and analysis of theWorkplace subforum in StackExchange, conducting five interviews with top contributors to gain insights about people’s motivations to seek career advice and contribute to career mentoring in the forum. Next, we conducted two studies to address our research questions. In Study 1, we qualitatively analyzed posts on Workplace to understand the types of career advice requests people make in an online Q&A forum (RQ1) and develop a taxonomy of career advice requests. In Study 2, we quantitatively examined whether there are substantial differences in responses elicited across the taxonomy of career requests (RQ2) and how characteristics of responses contributed to the value of the response (RQ3). Using regression, we tested the relationships between request type (based on the taxonomy from Study 1), response features, and value of the response as assessed by the original requester and a set of third party viewers (MTurk workers).
Research Site. Our research focused on the Workplace, a Q&A subforum in the StackExchange network self-described as "Q&A for members of the workforce navigating the professional setting" [1]. Workplace acts as a career resource for its members, who are mainly software developers [4]. StackExchange allows users to post questions visible to anyone, comment on others posts, and upvote/downvote questions and answers [48]. Authors of questions can then choose one answer as a "qualifying" response to their question. In 2015, 16k questions and 52k answers were posted on Workplace, with no unanswered questions [1]. To understand the context of our research site, we interviewed five participants on Workplace: onemoderator and four top contributors from the IT/IS profession. Interviews focused on motivations behind seeking advice and contributing responses on Workplace.
Paper 653 Page 3
These interviews helped us understand the nature of career mentoring in this forum and gain insights on participation.
Potential Benefits of Online Career Mentoring. Based on our interviews, we identified a series of benefits in seeking career advice in an online community rather than through offline sources: validation of offline mentoring, diversity, access, and safety. We also identified two key motives to contribute as mentors in Workplace: reciprocity to the community and personal skill improvement. A summary of our findings is presented in Table 1.
Our interviews identified motivations behind posting and participation dynamics on theWorkplace sub-forum of StackExchange. This background offered insights for understanding career advice interactions online, and provided the foundation for the following studies on request types (Study 1) and response patterns and value (Study 2).
In Study 1, we aimed to address RQ1: What kind of career advice requests do people make in an online community? To do this, we qualitative analyzed requests and responses on Workplace. We used a bottom-up process to identify themes and common topics and develop a proposed taxonomy.
Data collection: Requests and Responses. StackExchange releases "data dumps" of all of its publicly available content roughly every three months via archive.org, and offers that information through the Stack Exchange Data Explorer (SEDE). A data dump is an anonymized dump of all usercontributed content on the Stack Exchange network. Each site is formatted as a separate archive consisting of XML files zipped via 7-zip using bzip2 compression. Each site archive includes Posts, Users, Votes, Comments, PostHistory and PostLinks. The Workplace StackExchange site is 52.4mb of compressed text files. From the StackExchange data dumps, we collected a random sample of 847 thread-starting posts (April 2012-August 2016) along with follow-up responses and post and response metrics. In terms of anonymity, 534 unique users of these posts were anonymous (89.9%), 20 users revealed their name in the url but have a nickname on StackExchange (3.4%), and 40 have both their names and reveal their names on url (6.7%). The average number of responses for the posts in our dataset was 3.14. 304 original posts had an accepted response, 182 out of which had at least one more (rejected) response.
Regarding the social interactions in the Workplace posts in our dataset, 186 out of 847 posts (27%) had no followup of any kind from the original poster after the initial request, whereas 58.5% had some follow-up from the original poster requesting advice, such as through within-post comments and answers. The follow-ups consisted of the following types of behavior: acknowledgments of the responses such as thanks and gratitude expressions (29% of posts), clarifications of the original post/question (21% of posts), asking additional questions (8.5% of posts), and "other or irrelevant" posts (14.5% of posts). Consistent with previous findings [48], these indicate that users view the online community as a mentoring platform, with a "mentoring value" ranging from a simple "thank you" to asking more questions.
A taxonomy is a formal system for classifying multiple areas of inquiry according to a set of common conceptual domains and dimensions [46]. Our qualitative coding process included development, validation, and application of a code structure.
TaxonomyDevelopment. Weused 597 of the 847 anonymized public posts from Workplace forum. We limited our analysis to posts with tags such as as "career development" and "careers" from 515 unique users. We excluded 127 student posts. Following previous guidelines [30, 42], a single researcher (first author) conducted all of the coding. She coded posts using an inductive process where major themes emerge through interpretation of the data [46]. This process allows the researcher to continually create and refine categories to develop a complete or saturated categorization of the data [20]. The process was to (1) review the collected data and identify preliminary themes and categories, (2) revise these categories based on their relevance to subsequent new data as collected, and (3) create typologies for main themes and categories. First-order coding categorized the naturally occurring themes in the data. We used NVivo to calculate the frequency of the codes (i.e., the number of times a code was mentioned within and across the posts, [38]). The process resulted in 470 unique posts by 424 unique users coded into three key-types and 21 sub-themes.
Taxonomy Validation. We applied the developed codes to a new set of 250 posts with the same features as the original ones. The posts were drawn in a 19-months time period, from January 2016 to August 2017. Two independent coders were cross-trained using 50 posts and then independently coded the remaining ones (200 posts from 182 unique users). Regular meetings occurred to resolve disagreement in code applications and refine the initial set of codes. Cohen’s Kappa ranged from 0.75 to 0.90.
Paper 653 Page 4
We identified three types of career-advice seeking: 1) best practices, 2) threats to career progress, and 3) time sensitive decision-making (see Table 2).
Best Practices. The first major category of requests focused on seeking advice for best practices. Best practice requests sought general solutions or approaches to career relevant problems that were superior to other alternatives or the standard approach used in the industry. This category includes seven sub-themes, such as managing interviews, time, and resumes, among others (see Table 2). For example, users sought advice on how to improve their resume as a best practice:
"I have 25 years of experience with different companies, working in high-tech software industry. I have many links, skills, and education that made my resume more than 4 pages long. How can I reduce its length without short changing my skills and accomplishments?" (Post and User’s ID are removed; text is paraphrased)
Threats to Career Progress. The second major theme was seeking advice for problems that could hamper one’s career progress. Career progress outcomes include likelihood of promotion, status within the organization, or marketability and employability beyond their current position. This theme was characterized by requests for advice on how to manage challenging situations that individuals encountered and were concerned could negatively impact their performance, likelihood of promotion, or reputation in the organization or beyond. These situations were long term or chronic.
Seven sub-themes fell under this category: managing relationships, motivation, failures, health, organizational inclusion, resignation, and proving oneself. Here is an example post in this category from a user asking for advice on how to manage a demotion as a potential threat to their career:
"I’ve been working as a software director for 3 years with a team of talented developers building a complicated piece of code. We now have about 10,000 lines of operational code... Recently, the company got a few
Paper 653 Page 5
Time-Sensitive Decision Making. The last type of requests we identified were those seeking solutions to or input on a time-sensitive decision. These posts were characterized by a detailed description of a specific situation the poster was experiencing, a request for help in making a decision within that situation, and the time demand associated with the decision. This category includes four sub-themes: negotiations, ethics, and avoidance. For example, one user posted about managing time-sensitive job offers:
In Study 1, we aimed to understand how working adults use an online Q&A career forum to seek career advice. We introduced a taxonomy of career-advice requests that working adults seek online. The taxonomy we developed highlights the breadth of career support users seek in online communities. People seek advice for best practices, such as improving a resume or managing job interviews, which is common in offline formal career coaching [43]. They also seek guidance
Paper 653 Page 6
and strategies to address potential threats to their career progress and to help them make time-sensitive decisions. Next, we consider how these request types relate to the nature and value of responses they receive.
Study 2 addressed our second and third research questions– whether career advice request types (best practices, threats, and time-sensitive decisions) elicit different types of responses (RQ2) and what functions of responses are valued by the original requester and third parties (RQ3).
Sample. We randomly selected 36 original posts from our dataset of 470 posts (see Study 1) that had at least one accepted response and at least one rejected response, and created 72 unique pairs (original post-accepted response; original post-rejected response). Accepted responses had a positive follow-up comment in the same thread (e.g., a "thank you"). We randomly selected rejected responses when these were more than one.
Measuring Request Types. Authors used 6-point Likerttype scales to independently rate the extent to which each of the 36 requests fell into the three main request categories: (1) was about best practices, (2) reported a threat to the requester’s career, and (3) was time-sensitive. Because interrater reliability was high (ICC = .86), we averaged the three scores for each request on each of the three metrics.
Measuring Functions of Career Advice Responses. We employed Amazon Mechanical Turk (MTurk) workers to evaluate the functions and quality of the 72 responses. To ensure quality of MTurk responses, we employed only MTurk workers with 5,000 Human Intelligence Tasks (HIT, i.e., the tasks MTurk workers complete on Amazon platform) with a 98% or higher approval quality and paid them $3 for a 15-minute task. We duplicated certain items, included a screening question, and requested workers to justify their response ratings. We applied previous literature on mentoring functions to develop a coding scheme to measure features of responses in this sample [11, 35]. We used the conceptual definitions of mentoring functions described previously (i.e., informational support, instrumental support, socio-emotional support, and role modeling) to identify specific instances of these functions in the responses in our corpus.
Second, based on examples from the corpus, we generated 13 survey items that described how the mentoring functions were enacted in the online mentorship site (Table 3). Since we saw no instances of instrumental support in the corpus, we did not create survey items for this construct. We saw two
forms of informational support: general and specific information (or guidance). General information refers to the extent to which responses provide information that can apply to many situations and individuals, rather than being tailored to the original request. This type of elicited response is similar to informational support both in online and offline career mentoring. Guidance is another type of informational support that refers to problem solving strategies and tactics tailored to the original request. Socio-emotional support was shown in responses that encouraged the user to engage in some sort of activity to help the requester feel better. Encouragement was also used to provide non-emotional support, such as for promotion focus (i.e., turning one’s attention toward goal pursuit [26]). We also identified aspects of role modeling, where advice-givers shared their own personal experiences and the extent to which those experiences were positive.
Third, to validate the dimensions of support that we identified and to create scales, we conducted a principal component analysis (PCA) with direct oblimin rotation method to assess the extent to which the items were measuring the same underlying construct. For each of the 72 responses, six MTurk workers evaluated the extent to which the 13 survey items described the response on a 6-point Likert scale. We dropped two survey items that did not load highly (<.40) on any factor. The top four factors from the PCA analysis explained 68% of the variance in the ratings and revealed four online mentorship functions, with general information and guidance loading into two different factors (general information, guidance, encouragement, and role modeling). We then constructed multi-item scales for each of the mentoring functions by averaging the MTurkers’ judgments for a survey item, and then averaging the survey items designed to measure a specific mentoring function (Table 3). Intra-class correlations (ICCs) with one-way random effects ranged from .81 to .84, indicating that most of the variance in MTurker judgments could be attributed to the post being evaluated. Alphas for each sub-scale ranged from .78 to .84, indicating good consistency among items measuring the same construct.
Requesters’ Judgement of the Value of Responses. We measured the response value to the requester with a binary variable. We coded 1 if the requester (a) voted the response as “accepted” and (b) followed up with within thread comments. Rejected responses were coded as 0.
Third-Parties’ Judgement of the Value of Responses. The value of a response to third party viewers was assessed using MTurkers’ ratings. We used two items toward that purpose: “To what extent do you believe the Answer is helpful?”, and “How much effort do you think the writer of the Answer put in to the response?” MTurkers rated their agreement with these items on a 6-point Likert-type scale. These items had
Paper 653 Page 7
high internal consistency (ICC = .88, Cronbach’s alpha = .86). Thus we averaged them to create a value score as assessed by third parties. This value indicator was moderately correlated with acceptance by the original requester (r = .57, p = .001).
Descriptive statistics and zero-order correlations among request type, response functions, and value outcomes are presented in Appendix A. To examine the relationships among request types, response functions and the value of responses, Study 2 contains two sets of analyses. The first testedwhether response functions varied across request types (RQ2). The second tested how the response value varied as a function of the original request type and response functions (RQ3). We present these analyses in turn below.
Request Type and Response Features. We conducted linear regression with response nested within request, wherein standard errors are adjusted because observations are nonindependent. Here non-independence occurs because we analyzed cases where we randomly selected one rejected and one accepted response. None of the request types elicited different functions of responses.
Response Functions and the Value of the Response. We used logistic regression with response nested within request, to examine whether functions of a response predicted the likelihood of the original requester accepting the response. Responses containing more guidance were more likely to be accepted (β = 4.13, t = 2.82, p = .005), while other request features were not significantly related to acceptance (see Table 3). In a follow-up analysis not reported in Table 3, we included interactions between request type and response functions, but found no significant interactions (p = ns). This suggests that guidance is valued by the original requester across request types. Next, we used linear regression with response nested within request to assess how fuctions of responses were associated with the value of a post as rated by MTurkers. Functions of responses explained 65% of the variance in MTurks’ judgments of response value. Responses with more general information (β = .41, t = 3.74,p = .001), encouragement (β = .23, t = 2.54,p = .011) and guidance (β = .73, t = 7.21,p = .001) were rated as more valuable. In contrast, responses with more role modeling were judged less valuable, although the effect was only marginally significant (β = −.10, t = −1.87,p = .06). When we probed for interactions between request type and response function on external perceived value of the response, we found no significant results (p = ns). Again, response functions appear to play similar roles across the different types of requests.
Table 3 shows that responses with general information, encouragement, and guidance were valued by both the original requester and outside viewers, though some of the effects were marginally significant for requesters’ judgments. The correspondence between the types of value judges is to be expected, because their judgments are moderately correlated. The associations were weaker for the requesters’ value judgments because regression analyses lose power with binary outcomes [50]. Since the requesters’ judgments rely on a single judge, they are less reliable than the MTurkers’ judgments, which were based on the average of six judges. Appendix B contrasts examples for high-low response scores.
Study 2 examined whether different types of advice requests, as defined by the career advice taxonomy from Study 1, elicit different functions of responses, and whether response functions predicted the value of the response. We did so by developing a new scale that allows us to assess online career mentoring functions. Analyses revealed four types of online career advice (general information provision, role modeling, guidance, and encouragement) that were similar to but not identical with functions ofmentoring in offline environments. For example, online encouragement contains only one element of the socio-emotional support seen offline. Similarly, offline role modeling often occurs by observing what a mentor does, but our results show that online role modeling relies on explicit statements made by the mentor. Surprisingly, we found no relationships between the taxonomy of online career advice questions and the functions of responses they elicited. One might have expected that best practice requests will elicit general information responses and threat requests will elicit encouragement, but our data did not reveal such relationships. Additionally, while onemight have expected that the requesters and observers would value different types of responses (e.g., requesters seek personalized guidance, while external observers might want general information), results show that the same functions of responses predicted both requesters’ and observers’ perceptions of value.
Overall, our research contributes to emerging work in HCI that examines the interplay of career management and technology, such as job search [25, 45],skill development [16], and e-mentoring [6]. There are three main contributions of our research. First, we offer a taxonomy of career advice requests, delineating three core types of career advice requests observed in a Q&A forum: advice about best practices, threats to one’s career, and time-sensitive decisions. We identify specific topics within each type. This taxonomy serves as a starting point for a more detailed understanding of career
Paper 653 Page 8
challenges people face, and identifies areas of opportunity for technology support. Researchers and designers can utilize this taxonomy to build systems and interventions to facilitate career development and online career mentoring. Second, we identify how basic mentoring functions are enacted in Q&A forums. Although career advice requests resemble traditional mentoring functions to some extent, there are also considerable differences. For example, in traditional mentoring, researchers have observed instrumental (tangible) support[11, 27, 35], but we did not observe such behavior in the online environment. We also found other, more nuanced differences in how socio-emotional and informational support were offered in this setting. Mentors offered guidance
through providing requester-specific recommendations for action or step-by-step instruction in the online environment, which is different from how informational support is provided in traditional mentorship. Similarly, encouragement appears to be the major means to provide socio-emotional support in a Q&A forum. Appendix C shows how functions of offline mentoring are enacted in online mentoring. Third, our paper provides evidence for how advice seekers and third parties evaluate the effectiveness of a piece of career advice. Previous literature shows evidence in the relationship between career mentoring and career success [3].
Paper 653 Page 9
Within this context, we assessed the value of the career advice at a more fine-grained level, from two sources: the original requester and objective third parties. Surprisingly, the original requesters and outside observers valued similar responses and similar content in responses. For example, both original requesters and MTurkers valued responses tailored to the original requester’s situation and responses that provided guidance, even though one might have expected that tailoring would be most appreciated by the requester. Similarly, both requesters and outside observers valued responses that provided general information and encouragement, even though one might have expected that outsiders would most value general information and not encouragement.
Career mentoring in online communities is a distinct type of mentoring that can supplement and substitute for offline mentoring. Although offline mentors often offer support without receiving explicit requests, in an online environment, a person in need of mentorship initiates a request for support from the community. We examined how career mentoring exists in Q&A forums where career advice requests and responses comprise ad hoc mentoring interactions.
Our results suggest design opportunities to better support online career mentorship around critical events, ongoing relationships, response structuring, and response reuse.
One potential direction for future research and development is the development of event-specific decision support tools and systems. Our results suggest that career mentoring is sought for critical events and decisions such as promotions, job interviews, offers and negotiations, layoffs, and conflicts. Aside from interactive resume builders, there are tools that provide event-specific support for navigating important career decisions. Future research may investigate the potential for automated systems to scaffold critical career decisions. New communication platforms could also support real-time "on-demand advising," i.e., interactions between previously unacquainted mentees and advisors to exchange just-in-time information.
Improving the quality of online career advice Responses accepted by requesters differed qualitatively from those that they did not accept. Similarly, responses that third party viewers valued differed from those they valued less. Static and interactive feedback could help people improve their responses to requests for advice to achieve responses that requesters and members of the community really value.
Guidance on how to advise. New contributors can benefit from site-specific advice to improve their responses. This advice could be as simple a static document describing the type
of responses that requesters find most valuable. An alternative might be just-in-time mentoring in which responders receive feedback from othermembers of the community. This approach has already shown promise: past work has shown that redirecting people writing questions in StackOverflow to an on-site help room staffed by experienced members of the community can increase the quality of their questions by 50% [18]. The Wikipedia Teahouse is a analogous program to help new editors of Wikipedia articles [41].
Intelligent response critic. Considering the different effects of what is valued in responses, future research can also explore the effectiveness of an natural language processing (NLP)-driven critic for increasing the quality of responses. An intelligent response critic could apply NLP to analyze the content of a response as it is being constructed, and provide guidance to the author. For example, the critic could inform the responder that their response did not use action-oriented language, and suggest words or phrases to encourage the requester to act on the problem.
Q&A sites currently have few affordances to maintain users and help them build relationships. Advice in the Q&A environment we studied was transactional, because advice requesters and mentors did not have repeated interactions around career development. In contrast, extended relationships are core to offline mentoring. In other online communities, such as health support forums, people build relationships by exchanging advice over an extended period of time [56]. Online mentoring sites may consider shifting their model from Q&A forums to platforms that aim to build enduring online relationships similar to those found in online health support communities and other communities with sustained interactions.
We examined how people use online Q&A forums for career advice. In these communities, anonymity of participation and access to multiple expert opinions and just-in time responses offer a unique space where people can disclose and discuss issues that would otherwise harm their career prospects. We should look for opportunities to integrate heterogeneity of response, and openness to enhance career advice seeking in online communities and inside organizations as well.
We would like to thank Irene A. Chounta for her help on early drafts of the paper.
[1] 2018. Stack Exchange. Retrieved from https://stackexchange.com/
about.
Paper 653 Page 10
[2] Lada A Adamic, Jun Zhang, Eytan Bakshy, and Mark S Ackerman. 2008. Knowledge sharing and yahoo answers: everyone knows something. In Proceedings of the 17th international conference on World Wide Web. ACM, 665–674. [3] Tammy D Allen, Lillian T Eby, Mark L Poteet, Elizabeth Lentz, and Lizzette Lima. 2004. Career benefits associated with mentoring for protégés: A meta-analysis. Journal of applied psychology 89, 1 (2004), 127. [4] Andrew Begel, Jan Bosch, and Margaret-Anne Storey. 2013. Social networking meets software development: Perspectives from github, msdn, stack exchange, and topcoder. IEEE Software 30, 1 (2013), 52–66. [5] Steven Berglas. 2002. The very real dangers of executive coaching. Harvard business review 80, 6 (2002), 86–93. [6] Laura L Bierema and Sharan B Merriam. 2002. E-mentoring: Using computer mediated communication to enhance the mentoring process. Innovative Higher Education 26, 3 (2002), 211–227. [7] Julie Campbell, Cecilia Aragon, Katie Davis, Sarah Evans, Abigail Evans, and David Randall. 2016. Thousands of positive reviews: Distributed mentoring in online fan communities. In Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing. ACM, 691–704. [8] Georgia T Chao, Patm Walz, and Philip D Gardner. 1992. Formal and informal mentorships: A comparison on mentoring functions and contrast with nonmentored counterparts. Personnel psychology 45, 3 (1992), 619–636. [9] Chun-Wei Chiang, Anna Kasunic, and Saiph Savage. 2018. Crowd Coach: Peer Coaching for Crowd Workers’ Skill Growth. Proceedings of the ACM on Human-Computer Interaction 2, CSCW (2018), 37. [10] Suzanne C De Janasz, Sherry E Sullivan, and Vicki Whiting. 2003. Mentor networks and career success: Lessons for turbulent times. The Academy of Management Executive 17, 4 (2003), 78–91. [11] Jubilee Dickson, Katie Kirkpatrick-Husk, Dana Kendall, James Longabaugh, Ajal Patel, and Shannon Scielzo. 2014. Untangling protégé self-reports of mentoring functions: Further meta-analytic understanding. Journal of Career Development 41, 4 (2014), 263–281. [12] Tawanna R Dillahunt, Jason Lam, Alex Lu, and Earnest Wheeler. 2018. Designing Future Employment Applications for Underserved Job Seekers: A Speed Dating Study. In Proceedings of the 2018 Designing Interactive Systems Conference. ACM, 33–44. [13] Lillian Eby, Marcus Buits, Angie Lockwood, and Shana A Simon. 2004. Protégés negative mentoring experiences: Construct development and nomological validation. Personnel Psychology 57, 2 (2004), 411–447. [14] Lillian T Eby, Tammy D Allen, Sarah C Evans, Thomas Ng, and David L DuBois. 2008. Does mentoring matter? A multidisciplinary metaanalysis comparing mentored and non-mentored individuals. Journal of vocational behavior 72, 2 (2008), 254–267. [15] Lillian T Eby, Jaime R Durley, Sarah C Evans, and Belle Rose Ragins. 2006. The relationship between short-term mentoring benefits and long-term mentor outcomes. Journal of Vocational Behavior 69, 3 (2006), 424–444. [16] Umer Farooq, Patricia Schank, Alexandra Harris, Judith Fusco, and Mark Schlager. 2007. Sustaining a community computing infrastructure for online teacher professional development: A case study of designing Tapped In. Computer Supported Cooperative Work (CSCW) 16, 4-5 (2007), 397–429. [17] Daniel C Feldman and Melenie J Lankau. 2005. Executive coaching: A review and agenda for future research. Journal of management 31, 6 (2005), 829–848. [18] Denae Ford, Kristina Lustig, Jeremy Banks, and Chris Parnin. 2018. We Don’t Do That Here: How Collaborative Editing with Mentors Improves Engagement in Social Q&A Communities. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems.
ACM, 608. [19] Itamar Gati, Mina Krausz, and Samuel H Osipow. 1996. A taxonomy of
difficulties in career decision making. Journal of counseling psychology 43, 4 (1996), 510. [20] Judith Preissle Goetz and Margaret D LeCompte. 1981. Ethnographic research and the problem of data reduction. Anthropology & Education Quarterly 12, 1 (1981), 51–70. [21] Douglas T Hall. 2004. The protean career: A quarter-century journey. Journal of vocational behavior 65, 1 (2004), 1–13. [22] Douglas T Hall, Karen L Otazo, and George P Hollenbeck. 1999. Behind closed doors: What really happens in executive coaching. Organizational dynamics 27, 3 (1999), 39–53. [23] Betti A Hamilton and Terri A Scandura. 2003. E-Mentoring: Implications for organizational learning and development in a wired world. Organizational Dynamics 31, 4 (2003), 388–402. [24] F Maxwell Harper, Daniel Moy, and Joseph A Konstan. 2009. Facts or friends?: distinguishing informational and conversational questions in social Q&A sites. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 759–768. [25] David G Hendry, Norah Abokhodair, Rose Paquet Kinsley, and Jill Palzkill Woelfer. 2017. Homeless young people, jobs, and a future vision: Community members’ perceptions of the job co-op. In Proceedings of the 8th International Conference on Communities and Technologies. ACM, 22–31. [26] E Tory Higgins. 1998. Promotion and prevention: Regulatory focus as a motivational principle. In Advances in experimental social psychology. Vol. 30. Elsevier, 1–46. [27] Monica C Higgins and Kathy E Kram. 2001. Reconceptualizing mentoring at work: A developmental network perspective. Academy of management review 26, 2 (2001), 264–288. [28] Gary Hsieh, Robert E Kraut, and Scott E Hudson. 2010. Why pay?: exploring how financial incentives are used for question & answer. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 305–314. [29] Herminia Ibarra. 1993. Personal networks of women and minorities in management: A conceptual framework. Academy of management Review 18, 1 (1993), 56–87. [30] Valerie J. Janesick. [n. d.]. Strategies of qualitative inquiry. [31] Ruogu Kang, Laura Dabbish, and Katherine Sutton. 2016. Strangers on
your phone: Why people use anonymous communication applications. In Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing. ACM, 359–370. [32] Christina Algiere Kasprisin, Peg Boyle Single, Richard M Single, and Carol B Muller. 2003. Building a better bridge: Testing e-training to improve e-mentoring programmes in higher education. Mentoring and Tutoring 11, 1 (2003), 67–78. [33] Kevin R Kelly and Wei-Chien Lee. 2002. Mapping the domain of career decision problems. Journal of Vocational Behavior 61, 2 (2002), 302–326. [34] Yubo Kou and ColinMGray. 2018. What do you recommend a complete beginner like me to practice?: Professional Self-Disclosure in an Online Community. Proceedings of the ACM on Human-Computer Interaction 2, CSCW (2018), 94. [35] Kathy E Kram and Lynn A Isabella. 1985. Mentoring alternatives: The role of peer relationships in career development. Academy of management Journal 28, 1 (1985), 110–132. [36] Melenie J Lankau and Terri A Scandura. 2002. An investigation of personal learning in mentoring relationships: Content, antecedents, and consequences. Academy of Management Journal 45, 4 (2002), 779–790. [37] Colin ISG Lee, Will Felps, and Yehuda Baruch. 2014. Toward a taxonomy of career studies through bibliometric visualization. Journal of Vocational Behavior 85, 3 (2014), 339–351.
Paper 653 Page 11
[38] Thomas W Lee. 1999. Using qualitative methods in organizational research. Sage. [39] Lena Mamykina, Bella Manoim, Manas Mittal, George Hripcsak, and Björn Hartmann. 2011. Design lessons from the fastest q&a site in the west. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, 2857–2866. [40] Melissa E Mitchell, Lillian T Eby, and Belle Rose Ragins. 2015. My mentor, my self: Antecedents and outcomes of perceived similarity in mentoring relationships. Journal of Vocational Behavior 89 (2015), 1–9. [41] Jonathan T Morgan, Siko Bouterse, Heather Walls, and Sarah Stierch. 2013. Tea and sympathy: crafting positive new user experiences on wikipedia. In Proceedings of the 2013 conference on Computer supported cooperative work. ACM, 839–848. [42] Janice Morse and Lyn Richards. 2002. Read me first for a user’s guide to qualitative research. CA, US: Sage Publications Thousand Oaks (2002). [43] Wendy Marcinkus Murphy. 2011. From e-mentoring to blended mentoring: Increasing students’ developmental initiation and mentors’ satisfaction. Academy of Management Learning & Education 10, 4 (2011), 606–622. [44] Kevin Kyung Nam, Mark S Ackerman, and Lada A Adamic. 2009. Questions in, knowledge in?: a study of naver’s question answering community. In Proceedings of the SIGCHI conference on human factors in computing systems. ACM, 779–788. [45] Ihudiya Finda Ogbonnaya-Ogburu, Kentaro Toyama, and Tawanna Dillahunt. 2018. Returning Citizens’ Job Search and Technology Use: Preliminary Findings. In Companion of the 2018 ACM Conference on Computer Supported Cooperative Work and Social Computing. ACM, 365–368. [46] Michael Quinn Patton. 2005. Qualitative research. Wiley Online Library. [47] Sharoda A Paul, Lichan Hong, and Ed H Chi. 2012. Who is authoritative? understanding reputation mechanisms in quora. arXiv preprint arXiv:1204.3724 (2012).
[48] Daryl Posnett, Eric Warburg, Premkumar Devanbu, and Vladimir Filkov. 2012. Mining stack exchange: Expertise is evident from initial contributions. In Social Informatics (SocialInformatics), 2012 International Conference on. IEEE, 199–204. [49] Belle Rose Ragins and Terri A Scandura. 1999. Burden or blessing? Expected costs and benefits of being a mentor. Journal of Organizational Behavior (1999), 493–509. [50] Patrick Royston, Douglas G Altman, and Willi Sauerbrei. 2006. Dichotomizing continuous predictors in multiple regression: a bad idea. Statistics in medicine 25, 1 (2006), 127–141. [51] Terri A Scandura. 1998. Dysfunctional mentoring relationships and outcomes. Journal of management 24, 3 (1998), 449–467. [52] Carmit-Noa Shpigelman, Patrice L Tamar Weiss, and Shunit Reiter. 2009. E-mentoring for all. Computers in Human Behavior 25, 4 (2009), 919–928. [53] Peg Boyle Single and Carol B Muller. 2001. When email and mentoring unite: The implementation of a nationwide electronic mentoring program. Implementing successful coaching and mentoring programs (2001), 107–122. [54] Erik H Trainer, Arun Kalyanasundaram, and James D Herbsleb. 2017. E-mentoring for software engineering: a socio-technical perspective. In Software Engineering: Software Engineering Education and Training Track (ICSE-SEET), 2017 IEEE/ACM 39th International Conference on. IEEE, 107–116. [55] Gang Wang, Konark Gill, Manish Mohanlal, Haitao Zheng, and Ben Y Zhao. 2013. Wisdom in the social crowd: an analysis of quora. In Proceedings of the 22nd international conference on World Wide Web. ACM, 1341–1352. [56] Yi-Chia Wang, Robert E Kraut, and John M Levine. 2015. Eliciting and receiving online support: using computer-aided content analysis to examine the dynamics of online social support. Journal of medical Internet research 17, 4 (2015). [57] Earnest Wheeler and Tawanna R Dillahunt. 2018. Navigating the job search as a low-resourced job seeker. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 48.
Paper 653 Page 12
