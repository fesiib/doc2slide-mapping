- Good morning.
I just wanna say, this guy is a display genius, getting my slides up.
I'm gonna start my talk off with my main message.
This is the one take away point that I want you to remember from the talk.
And it is this.
Telepresence attendance needs to focus on a range of usage models, personalization is a challenge and social norms continue to develop.
I'm going to illustrate this message to you today by talking about studies we've done on Telepresence Robot Attendance at UB Comp, CSCW and CHI over the last few years.
Now as we all know, conferences are important in the research community.
It's the last day of CHI, it's the nine A.M. session and you all are here just really pointing to that emphasis on that idea.
We come here to see presentations by various people.
To see papers, to see talks, to see plenaries.
We also come to network with other individuals to find collaborators, to find jobs and lots of many additional reasons.
But the reality is, attendance is not always easy.
It's not easy for everybody to come to a conference like CHI.
People have accessibility challenges that might make it difficult to actually travel or move about the conference setting.
There's also sometimes travel restrictions, maybe bans on Visas going between different countries, or people with new babies that make it difficult to travel.
And there's also times cost restrictions not everybody can afford to come to a conference like CHI.
So what we've done over the last few years is try to explore different mechanisms to allow people to remotely attend conferences like CHI.
In particular through the use of Telepresence Robots that you see on the screen here, and these are Beam Pros created by Suitable Technologies.
So we've studied them across a number of conferences to understand how people can actually remotely attend through them.
Now of course this is not the first research that has looked at Telepresence Robots.
There's a lot of studies that looked at their usage in work places, settings for meetings, and for casual interactions.
There's also research on attendance at Avatar based conferences in virtual worlds.
And what we do is we build on this research to more deeply explore robot usage at a conference like CHI.
Now as I said, we studied remote attendance at three conferences, the first one is UB Comp 2014, which is co-located with ISWC, the International Symposium on Wearable Computing.
CSCW 2016 and then CHI 2016.
Now to give you a sense of the different types of conferences, if you're not too familiar with them, UB Comp 2014 had about 800 local people.
We had seven remote attendees using six dedicated robots.
And it's a fairly medium sized conference, I would say three paper tracks running in parallel.
CSCW had around the same number of local people and then we had 19 remote people attend using a combination of shared and dedicated robots.
And there were five paper tracks.
And then CHI 2016 had 3700 local people and we had 33 remote attendees using ten shared robots across 16 paper tracks.
Now what I want to emphasize across these conferences is the type of robot usage we were exploring, as you can see in the yellow color.
We tried a combination of dedicated robots and also shared robots to understand how people would see the different experiences and how that behavior might change over time.
And I'll get into more detail about that in a few minutes.
Now across these conferences, we use a variety of data collection methods.
We had ad hoc observations where we would go to the sessions that remote attendees were actually attending using their robot.
We also conducted focus groups and interviews and I'll bet you that's the first time you've ever seen a focus group with people and Telepresence Robots before.
We also collected daily diary information asking the people at the end of their day, what was the experience like, what was positive, what was negative and how could we improve on the experience for them? What I'm going to do now is step through the results from each of the conferences and show you kind of how things evolved over time and what the experience is like.
So first, starting with UB Comp, back in 2014, which was held in Seattle in the United States.
So first and foremost, what really stood out for us was a sense of empowerment.
The idea that the remote attendees really felt like they could do something that they were not able to do in any other way.
Especially for those who had accessibility challenges.
This was a real game changer for them, in that they could actually physically move throughout the space without having concerns.
To the point where the robot actually felt like an extension of their own body, their own self, where they may be driving along, bump into something, or somebody might bump into them, and they actually felt like their own body was being bumped into, it was that close of a tie between them and the embodiment of the robot.
Now when we're at a conference, as you know, we're wearing these badges that have our name and that's really how we present ourselves to others, in addition to how we look, our hairstyle, our clothes and so on.
But when you're in a Telepresence Robot, you kind of all look the same.
Especially if you're looking from the back side where you don't see the display.
And so we're really cognizant of watching what effect this might have on the remote attendees.
We had suggested ahead of time that people send us an item that we could attach to their Telepresence Robot, to make them stand out a little bit.
But only one person actually did this, but it turned out to be super successful, as you can see here, the scarf is attached to the top, it kind of floats down as she goes down the aisle into the beginning of the session.
So it was really beneficial and people in the conference could actually really identify who this person was when approaching from behind the Telepresence Robot.
So it worked well.
We also learned that it can be really difficult to attend a conference using a Telepresence Robot for a long period of time.
This is the schedule for one day of UB Comp, it's pretty packed, just like CHI is, maybe not quite so much, but there's still a lot going on.
And people found it challenging because they have their own schedule and they're in two places at once and things that happen in their local setting kind of impact their time at the remote place.
For example, picking up kids from daycare, you still have to do it.
People also experience effects from time zones.
Those who were attending remotely from Europe really could only stay at UB Comp in the robot til maybe early afternoon because at that point in time it was already pretty late into the evening.
So it was a challenge.
And it was also pretty cognitively demanding to be in a Telepresence Robot from maybe more than a couple of hours.
Because it's actually hard to navigate and drive while also talking to people at the same time.
We also found that there was challenges around social norms and understanding what to do in a Telepresence Robot and what's okay and what's acceptable.
For example, people found it really difficult to understand where they should park to see the talks.
It was hard to see slides from the back of the room, but then driving to the front of the room meant that now all of a sudden you're blocking the view from people who are sitting down and you can't really adjust the height of these robots, at least the ones we used.
So what was interesting to us was the remote attendees actually started a way to understand social norms and what to do on their own accord they created a back channel in Hangouts and started talking to each other and saying, how do you control your volume, how do you know how loud you are, where are parking, what's working well? And there's a really interesting conversation that we were luckily invited to observe.
So in summary, what we saw at UB Comp was that dedicated robots really empowered people.
But they struggled with using them all the time and for long periods of time at a conference.
Remote attendees also wanted help understanding how to behave.
It was such a new experience and they didn't really necessarily know what to do or what was acceptable.
Now following from UB Comp, we said, let's try it again and let's look at what we learned in UB Comp and try to improve the experience and explore additional facets.
And so here we wanted to really build in the idea this issue of dedicated robots and try out shared robots as an alternate experience.
And CSCW 2016 was held in San Francisco, California, just to give you a sense of context and space.
We had three workshop attendees use dedicated robots for the entire portion of time that they were able to attend the workshop.
And three people attended the main conference program using a dedicated robot and then 13 people shared robots, where they would have various time slices throughout the conference that they pre signed up for.
Now what's interesting about this last set, is we actually had two different research groups share their robot amongst the research groups.
For example, the first case, a professor shared his robot with two of his graduate students.
And in the second case, seven graduate students shared the robot together, while their faculty member was present at the conference locally.
We also built on the idea of personalization.
So this time we said, you have to send us something.
Send us something we can easily attach to the top of the robot, so it can be visible from afar.
And people were actually really good about doing this.
For the small, there were people that didn't and this is my grad student, Ray, in the robot here.
We attached a colored balloon to the top of the robot just to get it a bit of sense of difference between the other robots and it purposely was meant to bob up and down so it was a bit more noticeable over a distance.
In terms of dedicated attendance, moving on to the results, we found that again it was challenging to be in two places at once.
But we knew better about this challenge ahead of time, so we actually talked to the remote attendees and said, this is gonna be difficult, make sure you plan things out really well to know that you are going to be in two places at once, essentially.
And people did this and it worked well for those that were able to talk to their family or coworkers and say I'm gonna be at a conference, I'm away for this time period.
And they were really receptive of that.
So that worked actually well, but it did require pre planning.
Now for those had time slices and asynchronously shared the robots, this actually also really worked well because they didn't feel as responsible for that robot, they didn't feel like they had paid to be at the conference and they had to attend for the entire time.
So there's a lot less guilt because they knew they could just pop in for their time sessions and that was totally okay.
We also saw interesting sharing patterns immerge for things that we had not thought about.
We basically gave people the opportunity to use the robot as they felt and people used it in different ways.
For example, one professor brought his entire class to CSCW, you can kind of see them in the background.
While beneficial for them to experience what it was like to be at the conference, now all of a sudden you have these different set of needs and perspectives between maybe the students who might not wanna be on camera and the professor who was totally fine with it.
But really that robot is designed for only a single person.
We also saw small group sharing emerge, where two people or three people try and use the robot at the same time.
While beneficial again, now there's this awkwardness where you have to sit very close to that person within their social space in order to be on camera and to see what's visible.
And you're looking at a pretty small laptop screen.
In terms of the presentation of self, attaching these physical items worked fairly well.
However, for cases where people were sharing a Telepresence Robot amongst their research lab, it was challenging because they had one set of items to represent their institution.
But people talked about the idea of wanting to have individualized items, specific to their own personality, perhaps.
The balloons, didn't work so well.
People felt that when they had a Telepresence Robot with the balloon attached to it, it was maybe a little less serious and they received less serious conversations from people as a result.
We also experimented with a back channel we set up in Skype, this time, trying to address technical issues that might come up for remote attendees, such as, why is the WiFi down, my robot's not working, but it actually turned into again, a channel for people to talk about social things and figuring out where they should be in the room, when it was okay to leave.
And they actually very quickly understood that we were observing from the sessions and took advantage of that and would ask us, I know you can see the robot in the room, am I in a good spot, am I blocking anybody's view and so on.
In summary, remote attendance involves different attendance models than in person attendance.
Shared Beams provided value, but did create identity issues.
Lastly, I'm gonna briefly talk about CHI 2016.
And here what we wanted to do is understand what might happen when you scale very big.
When you go to a very big conference with lots of people, and even more remote people sharing a greater number of robots.
Again we looked at personalization this time, we used colored flags because we didn't want to have to change personalization items over time with that many people.
And they were quite easy to see at a distance, which made it nice and they were also sort of at a certain height, so it'd be nice to spot over people's heads.
Now the biggest thing we learned from CHI was a shift in behaviors in terms of what was important to people.
Where as in UB Comp and CSCW, they participated in all of the conference stuff you would normally do if you were in person.
Here they became much more, what I would say is utilitarian and functional and really wanted to just see the talks.
And they recognized the size of the venue, pretty much very similar to here, a lot of space to cover if you're trying to get between sessions, and it would take about a good ten to 15 minute drive and then you would often see situations like this, where people would quickly run over and try to get a picture with you and talk with you, which would slow it down even more.
People saw this and realized, it's probably gonna mean I'm ending up at the back of many sessions, which is not easy to see through a Telepresence Robot.
So they became very strategic and would pick and choose which robots they were going to use based on where they were docked.
And we had multiple docking stations that you see in purple here and they were trying to pick one that was close to the actual room they were going to.
They would also drive the robot ahead of time into sessions and just park it at the front of the room and wait for the session to start.
So effectively, they were turning this fairly rich embodiment of a robot, that was really mobile and purposeful for that reason, into something just to stream the talk, which is not entirely different than just watching it online.
So in summary, what we see is, large scale events, like CHI, can create new challenges and shift behaviors to focus on utilitarian needs, which is much different than what we saw for the more medium sized conferences like UB Comp and CSCW.
Now lastly, just a few points on discussion and design opportunities.
So very clearly we see varying usage and design models for Telepresence Robots and remote attendance.
We see cases where having a dedicated robot is extremely valuable for some people and very much empowering.
But then there are also cases where you might think attendance is quite different.
When we go to a conference in person, we pay for ourselves, we attend and we're just ourselves.
But there's ways to bring broader groups of people, whether it's a class or even small groups together that might want to share some design, but this technology's really only designed for a single person, that's the intended usage.
And going beyond that is actually kind of awkward, there's social issues and so really there are design opportunities.
And there's also ways of thinking about other attendance models, it's not just about Telepresence Robots, but there's ways to maybe navigate between different technologies like live streaming, robots and other things.
Personalization is clearly a challenge and obviously it's not a good solution if you want to scale to go to physical items attached to robots, but there's lots of design opportunities for digital augmentations, additional screenings, additional appendages and so on that you might think of.
And then lastly, there's clearly challenges around knowledge sharing.
How do allow people to understand what is socially acceptable to do, and how do those norms evolve over time? The conversations around that for these conferences really happened in the back channel.
Where people would talk, especially the remote attendees, about what was good to do, but really we think there's design opportunities to open this up, to have the broader conversation with more people.
So to conclude, I'm just gonna go back to my message that Telepresence attendance needs to focus on a range of usage models.
Personalization is a challenge and social norms continue to develop and there's many ways we can look to design to support these needs.
Thank you.
(clapping) - [Woman] Okay, we have time for a couple of quick questions.
- [Man 1] Hi, I'm (man's name) from Bombay, thanks for the wonderful talk.
The question is more from the point of view of a conference organizer.
So of course we see the normal Beam rewards here, at CHI this year.
But if you have to put these up in future events, is this now the most optimum solution or do you think maybe we should try streaming stuff first and then provide the mobility aspect later? - Yah, so that's a really great question.
And unfortunately what we don't get to talk about in our TOCHI article is all of the background, policy stuff.
And there's a ton of it, a ton of challenges that still need to be addressed.
I think the most basic answer to your question is the right remote attendance solution is multiple solutions.
There are times when robots work really well and that is in sort of small scale, group interactions, not so great in watching a talk like this, if you were to park it, you could then turn to live stream.
But the challenge is, I think there's value in knowing who's around, who's present and that you're watching that talk because then maybe you can catch somebody in the hallway as they're leaving this session if you wanna talk to them.
So really the answer is multiple solutions, but venues pose really great challenges.
I'm happy to chat offline after.
- [Man 2] I have full op question on that (mumbles) from the University of Munich.
So I think, what it hints from your research and others, that basically the streaming is now quite well established and I think there's having an idea of how this could be done, this mixing between these modalities as you (mumbles).
So basically, when (mumbles) in hole four at the moment, I think a robot would be really great, I could choose which way to go, who to talk to, I'm happy to be stopped, but being in here, I'm also not talking to many people while I do this.
Do you have an idea of how this transitions because I haven't seen any research (mumbles) transitions between those solutions.
Do you have any insight what could be a way of getting those transitions right? - Yes, my answer is probably too long for the time we have, I'm happy to chat after.
But I think you're right.
This is really the design space that we need to understand and explore now, for sure.
