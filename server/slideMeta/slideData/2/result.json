{"title": "tempTitle", "slideCnt": 46, "slideInfo": [{"index": 0, "startTime": 0.0, "endTime": 4.0, "script": "", "ocrResult": " text Hig CUMS) UO MMA Vee sens JSSIGCHI COPYRIGHT \u00a9 2019 ACM."}, {"index": 1, "startTime": 4.67, "endTime": 8.0, "script": "and thank you all for being here. So the speed-accuracy trade off is", "ocrResult": " text Ee A Formal Information-Theoretic Transmission Scheme (FITTS)"}, {"index": 2, "startTime": 8.67, "endTime": 20.0, "script": "something we encounter a lot in each time. Often when you try to evaluate the quality of an interaction, we measure its speed and accuracy. Right? And want this to be as high as possible.", "ocrResult": " text THE PROBLEM OF THE SPEED-ACCURACY TRADEOFF"}, {"index": 3, "startTime": 20.67, "endTime": 30.0, "script": "And if we want to increase the speed and accuracy, we end up at the limit, above which, if we try to increase accuracy, we should decrease the speed,", "ocrResult": " text THE PROBLEM OF THE SPEED-ACCURACY TRADEOFF"}, {"index": 4, "startTime": 31.33, "endTime": 38.67, "script": "This is what's called the speed-accuracy trade off. And in this talk I'm interested about the speed-accuracy trade off in pointing movements.", "ocrResult": " text THE PROBLEM OF THE SPEED-ACCURACY TRADEOFF Speed"}, {"index": 5, "startTime": 39.33, "endTime": 76.0, "script": "And so what he did was, he made participants sit in front of a board, with two targets that have a certain size w. And he made them repeatedly point back and forth between them. And now, Fitts, manipulated accuracy by modifying the values of d and w. Which is summarized by the index of difficulty. So ID is the log of one plus the ratio d over w. And what he found was that the movement time was actually predicted by this index of difficulty, and they found the linear relationship between movement time and index of difficulty. Now what's important for us in HCI", "ocrResult": " text JUANTIFYING THE SPEED-ACCURACY TRADEOFF Difficulty: ID = log(1+ D/W) (bit) law for M"}, {"index": 6, "startTime": 76.67, "endTime": 82.0, "script": "linear relationship, they vary according to the participants and to the device.", "ocrResult": " text IUANTIFYING THE SPEED-ACCURACY TRADEOFF Index of Difficulty: ID = log(1+ D/W) (bit) Par cording"}, {"index": 7, "startTime": 82.67, "endTime": 90.0, "script": "So what, if we estimate these values for a and b, then we can actually evaluate the performance of the device or user.", "ocrResult": " text Fitts' LAw IN HCI Evaluate (by estimating values a and b): formance"}, {"index": 8, "startTime": 90.67, "endTime": 101.33, "script": "so we used old values from existing experiments for example, we can actually predict movement time for a pointing task or as part of a more complex interaction.", "ocrResult": " text Fitts\u2019 LAw IN HCI aluate (by estimating values a and b):"}, {"index": 9, "startTime": 102.0, "endTime": 110.67, "script": "So Fitts law is widely is used in HCI. I guess all of you have probably heard of it, but still it suffers from many issues. And in this presentation, I have selected three problems.", "ocrResult": " text Even thou: lawis used in HCI, it suffers fr many issue for this presentation"}, {"index": 10, "startTime": 111.33, "endTime": 119.33, "script": "So the first problem, is the problem of many different formulations. And now the question is, how many different formulation can you think of?", "ocrResult": " text PROBLEM 1: MANY DIFFERENT FORMULATIONS How many can you think of ?"}, {"index": 11, "startTime": 120.0, "endTime": 124.0, "script": "probably more. And now the second problem is that sometimes", "ocrResult": " text PROBLEM 1: MANY DIFFERENT FORMULATIONS MT =a+(D/w)? T =a+Dblog,D + MI 15 different formulati"}, {"index": 12, "startTime": 124.67, "endTime": 155.33, "script": "participants miss the targets. So typically what we do in HCI is we look at the actual distribution of endpoints, which are all the, all the black bullet points. We measure their standard deviation and then we multiply this by a constant factor. And this is our effective width, W, e, and we replace the width by this effective width. Now this was a solution, first given by Crossman in the experiment of psychology, then it was popularized by MacKenzie in HCI.", "ocrResult": " text PROBLEM 2: SOMETIMES PARTICIPANTS MISS THE TARGET"}, {"index": 13, "startTime": 156.0, "endTime": 161.33, "script": "And in the paper we have a critique of this solution. So I will refer you to the paper, it's a bit to long for this talk.", "ocrResult": " text PROBLEM 2: SOMETIMES PARTICIPANTS MISS THE TARGET misses (usually W sman 1957, M: Refer to paper for a critique"}, {"index": 14, "startTime": 162.0, "endTime": 168.67, "script": "But actually this issue with target misses points to, is that Fitts's experiment actually fails to measure correct accuracy", "ocrResult": " text PROBLEM 2: NOISY MANIPULATION OF ACCURACY"}, {"index": 15, "startTime": 169.33, "endTime": 174.0, "script": "in an accurate way, because of the target misses.", "ocrResult": " text PROBLEM 2: NOISY MANIPULATION OF ACCURACY"}, {"index": 16, "startTime": 174.67, "endTime": 217.33, "script": "The third problem, is a problem which I call the problem of regression. So this is empirical data, that you see all the time in Fit'z law. So on the y axis, you have movement time and on the x axis, you have the index of difficulty. And here, each blue dot is the outcome of a single movement. Now, according to Fitts law, you would expect that all these blue dots align quite nicely, onto a straight line. An you see, it's actually not really the case and we can actually compute the best straight line possible for this points, which is the orange line here, and you see the r squared value is quite low. It's much too low for a typical Fitts task for a task (muffled speaking). Because what we actually do in HCI, usually is we consider to average", "ocrResult": " text PROBLEM 3: REGRESSION"}, {"index": 17, "startTime": 218.0, "endTime": 260.0, "script": "movement time per condition. So you can see here the blue scattered parts is the same as previously. Except here, a represented orange diamond which are the average movement time per condition. And in these align quite nicely actually, and if you compute the best straight line through this, you find typical values of r squared that you find in HCI. Except the parameters of the line are actually more or less the same as before. Now, I know some of you would tell me that this is normal. We are just re-using the noise that we have in the data by averaging the measures. But then the question is, what do you do with data like this?", "ocrResult": " text PROBLEM 3: REGRESSION Fitts average MT"}, {"index": 18, "startTime": 260.67, "endTime": 278.0, "script": "So this is, the data from the field study, which is very high variability. And of course, we can compute linear regression and this will give us the orange line that sits kind of in the middle. And you can see obviously, what can we do with this information? It's hard to interpret.", "ocrResult": " text"}, {"index": 19, "startTime": 280.67, "endTime": 290.67, "script": "the theoretical framework for the speed-accuracy trade off, that's simple but rigorous and not completely driven by empirical considerations and hopefully to help solve problems I've just shown.", "ocrResult": " text GOAL OF THIS WORK: mpirical consi"}, {"index": 20, "startTime": 291.33, "endTime": 310.67, "script": "And now what we are going to use this information theory, for several reasons, is first because Fitts Law was actually originally conceived as an analogy with the Shannon capacity formula, and because the channel capacity theorem can actually be interpreted as a speed-accuracy trade off. So let's jump right into the, only result", "ocrResult": " text GOAL OF THIS WORK: Tool used: Shannon's Information Theory Fit"}, {"index": 21, "startTime": 311.33, "endTime": 396.0, "script": "I'm going to present today of information theory which is the Capacity of the Gaussian Channel. So first of all, what's the channel? So a channel is just a pipe, it does an input, x, and an output, y. And in the case, this particular case of the Gaussian Channel, the model is that the output is a noisy observation of the input. For you see, y is the sum of x, the input plus sum gaussian symbol. And now we have a clever way of having a mathematical formula for the transmitted information in despite of the information theory which is called I. And what we try to do, is we try to maximize this transmitted information and this maximum transmitted information is called the capacity, C. And this maximum, you find it over all possible input distribution. So you look for all the x's that maximizes the transmitted information. And in the case of the Gaussian Channel, the input that maximize this is also the Gaussian distribution with variance P. Now if you look at the famous Shannon's Theorem Seventeen, it's just an evaluation of the C in the case of the Gaussian Channel. And so you see, it's simply the bandwidth times log of one plus p over n where p is the power of the input and n is the power of the noise. And this theorem expresses a trade off between time through the bandwidth parameter and bits.", "ocrResult": " text CAPACITY OF THE GAUSSIAN CHANNEL:"}, {"index": 22, "startTime": 396.67, "endTime": 430.0, "script": "Now Fitts directly applied this formula, and he said well, in case of human movements, my signal is the average movement and the noise is just a moving variability. And then he said, because bandwidth is expressed in Hertz , which is the units are one over a time, he simply identified bandwidth to one over a time. And if you put all of this into Shannon Capacity formula, you actually find Fitts' first formula in 1954, and then he added later in intercept for Better Data '15.", "ocrResult": " text A CLOSER LOOK AT FiTTS' 1954 ANALOGY analogy: Humans ha mplitude of a human movement is quivalent to signal\u201d \u2014+ P= D Movement variability is equivalent By is expressed in Hertz = s-! ~ MT MT & Zlog(1 + D/W) (19"}, {"index": 23, "startTime": 430.67, "endTime": 469.33, "script": "are some questions that emerge. So first of all, why do you identify bandwidth with one over m,t? It's not that simple. And why would you equate a variance, which is suppose to be proportional or at least related to the square of the input, to the amplitude, which is, would be related to the input itself. And what's the channel model of the aiming task and what are the input and output's. And by this, we mean, basically what's the link between Channels Capacity formula and aiming. Cause to us, it's hard to draw a link just from this. So our model actually answers these questions.", "ocrResult": " text A CLOSER LOOK AT FITTS\u2019 1954 ANALOGY analogy: Humans ha\\ mmuni itude of a human movement is tto signal\u201d \u2014 P= D Movement variability is equivalent t IT uesti"}, {"index": 24, "startTime": 470.0, "endTime": 476.0, "script": "So this is the name of the model, A Formal Information-Theoretic Transmission Scheme.", "ocrResult": " text FITTS: A FORMAL INFORMATION-THEORETIC TRANSMISSION SCHEME"}, {"index": 25, "startTime": 476.67, "endTime": 501.33, "script": "And so the first abstract model is very simple. So there's a, the user has the intention of aiming it towards the target and this intention is not to a signal that send it over a noisy channel to the muscle which prefer movement. And as we've seen just before, everything in this work relies on the Channel model. So what we are going to do, is were going to integrate the task constraints in the Channel model, okay.", "ocrResult": " text COMMUNICATION MODEL ing device intention [| ] gr ) hit Destination Neural Noise"}, {"index": 26, "startTime": 504.0, "endTime": 524.0, "script": "So if we loo at the task, or when we have to hit a target, what we are going to do is, we are going to aim at the center of the target and then we allow a variability that's the size of the targets. So this gives us first constraint on noise. And then the fact that the targets are separated by distance, D, gives us second constraint on input then if we take these two constraints together", "ocrResult": " text CONSTRAINTS ON X, Y AND Z Hit the targ than \u00a5 (no mi The amplitude"}, {"index": 27, "startTime": 524.67, "endTime": 530.0, "script": "this gives us third constraint on the output.", "ocrResult": " text CONSTRAINTS ON X, Y AND Z \u2018ability |"}, {"index": 28, "startTime": 530.67, "endTime": 556.0, "script": "So now we have assumed basically, that the noise was bounded which we still have to choose a distribution for noise and this is not something that's easy. So what we do is, we use something that's used in physics, which is called the Principle of Maximum Entropy, which is basically says that if you don't know how to choose your distribution, your best bet is to go with the one that maximizes the entropy. So in our case, this is the uniform distribution. So we assume, so this is a", "ocrResult": " text WHICH NOISE Z ? Principle of Maximum Entropy UJayn' ibution that be The maximum rm dis"}, {"index": 29, "startTime": 556.67, "endTime": 587.33, "script": "recap of the channel model, so it outer bounds and the uniform distributed noise. And so in the paper, we actually show how we can compute the capacity of this channel so we express the transmitted information and then look for the best input. And we show that the capacity is actually log of one, plus d over w. Which is exactly the idea proposed by MacKenzie in '99. And what's interesting is if you look at the input that actually reaches the capacity, its the discreet uniform input.", "ocrResult": " text UNIFORM CHANNEL MODEL u- Capacity of the uniform channel C = maxi(X; Y) = log(1+D/W) = ID (Mi Discrete uniform input X reaches capacity Addresses Problem 1 (Formulations)"}, {"index": 30, "startTime": 588.0, "endTime": 612.0, "script": "space are all the set of black bullet points. So its as if you see the entire available space was filled up with targets of size w and when you actually aim towards a target you actually choose the right target. And so we summered this in the paper with a catch phrase, which is that aiming is actually choosing. So this is an interpretation.", "ocrResult": " text CAPACITY ACHIEVING DISTRIBUTION W Fitts\u2019 paradigm X input ing is choosing"}, {"index": 31, "startTime": 612.67, "endTime": 644.67, "script": "So, I know some of you will have maybe a tough time accepting the uniform noise assumption, but the interesting thing here, is that if you look a what the uniform noise was given by the maximum entropy principle, so in our case it was actually the worse noise. Right. So this capacity is actually a lower bond. And now the question is, suppose the noise is not uniform, but for example Gaussian, which most of you will agree is likely, what is the error that we actually make by assuming this capacity with uniform noise.", "ocrResult": " text C AS ALOWER BOUND mum entr log(1 \u2018hat if the noise is not uniform, b"}, {"index": 32, "startTime": 645.33, "endTime": 655.33, "script": "this difference is at most zero point two bits. So its actually quite small. And you can find more details about this in the paper.", "ocrResult": " text AS A LOWER BOUND man-Mack"}, {"index": 33, "startTime": 656.0, "endTime": 666.67, "script": "So now we presented a model for errorless task with uniform noise and then we show how it can be generalized to any abitrary noise and I just show you an evaluation with the Gaussian noise.", "ocrResult": " text with Uniform Noise with any Arbitrary Ne"}, {"index": 34, "startTime": 669.33, "endTime": 700.0, "script": "So sometimes participants miss the target as I have said. And in the paper, to talk about misses, we distinguish errors from erasures. And what we mean by errors, if you look at how error, how the correction is computed it takes into account the standard deviation, and standard deviation basically considers the distance from each endpoint to the target center. So with in this definition, all movements involve metrical errors. So this is what we mean by errors. It's just that their amplitude varies.", "ocrResult": " text DISTINGUISHING ERRORS FROM ERASURES Participants sometimes miss the target (rate <) y Erasures 's center ments i"}, {"index": 35, "startTime": 700.67, "endTime": 721.33, "script": "Now on the other hand, if we look at GUI, what matters is really whether or not the click falls inside of the intended area. So here, if I want to click on sponsors I can click anywhere inside this light gray orange box. And it doesn't matter where the click takes place. And this Dichotomous hit or miss notion corresponds to the notion of erasures.", "ocrResult": " text ERASURES Ce cas ee a U t matt Whether or not the cl Not where the information-theory"}, {"index": 36, "startTime": 722.0, "endTime": 736.0, "script": "erasures and we show that the calculation of the capacity is actually very simple. And it's simply one minus epsilon. So which is actually the success rate times the i,d. And you see that the i,d, corresponds", "ocrResult": " text CAPACITY FOR THE CHANNEL WITH ERASURES (1) loga(1 + D/W)"}, {"index": 37, "startTime": 736.67, "endTime": 745.33, "script": "to the accuracy as prescribed by w and the success rate is just the correction for the misses.", "ocrResult": " text CAPACITY FOR THE CHANNEL WITH ERASURES )loga(1 + D/W) = (1 -s)ID = ID(e) Addresses Problem 2 (Misses)"}, {"index": 38, "startTime": 746.0, "endTime": 785.33, "script": "If we compare the two corrections, so the Crossman- Mackenzie correction and the the one that comes from the erasure model an important difference is that the Crossman-Mackenzie correction assumes the Gaussian distribution for the errors, where as in our case, there's no such assumptions. So actually we have a non- parametric formulation here. Another nice thing is that if you look at the condition for null error rates the Crossman-Mackenzie correction is actually undefined. And in our case, it's simply reduces to the index of difficulty, so this is simply interpreted as the index of difficulty is the transmitted information when there are no errors. So it's very simple interpretation.", "ocrResult": " text COMPARISON WITH CROSSMAN-MACKENZIE CORRECTION Crossman-Mackenzie Erasure Model"}, {"index": 39, "startTime": 786.0, "endTime": 803.33, "script": "So this is, I basically presented the complete model for movement time in Fitts task. But we never actually ask ourselves which movement time are we talking about. Cause, if we think about what channel capacity gives us, it should give us a minimum movement time, cause the channel capacity is expressed as a maximum.", "ocrResult": " text WHICH MOVEMENT TIME ? mplete model for movement time (M'T) in Fitts\u2019 t apacity gives minimum MT (C = max/(X;Y))"}, {"index": 40, "startTime": 804.0, "endTime": 819.33, "script": "what we ask participants to work as rapidly as possible then we trust them to actually do it then we compute the average time. So this is something that's kind of like an average-minimum time. And so what we argue in the paper", "ocrResult": " text WHICH MOVEMENT TIME ? X;Y))"}, {"index": 41, "startTime": 820.0, "endTime": 834.0, "script": "if we separate these two metrics into an average time metrics, which would be given by the linear regression as usual and the minimum time metric, which would correspond to the information theoretic interpretation of Fitts law.", "ocrResult": " text WHICH MOVEMENT TIME ? mplete model for movement time (M'T) in Fitts\u2019 ti Minimum time"}, {"index": 42, "startTime": 834.67, "endTime": 861.33, "script": "looks like, so this is a data sample from a point in field study. So you see that the orange line is the one that you get from linear regression kind of sits in the middle, and the minimum time metric is given by the the black line. So you see this gives a lot more information. You can actually compare to different metrics and this gives a lot more useful information than just the orange line that sits in the middle.", "ocrResult": " text PagerButton Linear Fit Front Fit Ip (bits)"}, {"index": 43, "startTime": 862.0, "endTime": 875.33, "script": "So to conclude, our model links the index of difficult to a channel capacity, where everything is defined and interpreted.", "ocrResult": " text CONCLUSION links ID to a channel capacity mpl ne where input, output anc defined and interpre"}, {"index": 44, "startTime": 876.0, "endTime": 900.0, "script": "it's kind of a black box model for endpoints. It's only concern with movement time, it's not concerned about the full trajectories. It's not really based on any empirical findings about the nervous system and it's based on abstract information theory and we don't take feedback into account. Now a third problem is that we never actually tell you in the paper, how to compute the minimum time regression and, so actually", "ocrResult": " text CONCLUSION links ID to a channel c FITTS is a \"black-box\" model for enc ncered with MT (ni empirical findin dditional problem: Compute the minimum time regression"}, {"index": 45, "startTime": 900.67, "endTime": 1064.67, "script": "this is, was work done in 2016, 2017 and it was published in 2018. So you can find the references here and since then, we've actually made a lot of progress. So we have come up with a new scheme, which we call Fitts 2. Which is basically a scheme for full trajectory with feedback control. So you can find most of it in the pre-print, or inside my thesis, which is online since December. And then we also provided recently, a new regression technique, which is a formal method to determine this minimum time metric. So again I refer you to pre-print for this. Thank you for your attention, and I will be taking questions. (Applause) [Announcer] - It's time for one quick question. [Interviewer] - I have a question for you, would you advise from now on if you want to characterize new input devices and you want to give like an index of difficulty or performance measure are you actually specifying that you should not normally compute minimum time but also average time, should we actually give two measures? [Speaker] - Yeah, I think there's a lot to be gained actually by separating these two measures and the difference between those two might give you interesting results, for example if I did this in a controlled, if I had shown you the same thing in a controlled study, the average time metric and the minimum time metric would be almost identical. In the field study, they are very far apart. And actually, just computing the two and looking at the difference can actually give you an idea of how much the participants actually invested their efforts during the experiments. Because sometimes we know participants, they get bored and especially in experiments like Fitts task and this actually, if you notice that the two lines are quite close it can give you some assurance that the participants were actually engaging the task and things like this. So this is one idea, of course there are probably other things that can be envisioned. [Interviewer] - Yeah, perhaps that a variance among participants or experiments, some input devices might just... [Speaker] - Yes. [Interviewer] - have more variance than others. [Speaker[ - Exactly, some Input devices might create more variance than others and this would also be noticeable with this. [Interviewer] - Okay, Thank you, very, very challenging (mumbles). (Applause) [Announcer] - Okay, with this we conclude the session on behavior monitoring.", "ocrResult": " text A Formal Information-Theoretic Transmission Scheme (FITTS) Fi, O. Rioul, and Y. G movement: A formal informati ACM Transaction -print hal. archives-ouver"}], "outline": [{"section": "", "startSlideIndex": 0, "endSlideIndex": 45}], "topSections": [["REFERENCES", "Limitations", "Annotation quality"], ["Annotation quality", "Annotation quality", "Limitations"], ["Annotation quality", "Annotation quality", "Annotation quality"], ["Annotation throughput", "REFERENCES", "Annotation quality"], ["Annotation throughput", "REFERENCES", "Annotation quality"], ["Annotation throughput", "REFERENCES", "Annotation quality"], ["REFERENCES", "Limitations", "Annotation quality"], ["Annotation throughput", "REFERENCES", "Annotation quality"], ["REFERENCES", "Annotation quality", "Annotation throughput"], ["REFERENCES", "REFERENCES", "REFERENCES"], ["CCS CONCEPTS", "REFERENCES", "REFERENCES"], ["REFERENCES", "CCS CONCEPTS", "REFERENCES"], ["Comparison to previous studies", "Annotation quality", "2 RELATED WORK"], ["REFERENCES", "Annotation throughput", "Annotation quality"], ["Annotation quality", "Comparison to previous studies", "REFERENCES"], ["REFERENCES", "Comparison to previous studies", "Annotation quality"], ["REFERENCES", "Comparison to previous studies", "Comparison to previous studies"], ["Comparison to previous studies", "REFERENCES", "REFERENCES"], ["Annotation quality", "Annotation throughput", "Comparison to previous studies"], ["Comparison to previous studies", "REFERENCES", "Tasks"], ["Annotation quality", "Comparison to previous studies", "REFERENCES"], ["1 INTRODUCTION", "Audio data", "REFERENCES"], ["REFERENCES", "Comparison to previous studies", "2 RELATED WORK"], ["1 INTRODUCTION", "REFERENCES", "2 RELATED WORK"], ["Annotation quality", "Annotation quality", "1 INTRODUCTION"], ["1 INTRODUCTION", "Comparison to previous studies", "REFERENCES"], ["REFERENCES", "Comparison to previous studies", "Comparison to previous studies"], ["Annotation throughput", "Comparison to previous studies", "Comparison to previous studies"], ["Tasks", "Audio data", "Tasks"], ["Tasks", "Tasks", "REFERENCES"], ["REFERENCES", "Tasks", "Annotation throughput"], ["Annotation quality", "REFERENCES", "1 INTRODUCTION"], ["2 RELATED WORK", "Tasks", "Comparison to previous studies"], ["Annotation quality", "Limitations", "REFERENCES"], ["Comparison to previous studies", "Annotation quality", "1 INTRODUCTION"], ["1 INTRODUCTION", "5 DISCUSSION", "Audio data"], ["Comparison to previous studies", "REFERENCES", "2 RELATED WORK"], ["Comparison to previous studies", "2 RELATED WORK", "Limitations"], ["REFERENCES", "Comparison to previous studies", "Annotation quality"], ["REFERENCES", "Annotation quality", "Annotation throughput"], ["Annotation quality", "Annotation quality", "Annotation quality"], ["Annotation quality", "Annotation quality", "Annotation quality"], ["Annotation quality", "Annotation quality", "Annotation throughput"], ["Annotation quality", "Annotation quality", "REFERENCES"], ["REFERENCES", "Annotation throughput", "2 RELATED WORK"], ["REFERENCES", "1 INTRODUCTION", "Annotation quality"]], "weight": [78, 94, 101, 107, 112, 115, 115, 115, 111, 14, 15, 15, 16, 16, 16, 14, 13, 15, 16, 17, 17, 17, 19, 19, 20, 23, 24, 23, 25, 28, 31, 30, 28, 31, 33, 36, 34, 35, 38, 40, 41, 38, -75, -72, -69, 36], "similarityTable": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1976463943719864, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2513297498226166, 0.29008227586746216, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18281926214694977, 0, 0, 0, 0.2102186530828476, 0, 0, 0, 0, 0, 0.19456622004508972, 0, 0, 0.2686617970466614, 0, 0, 0, 0.2678149342536926, 0, 0, 0, 0, 0, 0, 0, 0, 0.21720391511917114, 0, 0, 0, 0, 0, 0, 0, 0, 0.1950192004442215, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17695876955986023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1880197525024414, 0.25487256050109863, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.174752876162529, 0, 0, 0, 0.1740504652261734, 0, 0, 0, 0, 0, 0, 0.17185041308403015, 0, 0, 0.18308532238006592, 0, 0, 0, 0.2944321930408478, 0, 0, 0, 0, 0, 0, 0, 0, 0.19266685843467712, 0, 0, 0, 0, 0, 0, 0, 0, 0.18269221484661102, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1930677443742752, 0.19112741947174072, 0.18061113357543945, 0, 0, 0, 0, 0, 0, 0, 0, 0.18765637278556824, 0.20344601571559906, 0, 0, 0.18139371275901794, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3134773373603821, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1959945559501648, 0, 0.21439629793167114, 0, 0.21179459989070892, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1723014861345291, 0, 0.18513800203800201, 0, 0, 0, 0, 0, 0, 0, 0, 0.19114471971988678, 0.21321262419223785, 0, 0, 0.1642836481332779, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28693097829818726, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17323385179042816, 0.17094257473945618, 0, 0.20447243750095367, 0, 0.18029353022575378, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17230147123336792, 0, 0.18513795733451843, 0, 0, 0, 0, 0, 0, 0, 0, 0.1911446899175644, 0.21321259438991547, 0, 0, 0.1642836481332779, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28693097829818726, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17323392629623413, 0.17094260454177856, 0, 0.20447248220443726, 0, 0.18029353022575378, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17230147123336792, 0, 0.18513795733451843, 0, 0, 0, 0, 0, 0, 0, 0, 0.1911446899175644, 0.21321259438991547, 0, 0, 0.1642836481332779, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28693097829818726, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17323392629623413, 0.17094260454177856, 0, 0.20447248220443726, 0, 0.18029353022575378, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18377310037612915, 0.19982007145881653, 0, 0, 0, 0, 0, 0, 0, 0, 0.20259180665016174, 0.2016574740409851, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18391308188438416, 0, 0, 0, 0, 0, 0, 0.3015475869178772, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20103254914283752, 0.19690100848674774, 0, 0.2133598029613495, 0, 0.20189106464385986, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21869249641895294, 0.2172958105802536, 0, 0.2348366379737854, 0, 0, 0, 0, 0.22530093789100647, 0.20918238162994385, 0, 0, 0.23841719329357147, 0.23757338523864746, 0, 0, 0.21899427473545074, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3060529828071594, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2145909070968628, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17313095927238464, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22325506806373596, 0.2168404757976532, 0.20279377698898315, 0, 0.18347783386707306, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2850269377231598, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2060490846633911, 0.20806068181991577, 0, 0.18691407144069672, 0, 0.1882055103778839, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21316643059253693, 0.22200733423233032, 0, 0, 0.23591314256191254, 0.24254125356674194, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2775886058807373, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20749503374099731, 0.20684264600276947, 0.22980447113513947, 0.2082570493221283, 0, 0.2483147829771042, 0, 0, 0], [0.20440679788589478, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.23783618211746216, 0.21362018585205078, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3014165461063385, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1804066002368927, 0.22004257142543793, 0.23015156388282776, 0.20632869005203247, 0, 0.21329417824745178, 0, 0.17716887593269348, 0], [0.20559370517730713, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.23526513576507568, 0.2229282706975937, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3058152496814728, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2091120481491089, 0.21846352517604828, 0.21900761127471924, 0.23675480484962463, 0, 0.20871824026107788, 0, 0.19317840039730072, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20353184640407562, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20406800508499146, 0, 0, 0.2440473735332489, 0.25225988030433655, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21058784425258636, 0, 0, 0, 0, 0, 0.26506277918815613, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2149689942598343, 0, 0.22879661619663239, 0, 0.2205936461687088, 0, 0.21169008314609528, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20572040975093842, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18285667896270752, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.26317375898361206, 0.2625846862792969, 0.19421294331550598, 0, 0.18233099579811096, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2127903401851654, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19660818576812744, 0, 0, 0.22791719436645508, 0, 0, 0, 0.18916164338588715, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24675561487674713, 0.24622315168380737, 0.17481984198093414, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1766766607761383, 0, 0, 0, 0, 0, 0.18133258819580078, 0.16852669417858124, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.23558029532432556, 0, 0, 0.2309744507074356, 0, 0.16826573014259338, 0, 0.1802068054676056, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25983282923698425, 0.30142778158187866, 0.25171393156051636, 0, 0.19416815042495728, 0, 0, 0, 0.20658597350120544, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.227321058511734, 0.19723638892173767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1984691321849823, 0.20968131721019745, 0, 0.24453817307949066, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24635088443756104, 0.2862222194671631, 0.23355552554130554, 0, 0, 0, 0, 0, 0.197735995054245, 0, 0, 0, 0.17547070980072021, 0, 0, 0, 0, 0, 0.19184939563274384, 0.1991649568080902, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2007180154323578, 0, 0.23178306221961975, 0, 0, 0, 0.1933903694152832, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18030287325382233, 0, 0, 0, 0, 0, 0.18943241238594055, 0, 0, 0.1640777885913849, 0.21445031464099884, 0.1893938034772873, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.15487515926361084, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24496549367904663, 0, 0, 0.22715845704078674, 0, 0, 0, 0.148274764418602, 0.14828264713287354], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13595697283744812, 0, 0.14733406901359558, 0, 0, 0, 0, 0, 0.17277933657169342, 0, 0, 0.19710804522037506, 0.23936358094215393, 0.20024728775024414, 0, 0.14749445021152496, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1313183307647705, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16742128133773804, 0, 0, 0.2173416167497635, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16873550415039062, 0, 0, 0, 0, 0, 0, 0.18919134140014648, 0, 0, 0, 0, 0, 0, 0, 0.20161457359790802, 0, 0, 0.19424177706241608, 0.22392426431179047, 0.19725602865219116, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21766462922096252, 0.17167025804519653, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16947610676288605, 0, 0.24531230330467224, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17278985679149628, 0, 0, 0, 0, 0, 0, 0, 0, 0.1808934509754181, 0, 0, 0, 0, 0, 0.20109860599040985, 0, 0, 0.16345393657684326, 0.20184612274169922, 0.1814146339893341, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1625644713640213, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17469343543052673, 0, 0.15894189476966858, 0.2444317638874054, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0.13284404575824738, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13225005567073822, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18342550098896027, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16311457753181458, 0, 0, 0.17848888039588928, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.12346556037664413, 0.20143401622772217, 0, 0.19875138998031616, 0, 0, 0.18043404817581177, 0, 0, 0, 0.15434345602989197, 0], [0, 0, 0, 0, 0, 0.13057729601860046, 0, 0, 0, 0, 0, 0, 0.12275615334510803, 0, 0, 0, 0, 0.180014967918396, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13279201090335846, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17009767889976501, 0, 0, 0, 0, 0, 0.1248793974518776, 0, 0, 0, 0, 0, 0, 0.13741597533226013, 0.12854990363121033, 0.22249865531921387, 0, 0, 0, 0, 0, 0, 0, 0.13413935899734497], [0, 0, 0, 0, 0, 0.09295304119586945, 0, 0, 0, 0, 0, 0, 0.09024375677108765, 0, 0, 0, 0, 0.1271112859249115, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.10624537616968155, 0.13709591329097748, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1377975046634674, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.09226234257221222, 0.19186238944530487, 0, 0, 0, 0, 0.09582588076591492, 0, 0, 0.09868957102298737], [0, 0, 0, 0, 0, 0, 0.1526162475347519, 0, 0, 0, 0, 0, 0.16068971157073975, 0, 0, 0, 0, 0, 0, 0.1647738218307495, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.15553559362888336, 0, 0, 0, 0.1526932418346405, 0, 0, 0, 0, 0, 0.15833738446235657, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.15778927505016327, 0, 0, 0, 0, 0, 0, 0, 0.16704660654067993, 0.22443237900733948, 0, 0, 0, 0, 0, 0, 0, 0.17385870218276978], [0, 0, 0, 0, 0, 0, 0.127743661403656, 0, 0, 0, 0, 0, 0.1329832375049591, 0, 0, 0, 0, 0, 0, 0.1316840946674347, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13584747910499573, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13522645831108093, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.12632212042808533, 0, 0, 0, 0, 0, 0, 0, 0.13183635473251343, 0.20103025436401367, 0, 0, 0, 0.1253615915775299, 0, 0, 0, 0.14607033133506775], [0, 0, 0.12890008091926575, 0, 0, 0.16017869114875793, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1400948017835617, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13657689094543457, 0, 0, 0, 0, 0, 0, 0.1251136213541031, 0, 0, 0, 0, 0.1254195272922516, 0, 0, 0, 0, 0, 0, 0, 0.20909923315048218, 0, 0.25444260239601135, 0, 0, 0.12864291667938232, 0, 0.16488191485404968, 0, 0, 0], [0, 0, 0.17403903603553772, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18161149322986603, 0, 0.15184661746025085, 0, 0, 0, 0, 0.14223863184452057, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1391707807779312, 0, 0.13855066895484924, 0, 0.17565028369426727, 0, 0, 0, 0, 0, 0, 0, 0, 0.1577461063861847, 0, 0.1662173867225647, 0, 0, 0, 0, 0.21857506036758423, 0, 0, 0], [0, 0, 0, 0, 0, 0.182604119181633, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.15521135926246643, 0.15433454513549805, 0, 0.17903856933116913, 0, 0, 0.16476893424987793, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17218227684497833, 0, 0.17643916606903076, 0, 0, 0, 0, 0, 0, 0, 0, 0.20415407419204712, 0, 0.16821767389774323, 0, 0, 0, 0, 0.22615429759025574, 0, 0, 0], [0, 0, 0, 0, 0, 0.19593720138072968, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1891593188047409, 0, 0.18863525986671448, 0, 0, 0.18890896439552307, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2008240520954132, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19855482876300812, 0, 0.19643108546733856, 0, 0, 0, 0, 0, 0, 0, 0, 0.20960843563079834, 0, 0.18624600768089294, 0, 0, 0, 0, 0.2599387764930725, 0, 0, 0], [0, 0, 0, 0, 0, 0.20752492547035217, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1926371455192566, 0, 0, 0, 0.13707834482192993, 0, 0, 0, 0, 0, 0.13216382265090942, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1800031065940857, 0, 0, 0, 0, 0, 0.15973275899887085, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.23838064074516296, 0, 0.25466668605804443, 0, 0, 0, 0, 0.14520996809005737, 0, 0, 0.14375001192092896], [0, 0, 0, 0, 0, 0, 0.24748626351356506, 0, 0, 0, 0, 0, 0.25257277488708496, 0, 0, 0, 0, 0, 0, 0.25569021701812744, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25219541788101196, 0, 0, 0, 0.25783276557922363, 0, 0, 0, 0, 0, 0.2530371844768524, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25404566526412964, 0.3442588448524475, 0, 0, 0, 0.2496912181377411, 0, 0, 0, 0.28038492798805237], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.23071905970573425, 0, 0, 0, 0, 0, 0, 0.226314976811409, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.23366597294807434, 0, 0, 0, 0.2346007525920868, 0, 0, 0, 0, 0, 0.2335478812456131, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22552892565727234, 0, 0, 0, 0, 0, 0, 0, 0.23351365327835083, 0.3387206196784973, 0, 0, 0, 0.23174069821834564, 0, 0, 0, 0.2572329044342041], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16541320085525513, 0, 0, 0, 0.19185742735862732, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16135619580745697, 0, 0, 0, 0.16263246536254883, 0, 0.16861528158187866, 0, 0, 0, 0.16009043157100677, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21195755898952484, 0.15980125963687897, 0.2992258071899414, 0, 0, 0, 0, 0, 0, 0, 0.18804864585399628], [0, 0, 0, 0, 0, 0.16202577948570251, 0, 0, 0, 0, 0.18031948804855347, 0, 0, 0, 0, 0, 0, 0.21571466326713562, 0, 0, 0, 0.19929832220077515, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17156562209129333, 0, 0, 0, 0.21798080205917358, 0, 0, 0, 0, 0, 0.20869871973991394, 0, 0, 0, 0.17756889760494232, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24974581599235535, 0, 0.27479034662246704, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0.20156703889369965, 0, 0, 0, 0, 0.21066588163375854, 0, 0, 0, 0, 0, 0, 0.19415390491485596, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20565171539783478, 0.23889896273612976, 0, 0, 0, 0.2147824466228485, 0.1981714367866516, 0, 0, 0, 0, 0.2292129099369049, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28252583742141724, 0, 0.2884085178375244, 0, 0, 0, 0, 0, 0, 0, 0], [0.17233990132808685, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.14821498095989227, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.239765465259552, 0.2492886632680893, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1615903228521347, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.23060816526412964, 0, 0.16709239780902863, 0, 0.16686570644378662, 0.21373388171195984, 0, 0.1494293510913849, 0, 0, 0], [0.19675074517726898, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18566466867923737, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2887992262840271, 0.28589826822280884, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1850263476371765, 0, 0, 0, 0.19259382784366608, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.26759082078933716, 0, 0.19846037030220032, 0, 0, 0.23594047129154205, 0, 0.19931207597255707, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17772765457630157, 0, 0, 0.28987666964530945, 0.31253600120544434, 0, 0, 0.22509075701236725, 0, 0, 0, 0, 0, 0, 0, 0.2169525921344757, 0, 0, 0, 0, 0, 0.18818455934524536, 0, 0, 0, 0, 0, 0, 0, 0, 0.19347645342350006, 0, 0.22087770700454712, 0, 0.21496827900409698, 0.19613884389400482, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1634238362312317, 0, 0, 0, 0, 0, 0, 0, 0, 0.16398003697395325, 0, 0.19568683207035065, 0.274458646774292, 0.19926908612251282, 0, 0.2039562314748764, 0, 0, 0, 0, 0, 0, 0, 0.1908210963010788, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16841544210910797, 0, 0, 0.2793081998825073, 0, 0.16603520512580872, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19426433742046356, 0, 0, 0.2109447717666626, 0, 0, 0, 0, 0.16284170746803284, 0.18740208446979523, 0, 0, 0, 0.23771989345550537, 0.20991602540016174, 0, 0.16442719101905823, 0, 0, 0, 0, 0, 0, 0, 0.2018202543258667, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20609191060066223, 0, 0, 0.28681278228759766, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22113066911697388, 0.1924125701189041, 0, 0.21549218893051147, 0, 0, 0, 0, 0, 0.1891208291053772, 0, 0, 0, 0.22198668122291565, 0.17809896171092987, 0, 0.17677105963230133, 0, 0, 0, 0, 0, 0, 0, 0.20241892337799072, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19417613744735718, 0, 0, 0.25338757038116455, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18325969576835632, 0.158837229013443, 0, 0.19699615240097046, 0, 0, 0, 0, 0.17162726819515228, 0.2171589732170105, 0, 0, 0, 0.2211717665195465, 0.16302302479743958, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19284507632255554, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17189578711986542, 0, 0, 0.24428583681583405, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20395812392234802, 0.17988258600234985, 0, 0.17257986962795258, 0, 0, 0, 0, 0.17596715688705444, 0.2429569661617279, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21436581015586853, 0, 0.1778821349143982, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1829499900341034, 0, 0, 0, 0, 0.17640529572963715, 0, 0.1656646430492401, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16534271836280823, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1803857982158661, 0.17201845347881317, 0, 0.17617711424827576, 0, 0, 0, 0, 0, 0.21603533625602722, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21867738664150238, 0, 0.1871439814567566, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18001264333724976, 0, 0.17426253855228424, 0, 0.17648161947727203, 0], [0, 0, 0, 0, 0, 0.13575761020183563, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1356395184993744, 0, 0, 0, 0, 0, 0.20453110337257385, 0, 0, 0.14471612870693207, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.194238543510437, 0, 0.16204887628555298, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17422336339950562, 0, 0.1894925832748413, 0, 0, 0.177777960896492, 0, 0, 0, 0.1391659826040268, 0]]}