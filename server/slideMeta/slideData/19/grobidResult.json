{"authors": "Jay Henderson; Jeff Avery; Laurent Grisoni; Edward Lank", "pub_date": "", "title": "Leveraging Distal Vibrotactile Feedback for Target Acquisition", "abstract": "Many touch based interactions provide limited opportunities for direct tactile feedback; examples include multi-user touch displays, augmented reality based projections on passive surfaces, and mid-air input. In this paper, we consider distal feedback, through vibrotactile stimulation on a smart-watch placed on the user's non-dominant wrist, as an alternative feedback mechanism to interaction location vibrotactile feedback, under the user's finger. We compare the effectiveness of interaction location feedback vs. distal feedback through a Fitts's Law task completed on a smartphone. Results show that distal and interaction location feedback both reduce errors in target acquisition and exhibit statistically comparable performance, suggesting that distal vibrotactile feedback is a suitable alternative when interaction location feedback is not readily available.\u2022 Human-centered computing \u2192 User studies.", "sections": [{"heading": "INTRODUCTION", "text": "Displays are ubiquitous: we carry them with us in the form of smartphones and tablets, we find them in the environment in the form of public screens, and we project them into the air or on surfaces around us using augmented reality (AR) technology. The most common form of interaction with personal, public, and virtual display screens is some form of gesture -using either 2D touch or 3D motion to manipulate content. While there are several challenges with gestural interaction, the specific challenge we seek to address is feedback. When one touches a flat display (or gestures at a virtual screen) there is no physical sensation of widget interaction [5]. This lack of feedback is a known challenge on touchscreen displays, which a large body of research attempts to overcome by using haptic effects [6,18,19,22,26,36]. Similarly, commercial smartphones and tablets use vibration to communicate to the user that contact has been made with a target.\nWhether one uses vibration or some other form of haptic stimulation, the design of these feedback techniques makes two assumptions: first, the device has some sort of physical form (e.g. it is not a virtual projection as with augmented reality); and second, the device will be used by only a single user. Typical haptic effects such as electrostatic vibration [36], the squeeze film effect [7], or the use of the internal vibration motor on a mobile device all manipulate the entire display or the entire device. To localize effects, we determine the user's contact point and movement, what effect we wish to convey at that point, and time the generated haptic effect to coincide exactly with the user's position. While this is not a problem for single-user physical displays, it does not allow multiple users to interact simultaneously nor does it support feedback for virtual screens.\nWhile one can imagine engineering solutions to segment haptic displays [3] or to artificially stimulate fingers in midair [6,26], we wondered whether some other form of feedback, e.g. vibration, could be provided distally (on a location other than the interaction site), and whether that vibration feedback could then support target acquisition tasks. Given that smartphones use vibration to communicate target acquisition, could we leverage a convenience device like a smartwatch to provide feedback at another on-body location during interactions when interaction location feedback is impractical (e.g. when a display is shared or virtual)?\nIn this paper we explore the effectiveness of smartwatchbased feedback as an aid to target acquisition with the dominant hand. We do this by quantitatively assessing the performance of smartwatch-based vibration feedback during touchscreen interaction to under-finger vibration. This experiment demonstrates parity in performance between localized feedback -where the touchscreen device provides vibration -and distal feedback -where vibration is provided by the smartwatch. In essence, our results argue that, if vibrotactile feedback is desired but cannot be provided under the finger, that providing vibrotactile feedback via another mobile, personal device can effectively support interaction.", "n_publication_ref": 12, "n_figure_ref": 0}, {"heading": "RELATED WORK", "text": "Motivated by work by Cockburn and Brewster in multimodal feedback effects on targeting [9], many researchers have explored the various ways that tactile feedback can be used to enhance targeting performance. Levesque et al. [20] and Casiez et al. [7] demonstrated the advantages of surface friction with respect to targeting performance. More recent work by Zhang and Harrison [36] explored how best to render one category of tactile effect -electrovibration, where an alternating voltage varies the feeling of \"rubberiness\" of the surface -to maximally improve targeting performance.\nWhile many of these tactile effects have been explored in research systems, the most common form of tactile feedback employed on commercial smartphones is vibration [28]. Early research in this space explored how best to design hardware to support vibrotactile feedback [27,29], while more recent work has focused on the design of vibrotactile stimuli [17,28]. Current vibrotactile effects are provided by a small electrical motor with a slightly off-balance shaft. When vibration is desired, the motor spins the shaft, and the outof-balance mass causes a small vibration in the device. This type of vibration device is called an electrically rotating mass (ERM) component. Vibrotactile feedback on touch-screens has proven an effective method to reduce errors in targeting tasks, such as text input on PDAs or smartphones [4,14]. We know that targeting aids are important, particularly for acquisition of small targets: Hoggan et al. [14] noted frustration among users for touch-screen targeting as the user's finger may block the target from their field of view. When this happens, the user would have no visual indication if they are correctly hitting the target. This issue of occlusion is often attributed to the size of the user's finger, i.e. the fat finger problem [31].\nHowever, situations exist where under-finger or interaction location feedback is impractical for targeting tasks, such as virtual reality, augmented reality or multi-user scenarios. Solutions to these domains include haptic feedback on a wand [18] or stylus [10,19] on contact with a target, and vibration on a mobile phone when augmented reality targets come into view [1]. The drawback of techniques like these is they encumber the hand being used for interaction.\nTo avoid this problem, we we consider distal feedback as an alternative to interaction location feedback. There is some reason to believe that wrist-worn feedback on the arm associated with interaction [15] might provide benefits because, as the user makes contact with something, the wrist-based vibration will vibrate bones in the wrist and hand and transmit the vibrotactile effect to the point of interaction. Leveraging this idea of skeletal transmission, Maeda et al. [22] describe the design of wrist-worn vibration to enhance haptic effects during interaction, including enhancing interaction in virtual environments [23]. It is less clear whether vibrotactile effects that are more distantly separated from interaction are beneficial. In virtual or augmented reality, Kaul et al. [16] looked at adding haptic effects to a VR or AR headset to improve targeting and found that it was not particularly effective, while Richter et al. [30] examined various configurations of body-worn haptic feedback during typing tasks and found improved performance.\nWe are not the first to explore wrist-won tactile feedback: the evaluation of wrist-worn tactile feedback has been explored for typing on a touch tabletop with wrist-worn tactile output provided on the users input arm by McAdam and Brewster [24,25]. In this prior work, an actuator is attached using a tubegrip bandage to the same side of the body that is used for interaction. We extend this research with two key differences. First, we use an off-the-shelf smartwatch, a commodity device, rather than an actuator held in tight contact with the skin via a tubegrip bandage. Second, we administer feedback on the wrist of the non-dominant (typically noninteractive) hand (versus the dominant/interactive hand as in McAdam and Brewster) because the majority of people wear their watch on their non-dominant wrist [32]. Alongside the work of McAdam and Brewster, Tankana et al. [34] have explored distal feedback on a users non-dominant hand in the application of forceps manipulation for laparoscopic surgery, but their study is limited to finger-only feedback and they do not compare this to other feedback types -including forceps (proximal) feedback, or locations beyond fingers/a specialized haptic display. In summary, despite past work, it is unknown how vibrotactile feedback from a smartwatch worn on the wrist of the non-dominant hand would compare to interaction location vibrotactile feedback provided under a user's finger via vibration of a touch surface.\nResearchers have also explored the design of tactile feedback, but have found few benefits in targeting tasks [11,24].\nMcAdam and Brewster hypothesize that benefits of distal vibrotactile feedback may be reduced due to target size, since Fitts's Law shows that as target size increases, they become easier to acquire, i.e. if targets are large enough, tactile feedback may not be required [24]. Thus, we see benefit in studying a standard Fitts's law task, using more challenging targets to acquire, to further explore the distal feedback phenomenon.", "n_publication_ref": 29, "n_figure_ref": 0}, {"heading": "PILOT STUDY", "text": "One open question when designing vibrotactile feedback is the form that vibrotactile feedback should take. Should a device vibrate when the user enters the target, then stop, or should the device continue to vibrate continuously while a user is within the target? Inspired by past work Zhang et al. [36] on vibrotactile feedback, we conducted an initial pilot study to evaluate four different feedback conditions: no feedback, fill feedback, center feedback (where 1/4 of the target provided feedback to guide participants to the center of the target and reduce errors), and line leading edge feedback (see Figure 2). For the pilot study, participants performed a short Fitts's Law experiment [33] with three target sizes (3.8mm, 7.6mm and 12.6mm) and two different amplitudes (32mm and 64mm).\nThe specific devices used in our study were a Nexus 6P smartphone running Android 7.1.2 (14.5 cm display, 1440 by 2560 pixels at 518 dpi), and a Sony Smartwatch 3 running Android Wear 1.5.0.\nTo assess feedback, we conducted a semi-structured interview with participants after the pilot study, exploring which interaction techniques they preferred, and their impressions of vibrotactile feedback and the use of the watch for feedback. We also collected timing information. RM-ANOVAS indicated that there was no significant effect of condition on elapsed time (F 1.061,15.917 = 1.032, p = ns, \u03b7 2 = 0.00179), or condition on error rate (F 1.061,15.917 = 1.12, p = ns, \u03b7 2 = 0.00195). This analysis suggests that the techniques were comparable and error rates differed only marginally between techniques.\nWe also examined survey results to uncover user preferences. While we found that participants preferred vibrotactile feedback on the smartphone, the smartwatch was also highly rated in comments. In terms of the specific haptic feedback conditions, participants found the fill technique the easiest to use overall because it provided constant feedback when over the target (i.e. participants were not required to search for the actual target on the display).\nAlongside understanding how best to apply vibrotactile effects, one strongly positive result from our study is that participants highlighted no perceived difficulties in integrating distal watch feedback from the non-dominant arm with on-screen interaction. One participant noted that, as he interacted with small targets using the watch, he became convinced that we were also doing \"something with the phone too\" and, when re-assured that we were not, that the watch and phone were distinct, he noted that it was \"amazing how fast [we] re-wired [his] brain\" (to associate the distal feedback to an interaction location location). The promising results from this pilot study motivated a more complete study of smartwatch-based vibrotactile feedback.", "n_publication_ref": 2, "n_figure_ref": 1}, {"heading": "EXPERIMENTAL EVALUATION", "text": "We compare interaction location vibrotactile feedback (i.e. under the finger) to distal vibrotactile feedback (i.e. a smartwatch) with respect to target acquisition time, error rate, and user preference. We conducted a full-factorial, repeated measures experiment to assess the validity of using an distal vibrotactile feedback as a comparable technique to that of interaction location. The current section describes our experimental protocol, including participants, devices, dependent variables, procedure and data collected.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Participants", "text": "Sixteen participants volunteered for a 45 minute user study. Nine participants identified as female and seven identified as male, with ages ranging from 22 to 38 (mean = 24.94, standard deviation = 3.78). One participant preferred not to disclose their age. Three participants were left-handed and the remaining 13 were right-handed. All participants received a $10 remuneration for their participation.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Devices", "text": "Our experimental protocol required use of two mobile devices: a smartphone and a smartwatch. These are depicted in figure 3. The smartwatch was a Sony Smartwatch 3 with a Sony SWR510 Strap. The core unit's dimensions are 51 x 36 x 10mm, with a weight of 45g. The Smartphone was a Huawei Nexus 6P running vanilla Android OS version 7.1.2. The display measured 14.5cm with a resolution of 1440 by 2560 pixels, yielding a 518 dpi display. These were the same devices used in the pilot study.\nTo drive our experimental design, we implemented a version of the ISO 9241 Fitt's task that measured user finger position and provided Vibrotactile feedback. Input was captured on the touchscreen of the smartphone, and vibrotactile feedback was provided either by the smartphone itself or by the smartwatch using Eccentric Rotating Mass (ERM) vibration motors. To coordinate vibration with input, we connected the smartphone to the Smartwatch via Bluetooth.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Dependent Variables", "text": "Initially, we conceptualized our experiment as a having three vibrotactile feedback condiditons: feedback on the smartphone (interaction location), feedback on a smartwatch worn on the user's non-dominant wrist (distal), and a control condition (no feedback). We implemented our application and logging (described below) and ran the full experimental protocol. In this initial experiment, we found that the smartphone was slightly faster than the smartwatch, by about 30 to 50ms. We hypothesized that this delay might be due to transmission delays of the Bluetooth connection between smartphone and smartwatch during the distal condition. While the delay could reasonably be expected in distal vibrotactile feedback applications, we decided to add a fourth condition to the experiment (interaction location feedback with simulated Bluetooth delay). Even small delays in feedback can have significant impacts on performance, so adding Bluetooth delay to the smartphone allows us to account for this delay. Bluetooth delay was calculated as half of the round trip time for inter-device communication, approximately 39ms. We discarded the data from our initial experiment and reran our experiment with four factors.\nWith this change, our final experimental design included four vibrotactile feedback conditions: feedback on the smartphone (interaction location) with no delay, feedback on the smartphone with a 39ms delay (interaction location delay), feedback on a smartwatch worn on the user's non-dominant wrist (distal) and a control condition (no feedback).\nBased on pilot results, we utilized target fill for vibrotactile feedback. Our four feedback conditions were implemented as follows:\n\u2022 Interaction location feedback with no delay (C01): when the user correctly enters the target region, the phones vibration motor immediately activates and remains active until the user either lifts their finger or removes their finger from the region. This is typically the way that vibrationbased feedback works in modern interactive touchscreens. \u2022 Interaction location feedback with delay (C02): when the user correctly enters the target region, the phones vibration motor activates after the calculated delay time (39ms) and remains active until the user either lifts their finger or removes their finger from the target plus the delay time. \u2022 Distal feedback (C03): when the user correctly enters the target region a message is sent from the phone to the smartwatch to activate the watch vibration motor. This remains active until the user either lifts their finger or removes their finger from the region, at which time a message is sent to deactivate the vibration motor of the watch.\n\u2022 No feedback (C04): no vibration feedback occurs upon correct target acquisition.\nParticipants performed an ISO 9241 Fitts task [33] with six target widths (2cm, 1cm, 6.3mm, 3.2mm, 1.9mm, and 1.3mm) and six distances (18.2mm, 24.7mm, 31.2mm, 37.7mm, 49.4mm and 57.2mm.) in order to generate appropriate Fitts's curves. This yields 36 IDs ranging from 0.924 to 5.807.\nOur six distances were chosen based on the size of the smartphone screen and the constraints of the Fitts's Law task. Our rationale for target sizes was based on typical targeting tasks in smartphone interfaces. 2.0cm represents inter-icon spacing on a home screen, and 1.0cm represents the typical size of an icon on the display, given our smartphone's screen size. 6.3mm coincides with Android design guidelines for Figure 4: Rationale for target sizes. A typical application, like email, presents a range of target sizes: 1.9mm approximates the height of text; 1.3mm is the typical distance between words, useful in text selection; 3.2mm is the width of a character, for cursor navigation across a word; 6.3mm to 1.0cm approximates the width of widgets.\nminimum-size of finger targets [12] (approximately 7mm with a minimum of 1mm inter-target spacing). We also used a set of smaller targets, highlighted in Figure 4. Specifically, 3.2mm was used to represent smaller targets used in everyday interaction, such as keyboard buttons (normal range of 3-5mm). We also added two additional, very small targets: 1.9mm (approximate height of a text link before zoom) and 1.3mm (approximate inter-word spacing in a line of text, used when positioning a cursor). These sizes are both common with targeting tasks like browsing the web or editing an email message, and are often difficult to select.\nGiven that our goal is to contrast vibrotactile feedback both at the point of contact to feedback via a smartwatch worn distal, exploring a range of typical targeting tasks from the simple to the complex seemed appropriate. Figure 5 shows these target sizes in comparison to an index finger; we acknowledge that the smallest target sizes are often difficult to acquire, but, as we note above, there exist a class of relatively frequent targeting tasks (e.g. inserting a missing word or correcting wording in an email prior to sending) that require acquiring these small targets.", "n_publication_ref": 2, "n_figure_ref": 3}, {"heading": "Procedure", "text": "Participants were instructed to select a blue target with their index finger as the start position, then move their index finger from the blue target to the red target, and lift their finger once it is within the red target. There were a total of 5 circles within each targeting task. Text feedback in the top right hand corner of the display indicated whether or not a  user had successfully completed the targeting task. Figure 6 shows the application interface.\nThis was a within-participant design, where each participant was presented with all of the feedback conditions. Participants completed a practice block followed by two experimental blocks for each of the conditions. Order of conditions were varied: the Feedback condition was counterbalanced across participants using a 4x4 Latin Square Design. Target width and distance were randomly varied for each feedback condition within each experimental block.\nAfter the completion of each condition, participants were administered the NASA Task Load Index (TLX) [13] to assess weighted workload scores for each interface. Categories assessed as part of the NASA TLX are physical demand, mental demand, temporal demand, performance, effort and frustration [13]. Lastly, post experiment, participants were asked to rank the feedback techniques (smartphone, watch, or none) from most to least preferred.\nOverall, our experimental design yielded: 4 techniques \u00d7 6 widths \u00d7 6 distances \u00d7 5 targets \u00d7 2 blocks \u00d7 16 participants = 23,040 trials Measures Given that our experimental design is a standard Fitts's Law task, our dependent variables are time and error rate. We also collected the weighted NASA TLX ratings for each condition and ranking of feedback options.", "n_publication_ref": 2, "n_figure_ref": 1}, {"heading": "Hypotheses", "text": "We evaluate the following hypotheses during our experiment:\n[H1] Feedback improves targeting time compared to no feedback.\n[H2] Feedback lowers error rate compared to no feedback.\n[H3] Participants prefer feedback conditions over no feedback, and prefer phone feedback over watch feedback.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "RESULTS", "text": "We performed a repeated measures analysis of variance (RM-ANOVA) with time and error rate as dependent variables. Considering, first, time, Mauchly's test of sphericity indicated that the sphericity assumption was not violated for condition; however, it was violated for width (p < 0.01, \u03f5 = 0.358) and for distance (p < 0.01, \u03f5 = 0.212) with respect to time. Greenhouse-Geisser correction was applied to RM-ANOVA tests for width, distance, and interactions. RM-ANOVA indicates a main effect for distance (F 1.790,26.851 = 53.591, p < 0.001, \u03b7 2 = 0.781), width (F 1.061,15.917 = 18.136, p < 0.01, \u03b7 2 = 0.547) and feedback condition (F 3,45 = 3.686, p < 0.05, \u03b7 2 = 0.197) on time. There also exists significant interactions between all factors, with significantly higher time for small, distant targets. Distance and width effects are to be expected due to the increasing complexity of small distant targets versus of large close targets (i.e. Fitts's Law). Figure 7 depicts time versus ID for each of the conditions in our study. Post-hoc analysis using Fisher's LSD indicates that phone feedback with delay and watch feedback are slower than no feedback (p < 0.01), but do not differ from phone feedback without delay. Phone feedback without delay does not differ significantly from any other feedback condition. Phone feedback with delay and watch feedback do not differ significantly. Figure 7 depicts time versus ID for each of the conditions in our study.\nConsidering errors, Mauchly's test of sphericity indicated that the sphericity assumption was violated for width on errors (p < 0.05, \u03f5 = 0.344); Greenhouse-Geisser correction was applied. RM-ANOVA indicates a main effect for width (F 1.720,25.799 = 18.136, p < 0.05, \u03b7 2 = 0.966) and feedback condition (F 1.999,29.983 = 5.975, p < 0.01, \u03b7 2 = 0.285) on error rate (but not distance). Interactions are also significant, with higher error rate for small targets, an expected result. Figure 8 depicts the effect of feedback condition on error rate at each target width. Post-hoc analysis using Fisher's LSD indicates that no feedback differs significantly from phone feedback with delay and watch feedback (p < 0.01). No feedback has higher error. However, phone and watch feedback do not vary significantly from each other. Figure 8 depicts the effect of feedback condition on error rate at each target width.", "n_publication_ref": 0, "n_figure_ref": 4}, {"heading": "NASA Task Load Index", "text": "Recall that after each condition was complete, we asked participants to complete the six category NASA Task Load Index [13]. According to Mauchly's test of sphericity, the Mental Demand category violated sphericity (p < 0.05, \u03f5 = 0.622); Greenhouse-Geisser correction was applied. An RM-ANOVA analysis indicated that the Mental Demand category displayed significant results across conditions (F 3,45 = 6.193, p < 0.01). Particularly a significantly higher mental demand was shown for the no feedback condition as opposed to the remaining three conditions. The remaining NASA TLX categories (Physical Demand, Temporal Demand, Performance, Frustration, Effort) [13] showed no significance.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "Participant Preference", "text": "Finally, we examine user preference for techniques. Overall, when asked to rank techniques, 9 participants selected phone feedback as their preferred condition and 4 participants selected watch feedback. 14 out of 16 participants preferred receiving vibrotactile feedback over no feedback. The one participant who chose no feedback first noted: \"I chose no feedback first because I was more frustrated when I got the incorrect result [when selecting very small targets] with feedback\".", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "DISCUSSION", "text": "Overall, a straightforward interpretation of these results is as follows:\n\u2022 H1 posited that feedback would reduce targeting time.\nHowever, we find that targeting time increases in two feedback conditions (Phone with delay and watch) versus the no feedback condition. Despite the fact that this appears due to Bluetooth delay, because feedback conditions are never statistically faster than no feedback, H1 is not supported. \u2022 H2 posited that feedback would reduce errors. We find that feedback does reduce errors; therefore H2 is supported. \u2022 H3 posited that participants would prefer feedback over no feedback and phone feedback over watch feedback. Given our user preferences, we find that H3 is supported.\nIn Fitts's Law tasks, performance is a function of the speed accuracy trade-off. Specifically, hitting smaller targets requires higher accuracy; hence, interaction times are longer [21]. Furthermore, even within Fitts's law tasks, a bias toward speed or accuracy can measurably impact performance [2,21]. Examining the above hypotheses, the overall effect of feedback is to bias response [2]. Participants were slower  but more accurate when feedback guided them to more accurate target acquisition. The results suggest that feedback encourages slower, more precise movements.\nThe larger research question that this paper explores, however, is whether smartwatch feedback can serve as a proxy for under finger-feedback, particularly in situations (projected or multi-user displays) when under-finger feedback is not available or inconvenient. Our results provide evidence that phone feedback and watch feedback have similar performance characteristics, in terms of time and error rate. This, in turn, argues that smartwatch feedback is an effective alternative to interaction location feedback. In particular, we find no significant difference between watch and phone with and without delay in time and error rate. In fact, qualitatively we note that, while watch feedback is slower on average than phone feedback, watch feedback also has the lowest error rate. The primary difference between under-finger feedback and smartwatch feedback appears to be Bluetooth delay, due to the similarity between under-finger feedback with delay and smartwatch feedback, but this delay does not result in significant differences in timing. Adding Bluetooth delay, performance converges to virtually identical times for phone and watch.", "n_publication_ref": 4, "n_figure_ref": 0}, {"heading": "Synthesis of Time and Errors: An Outline of Future Work", "text": "One unexpected result from H1 is the observation that feedback slows targeting tasks. While this slowing may be due to Bluetooth delay, our expectation was that feedback would speed targeting. In this section, we will more carefully examine variations in user performance, particularly with respect to time and error, to fully clarify the effects of error and provide guidance for future research.\nTo more fully probe the increased time associated with feedback conditions, we examine an interaction effect that exists between feedback condition and target width. Figure 9 shows time per condition per width. Here, we can clearly see the Bluetooth delay slowing interaction, with both phone with delay and smartwatch conditions taking more time than the phone condition without delay and the no feedback condition. In Figure 9, for target sizes of 2cm and 1cm, we see similar performance across conditions. This is because targeting can be verified visually, i.e. the target is visible during interaction. For target sizes of 6.3mm and 3.2mm, the phone condition without delay (red bar) versus the no Feedback condition (gray bar) remain identical in timing; the watch conditions and phone with delay conditions are also similar in time, but slightly delayed, a result of about 40ms of Bluetooth delay. Finally, for smaller targets of 1.9mm and 1.3mm, we see significantly slower performance for feedback conditions than for the no feedback condition.\nWe can consider target sizes of 2cm, 1cm, 6.3mm, and 3.2mm to be typical target sizes in interfaces as they represent common widgets such as icons, buttons, and keyboards. Returning to Figure 7, we plot Fitts's Law curves using these typical target sizes (down to 3.2mm). Table 10 shows the Fitts's parameters for each of these lines. Recall that feedback seemed to slow interaction. However, for typical target sizes -down to 3.2mm -it seems that feedback does not harm performance. Phone feedback without delay is virtually identical in time to no feedback. Its sole effect is to improve error rate, particularly for the 3.2mm target (see Figure 8).  The 1.9mm targets and 1.3mm targets are exceptional targets, i.e. small, very difficult targets, where there is very limited visual feedback. There is some question as to whether it is even reasonable to include these targets in a targeting experiment. Our rationale was to include them simply because we do see these targeting tasks in interfaces, particularly when resolution is high and displays are small or packed with widgets. Alongside email editing, mentioned earlier, if one uses a standard web interface on a smartphone or one uses a mobile remote desktop application, widgets are sized for pixels significantly different in scale to the tightly packed pixels on a typical phone screen.", "n_publication_ref": 0, "n_figure_ref": 4}, {"heading": "Condition", "text": "In these exceptional targeting tasks, the Fitts's curves on Figure 7 are instructive. Recall that these curves omit these targets when drawing the best-fit line. We do this because of Figure 9, where we see performance vary with these targets, and also because of Figure 8, where we see very high error rates. In the No Feedback condition, Figure 7d, the 1.3mm and 1.9mm target times are all under the Fitts's Law curve, whereas in every other condition they are all, without exception, over the curve. We see a similar effect in Figure 9: 3.2mm, 1.9mm, and 1.3mm targets have very similar times in the no feedback condition.\nLet us perform a simple mental experiment: assume that, all other things being equal, any average time versus ID point is normally distributed around the Fitts's Law curve with its mean centred on the curve. This is standard Fitts's Law behaviour [8]: For any given point in a best-fit line, there is a 50-50 chance that a randomly chosen point will be above the line or below the line, with its expected location centred on the line. What is the likelihood, as observed in Figure 7, that all points for 1.3mm and 1.9mm target points are below the line in Figure 7d (control condition) and all 1.3mm and 1.9mm target points are above the line in each experimental condition? The answer, if we perform a mathematical equivalent such that we assume over in experimental conditions is equivalent to under in the control condition, is exactly p = 1 2 48 , or about 1 in 256 trillion. Clearly, it is reasonable to seek an alternative explanation -i.e. to explore whether something changes participants' behaviour on small targets with feedback versus in the control condition.\nOne reasonable explanation, posited here as potential future work, is to ask the question what if, instead, behaviour were different when feedback was present and targeting was difficult? For example, if the user simply gave up, realizing the targeting task was too difficult, and did not even particularly try to acquire small targets for the control condition, then the speed accuracy condition in control would break down and all points would be below the Fitts's line. If, in vibrotactile conditions, the user, instead, assumed that they could complete the difficult task, then they might feel around, subtly try to position their finger, then recognize that the task was extremely hard and that their error rate was high, but that interaction was still possible. Thus, again, Fitts's law might partially break down, but in the opposite way: because of errors, the participants would be biased toward being more careful and points would exist above the line [35].\nAn additional issue to explore is whether vibrotactile feedback is worthwhile at all for typical targeting tasks. If we examine Figure 8, one thing that is clear is that the effect of feedback on error rate is marginal for targets larger than 6.3mm in size. This is undoubtedly because visual feedback is sufficient to ensure contact with target, a result previously hypothesized by McAdam and Brewster [24]. However, does this mean that vibrotactile feedback, where the phone vibrates when buttons are pressed, is to be avoided? We would argue that it does not. While there is no temporal or error rate advantage to vibrotactile feedback for these conditions, there is also no penalty. Furthermore, it does provide the user with confidence, during interaction, that the button was acquired and pressed, potentially allowing them to go on to the next task without awaiting on-screen confirmation. Due to the density of on-screen widgets in feature-rich smartphone applications, and to its ability to provide non-visual confirmation, we feel there exists a value to feedback that extends beyond raw time and error-rate values.\nThis paper focused primarily on one type of distal vibrotactile feedback, provided by a smartwatch worn on the nondominant hand during dominant-hand interaction. Clearly a myriad of other distal vibration devices can be conceptualized: users could hold their phone in their non-preferred hand while interacting; users could wear their smartwatch on their dominant hand such that the vibration would be closer to the locus of interaction; we could design custom jewelry such as a wristband, ring, earring, necklace, or even use a piece of clothing; the device could be in the user's pocket instead of in their hand; we could build complex external hardware that would make the air vibrate at an arbitrary location. While there is merit in testing many variants of vibrotactile feedback, evaluation of the efficacy of an everyday device, a smartwatch, worn in it's typical fashion, to support vibrotactile feedback for dominant-hand touch interactions is a valuable and logical first step in the exploration of these alternatives with respect to time, error, and user preference.\nAlongside additional contact locations, another avenue of future work could explore distal vibrotactile feedback in multi-user scenarios. Multi-user scenarios are a strong motivational factor for distal feedback because, when multiple users interact with a single screen, it becomes challenging to vibrate only a portion of the screen under a single user's finger. Furthermore, when multiple users -beyond two, for example -all interact simultaneously, the need, to selectively provide tailored feedback for a subset of users further exacerbates hardware design challenges. Extending our exploration to this multi-user interaction is a clear next step.", "n_publication_ref": 3, "n_figure_ref": 8}, {"heading": "CONCLUSION", "text": "Current vibrotactile hardware, while effective in providing simple feedback, cannot typically handle multi-user scenarios nor projected display scenarios (particularly when the projected surface is an inanimate artifact such as a wall or an artificial surface as in augmented or virtual reality). In these situations, it makes sense to leverage other existing devices that can offer vibrotactile feedback. Smartwatches, in particular, seem well-positioned to support interaction; they are readily available, and, without repositioning or grasping, can immediately be used to interact with external computation such that vibrotactile feedback from the watch can be used as a proxy for under-finger feedback.\nOur experiment demonstrates that the effects of distal feedback provided by the smartwatch are virtually identical to interaction location feedback on the touchscreen -particularly once Bluetooth delay is incorporated into the feedback. These results -in particular, the fact that distal feedback reduces error rate compared to know feedback as effectively as under-finger feedback -demonstrate that distal vibrotactile feedback can be an effective proxy for interaction location feedback.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "ACKNOWLEDGEMENTS", "text": "The researchers thank all participants in our studies. Funding for this research was provided by the Natural Science and Engineering Research Council of Canada's Discovery Grants Program and by the region Hauts-de-France.", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "Augmented Reality Target Finding Based on Tactile Cues", "journal": "ACM", "year": "2009", "authors": "Vuokko Tuulikki Teemu Tuomas Ahmaniemi;  Lantz"}, {"title": "Biasing Response in Fitts' Law Tasks", "journal": "ACM", "year": "2006", "authors": "Emory Al; -Imam ; Edward Lank"}, {"title": "Tesla-Touch: Electrovibration for Touch Surfaces", "journal": "", "year": "2010", "authors": "Olivier Bau; Ivan Poupyrev; Ali Israr; Chris Harrison"}, {"title": "Annual ACM Symposium on User Interface Software and Technology (UIST '10)", "journal": "ACM", "year": "", "authors": ""}, {"title": "Tactile Feedback for Mobile Interactions", "journal": "ACM", "year": "2007", "authors": "Stephen Brewster; Faraz Chohan; Lorna Brown"}, {"title": "Issues and Techniques in Touch-sensitive Tablet Input", "journal": "ACM", "year": "1985", "authors": "William Buxton; Ralph Hill; Peter Rowley"}, {"title": "UltraHaptics: Multi-point Mid-air Haptic Feedback for Touch Surfaces", "journal": "ACM", "year": "2013", "authors": "Tom Carter; Sue Ann Seah; Benjamin Long; Bruce Drinkwater; Sriram Subramanian"}, {"title": "Surfpad: Riding Towards Targets on a Squeeze Film Effect", "journal": "ACM", "year": "2011", "authors": "G\u00e9ry Casiez; Nicolas Roussel; Romuald Vanbelleghem; Fr\u00e9d\u00e9ric Giraud"}, {"title": "Fitts' Law in the Wild: A Field Study of Aimed Movements", "journal": "", "year": "2007", "authors": "Olivier Chapuis; Renaud Blanch; Michel Beaudouin-Lafon"}, {"title": "Multimodal feedback for the acquisition of small targets", "journal": "Ergonomics", "year": "2005", "authors": "Andy Cockburn; Stephen Brewster"}, {"title": "Indirect Stylus Input in Pointing and Crossing Selection Tasks", "journal": "ACM", "year": "2008", "authors": "Clifton Forlines; Ravin Balakrishnan"}, {"title": "Tactile Feedback for Above-Device Gesture Interfaces: Adding Touch to Touchless Interactions", "journal": "ACM", "year": "2014", "authors": "Euan Freeman; Stephen Brewster; Vuokko Lantz"}, {"title": "", "journal": "Android API Guide", "year": "2017-02", "authors": "Open Google;  Handset Alliance"}, {"title": "Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research", "journal": "Elsevier", "year": "1988", "authors": "G Sandra; Lowell E Hart;  Staveland"}, {"title": "Investigating the Effectiveness of Tactile Feedback for Mobile Touchscreens", "journal": "ACM", "year": "2008", "authors": "Eve Hoggan; Stephen A Brewster; Jody Johnston"}, {"title": "Vibrotactile Experiences for Augmented Reality", "journal": "ACM", "year": "2016", "authors": "Wolfgang H\u00fcrst; Nina Rosa; Jean-Paul Van Bommel"}, {"title": "HapticHead: 3D Guidance and Target Acquisition Through a Vibrotactile Grid", "journal": "ACM", "year": "2016", "authors": "Kaul Oliver Beren; Michael Rohs"}, {"title": "Feel-good Touch: Finding the Most Pleasant Tactile Feedback for a Mobile Touch Screen Button", "journal": "ACM", "year": "2008", "authors": "Emilia Koskinen; Topi Kaaresoja; Pauli Laitinen"}, {"title": "Haptic Feedback in Remote Pointing", "journal": "ACM", "year": "2009", "authors": "Laurens R Krol; Dzmitry Aliakseyeu; Sriram Subramanian"}, {"title": "Haptic Pen: A Tactile Feedback Stylus for Touch Screens", "journal": "ACM", "year": "2004", "authors": "Johnny C Lee; Paul H Dietz; Darren Leigh; William S Yerazunis; Scott E Hudson"}, {"title": "Enhancing Physicality in Touch Interaction with Programmable Friction", "journal": "ACM", "year": "2011", "authors": "Vincent Levesque; Louise Oram; Karon Maclean; Andy Cockburn; Nicholas D Marchuk; Dan Johnson; J Edward Colgate; Michael A Peshkin"}, {"title": "A Note on the Information-Theoretic Basis for Fitts", "journal": "Law. Journal of Motor Behavior", "year": "1989", "authors": "I ; Scott Mackenzie"}, {"title": "HapticAid: Wearable Haptic Augmentation System for Enhanced, Enchanted and Empathised Haptic Experiences", "journal": "", "year": "2016", "authors": "Tomosuke Maeda; Roshan Peiris; Nakatani Masashi; Yoshihiro Tanaka; Kouta Minamizawa"}, {"title": "", "journal": "ACM", "year": "", "authors": ""}, {"title": "Wearable Haptic Augmentation System Using Skin Vibration Sensor", "journal": "ACM", "year": "2016", "authors": "Tomosuke Maeda; Roshan Peiris; Masashi Nakatani; Yoshihiro Tanaka; Kouta Minamizawa"}, {"title": "Distal Tactile Feedback for Text Entry on Tabletop Computers", "journal": "British Computer Society", "year": "2009", "authors": "Christopher Mcadam; Stephen Brewster"}, {"title": "Mobile Phones As a Tactile Display for Tabletop Typing", "journal": "", "year": "2011", "authors": "Christopher Mcadam; Stephen Brewster"}, {"title": "", "journal": "ACM", "year": "", "authors": ""}, {"title": "HaptoMime: Midair Haptic Interaction with a Floating Virtual Screen", "journal": "ACM", "year": "2014", "authors": "Yasuaki Monnai; Keisuke Hasegawa; Masahiro Fujiwara; Kazuma Yoshino; Seki Inoue; Hiroyuki Shinoda"}, {"title": "Tactile Virtual Buttons for Mobile Devices", "journal": "ACM", "year": "2003", "authors": "Andrew Nashel; Sharif Razzaque"}, {"title": "Tactile Effect Design and Evaluation for Virtual Buttons on a Mobile Device Touchscreen", "journal": "ACM", "year": "2011", "authors": "Gunhyuk Park; Seungmoon Choi; Kyunghun Hwang; Sunwook Kim; Jaecheon Sa; Moonchae Joung"}, {"title": "", "journal": "", "year": "", "authors": "N Y York;  Usa"}, {"title": "Tactile Interfaces for Small Touch Screens", "journal": "ACM", "year": "2003", "authors": "Ivan Poupyrev; Shigeaki Maruyama"}, {"title": "Comparing direct and remote tactile feedback on interactive surfaces", "journal": "Springer", "year": "2012", "authors": "Hendrik Richter; Sebastian Loehmann; Florian Weinhart; Andreas Butz"}, {"title": "High Precision Touchscreens: Design Strategies and Comparisons with a Mouse", "journal": "Int. J. Man-Mach. Stud", "year": "1991-04", "authors": "Andrew Sears; Ben Shneiderman"}, {"title": "Pointing at a Distance with Everyday Smart Devices", "journal": "ACM", "year": "2018", "authors": "Shaishav Siddhpuria; Sylvain Malacria; Mathieu Nancel; Edward Lank"}, {"title": "Towards a standard for pointing device evaluation, perspectives on 27 years of Fitts' law research in HCI", "journal": "International journal of human-computer studies", "year": "2004", "authors": "William Soukoreff;  Scott Mackenzie"}, {"title": "Tactile sensing system including bidirectionality and enhancement of haptic perception by tactile feedback to distant part", "journal": "", "year": "2013", "authors": "Y Tanaka; T Nagai; M Sakaguchi; M Fujiwara; A Sano"}, {"title": "Speed-accuracy tradeoff in Fitts' law tasks on the equivalency of actual and nominal pointing precision", "journal": "International Journal of Human-Computer Studies", "year": "2004", "authors": "Shumin Zhai; Jing Kong; Xiangshi Ren"}, {"title": "law 50 years later: applications and contributions from humancomputer interaction", "journal": "", "year": "", "authors": " Fitts"}, {"title": "Quantifying the Targeting Performance Benefit of Electrostatic Haptic Feedback on Touchscreens", "journal": "ACM", "year": "2015", "authors": "Yang Zhang; Chris Harrison"}], "figures": [{"figure_label": "2", "figure_type": "", "figure_id": "fig_0", "figure_caption": "Figure 2 :2Figure 2: Feedback conditions: (1) fill feedback, (2) center feedback, (3) line leading edge feedback, (4) no feedback (blue colouring denotes feedback area).", "figure_data": ""}, {"figure_label": "3", "figure_type": "", "figure_id": "fig_1", "figure_caption": "Figure 3 :3Figure 3: Devices used for the experiment: Sony Smartwatch 3 (left), Huawei Nexus 6P (right), Sony SWR510 Strap (top).", "figure_data": ""}, {"figure_label": "5", "figure_type": "", "figure_id": "fig_2", "figure_caption": "Figure 5 :5Figure 5: Target widths used in the experimental protocol.", "figure_data": ""}, {"figure_label": "6", "figure_type": "", "figure_id": "fig_3", "figure_caption": "Figure 6 :6Figure 6: Samples of the Fitts Law ISO Task on a Smartphone Interface", "figure_data": ""}, {"figure_label": "7", "figure_type": "", "figure_id": "fig_4", "figure_caption": "(Figure 7 :7Figure 7: Scatterplots of average time to select a target by Fitts's IDs for each condition.", "figure_data": ""}, {"figure_label": "8", "figure_type": "", "figure_id": "fig_5", "figure_caption": "Figure 8 :8Figure 8: Error rates across target sizes for each condition.", "figure_data": ""}, {"figure_label": "9", "figure_type": "", "figure_id": "fig_6", "figure_caption": "Figure 9 :9Figure 9: Time for individual target sizes for each condition.", "figure_data": ""}, {"figure_label": "10", "figure_type": "", "figure_id": "fig_7", "figure_caption": "Figure 10 :10Figure 10: Fitts's parameters for typical targets (above 3.2mm in size).", "figure_data": ""}], "doi": "10.1145/3290605.3300715"}