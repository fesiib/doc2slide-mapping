{"authors": "Xuhai Xu; Chun Yu; Anind K Dey; Jennifer 2019 Mankoff;  Clench", "pub_date": "", "title": "Clench Interface: Novel Biting Input Techniques", "abstract": "People eat every day and biting is one of the most fundamental and natural actions that they perform on a daily basis. Existing work has explored tooth click location and jaw movement as input techniques, however clenching has the potential to add control to this input channel. We propose clench interaction that leverages clenching as an actively controlled physiological signal that can facilitate interactions. We conducted a user study to investigate users' ability to control their clench force. We found that users can easily discriminate three force levels, and that they can quickly confirm actions by unclenching (quick release). We developed a design space for clench interaction based on the results and investigated the usability of the clench interface. Participants preferred the clench over baselines and indicated a willingness to use clench-based interactions. This novel technique can provide an additional input method in cases where users' eyes or hands are busy, augment immersive experiences such as virtual/augmented reality, and assist individuals with disabilities.\u2022 Human-centered computing Interaction paradigms; Gestural input; Activity centered design.", "sections": [{"heading": "INTRODUCTION", "text": "Modern ubiquitous interaction is increasingly being enriched by hands-free and eyes-free input from areas such as the face [3,13], breath [27,29], feet [20] and mouth [4,26,28]. In this paper, we contribute to that literature by expanding the expressiveness of mouth, specifically clenching.\nWe eat every day. Biting is one of the most common and fundamental actions that we perform on a daily basis. Biting can be useful in situations where a user's hands or eyes (or both) are busy, for augmenting immersive user experiences such as virtual and augmented reality (VR/AR), and for individuals with disabilities. For example, users can easily answer a phone call or control a music player when riding a bike. In addition to hands-and eyes-free properties, there are a number of reasons to leverage biting: it is common and natural hence it requires little training; it is subtle and therefore minimally distracting.\nResearchers have begun to develop mouth-based interactions, including tongue-based interfaces [28] and tooth-click interfaces [4,40]. However, although tongue has been used for pointing [13,26], and tooth clicking has been used for list selection and typing [4], there is value in exploring techniques for combining a range of spatio-temporal signals to support richer interactions, such as force and mouth region. In addition, a design space for interaction with the teeth needs to be developed.\nIn this paper, we propose to use jaw clenching to create a jaw-based interface and explore a design space for clench input, which we define as a subset of biting in which the jaw is closed, but the force of pressure of the teeth against each other is changed. Jaw clenching is ideal for interaction because it can have many dimensions: force, length of time and location. The clench action is also subtle and low-impact, simply involving a squeezing of the jaw together. Clenching can support rich interactions since it can have multiple dimensions.\nKnowing how well users can control their clench force is fundamental for clench interaction design. We conducted a user study with a clench-controlled target acquisition task to evaluate users' clench control ability. We compared different numbers of clenching force levels (N = 3, 4, 6 and 8) and three confirmation techniques (Quick Release, Time Dwell and Button Click). Our results show that users can easily discriminate N = 3 clench force levels and Quick Release outperforms other confirmation techniques.\nWe then developed three-dimensional design space (Force Level, Time and Location) for clench interactions. We deployed a survey to get user feedback on the design space and found the six clench actions in the design space most preferred by participants. We propose semantic interaction associations for the six clench actions and devise three interaction patterns for clench actions: clench gestures for discrete command input, clench for value control and clench integrated with other interactions.\nWe evaluated the usability of clench interaction from two perspectives. A second user study was conducted to measure the performance of the best six clench actions in virtual reality (VR). We also conducted a third user study to evaluate the usability of clench interaction in a situation close to a real use case, bicycling, where users' hands and eyes are busy (as an example of both discrete command input and value control patterns). Clench interaction is faster than baselines in most cases in both studies, and participants stated a willingness to use clench as a novel input technique since it can be performed easily and conveniently.\nWe use an in-mouth pressure sensor to obtain direct and accurate real-time clench force measurements, which we designed to maximize the realism by keeping the sensor thickness to 1.50mm. We measure isometric clenching with molar teeth, i.e., teeth and jaw do not move during interactions and the only variation is given by clench force (see Figure 1). While this sensor serves our goal of developing a robust design space for clench interaction, a deployable implementation can easily use other sensors based on our study results, which help to define parameters for design. For example, electromyography (EMG) is a viable alternative if force accuracy is unimportant (as is indicated by our design space survey), since there is a strong linear relationship between clench force and EMG signal on temporalis [5,10]. And the positions of temporalis are compatible with modern devices such as VR/AR headsets and smart glasses.\nOur contributions in this paper are threefold:\n\u2022 We proposed a novel approach to isometric clench interaction that leverages a clench on occlusal surfaces (see Figure 1) as a new input technique.\n\u2022 We conducted a user study to demonstrate users' ability to control clench force.\n\u2022 We developed a design space for clench interaction and conducted two user studies that illustrated the high usability of the clench interaction.", "n_publication_ref": 16, "n_figure_ref": 2}, {"heading": "RELATED WORK", "text": "We now review and summarize the related literature, focusing on face-related interaction, clench force measurement and clench detection in the wild.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Interaction with The Face", "text": "There have been a variety of interaction techniques designed that leverage the face. For example, Salem and Zhai [26] proposed to use the tongue for isometric pointing tasks. Cheng et al. [9] proposed to detect whether a user applied pressure to the cheek using the tongue, as a gesture for hands-free interaction. Goel et al. [13] further expanded the input bandwidth by measuring different positions on one's face touched by the tongue that support richer interactive tongue gestures. Sahni and Bedri et al. [6,25] measured the movement of a small magnet glued to one's tongue and deformation in the ear canal caused by jaw movement to support a silent speech interface. Facial expression is another input modality that has been investigated extensively. Lyons et al. proposed to use facial expressions as gestures for controlling a musical interface [18], and used mouth movement recognized by a camera to augment text-entry [17]. Ando et al. [2,3] proposed to employ face-related movements as part of a hands-free music player and content reader. Much less work has focused on employing teeth as an input modality [4]. The tooth-click interface, developed as an assistive technology, is closely related to our work. Both Kuzume [15] and Zhong et al. [40] used an in-ear bone-conduction microphone to detect tooth click sounds as an additional input technique. Ashbrook et al. [4] investigated the click sounds of five different pairs of teeth to expand input bandwidth. A number of previous works used tooth-click for interactions such as selection [22,40], confirmation [15,39] and mode switch [28] with a single and/or double click. However, such an interface mainly relies on a instantaneous tooth click. It cannot leverage information such as clenching force, or sustained clench actions, etc. Clench interaction extends the input space along these dimensions.", "n_publication_ref": 18, "n_figure_ref": 0}, {"heading": "Bite Force Measurement", "text": "Humans use different muscles for biting and chewing in different situations [14], leading to different properties; e.g., the maximum force varies greatly in different directions. The traditional instrument for directly measuring bite clench force is called a gnathodynamometer [19,34]. In addition, there is some research that has studied the relationship between clench force and EMG signals on masseter and temporal anterior muscles of the face. Bakke et al. [5] found a strong linear correlation (p < 0.05, r = 0.98-0.99) between bite force and unilateral masseter or temporal muscle activity within the range of 12.5 to 87.5% of maximal unilateral bite force at eight sample points. The linear correlation becomes weaker when the bite force approaches the maximum. Bilt et al. [32] found the correlation between maximum voluntary bite force and total muscle activity ranged between 0.54 to 0.57. However, in previous research, all the devices were either on the outside of the face and quite inaccurate for continuous bite force measurement, or were in between the top and bottom teeth and had non-negligible height, mostly around 8 to 10 mm [5,10,32,36].\nThis vertical height during biting can greatly affect muscular activity [19] and a gnathodynamometer is too thick for practical usage. Ideally the height should be nearly zero and close to the neutral condition of the mouth and teeth. This is a big reason to clenching, which is a subset of biting that involves pressing the teeth together with minimal jaw movements.\nMoreover, whether in or out of the mouth, none of the previous work has explored the human ability to control bite force except maximum bite force [32] and bite duration [31]. In this work, we investigated users' ability to use clenching, to control clench force, and further proposed a set of clench interaction techniques that extend even beyond this clench force dimension.", "n_publication_ref": 12, "n_figure_ref": 0}, {"heading": "Clench Detection in The Wild", "text": "Eating detection, which mainly involves chewing, biting and clenching, has been investigated in previous research. A number of methods have been proposed to detect jaw movement and mastication, such as acoustic sensors [1,21,23], inertial sensors [35], piezoelectric sensors [33] and proximity sensors [7,16]. In addition, another common detection method is based on EMG signals. Zhang et al. designed 3-D printed glasses to detect chewing with EMG sensors placed near the temporal anterior muscles to detect muscular activity, and acceleration sensors to detect bone vibration [37]. They used their glasses for eating detection and achieved an F1 score of 0.770 with naturalistic data [38]. Blechert et al. [8] placed electrodes on a line between the mastoid and the masseter muscle to collect EMG signals and achieved an F1 score of 0.871 with in-the-wild data.\nThese works show the potential for using EMG signals for multi-force-level clench interaction in the wild, especially as the detection of clenching/chewing can be easily distinguished from other physical actions such as speaking, walking, and drinking [8,35,38]. Although we employed a pressure sensor in the mouth instead of EMG sensors to obtain an accurate measurement of clench force, we envision that an unobtrusive measuring system will not be an issue in the future.", "n_publication_ref": 13, "n_figure_ref": 0}, {"heading": "USER STUDY 1: CLENCH FORCE CONTROL", "text": "We will now describe our first study, whose objective is to investigate human ability to control clench force for a basic discrete selection task with different degrees of visual feedback. The results of this study can guide clench interaction designs, such as the percentage of maximum force to be used for interaction, the number of levels of force that a user can easily distinguish, etc. We also compare three methods to find the best confirmation method for clench-based selection, since it is a fundamental aspect of any selection-based task.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Task", "text": "A serial target acquisition and confirmation task was used to investigate the users' ability to control their clench force. [24]. Based on the users' sensed clench force, the cursor moved vertically on the screen, through regions. The number of regions was determined by the number of force levels being tested. If the user was able to confirm their selection while the cursor was in a specified region for a given trial, the trial was considered a success.\nClench force was uniformly mapped to its vertical distance after calibration for each user. The study included three different confirmation techniques and two visual feedback conditions. Before each trial, the user was asked to release the clench force and return to a neutral state.\nConfirmation techniques: We investigated three confirmation techniques, which are used after the cursor is in the intended region. Button Click (BC): pressing a button on the keyboard; Dwell (DW ): maintaining the cursor in the target region for 1s; and Quick Release (QR): quickly releasing the clench and moving the cursor below the pressure threshold (see Fig. 2). 300 ms was empirically chosen as the temporal  Colored area indicate targets to be reached. Two independent variables are reflected: 1) Force Levels. N is the number of levels; H is the corresponding height of a target; 2) Target Positions. D is the distance of some place in the target to the starting threshold, which implies the target to be reached in a trial.\nthreshold to recognize a \"quick\" release. The starting point of the releasing procedure indicates the selected position.\nVisual feedback conditions: There were two visual feedback conditions in our study. In the Full Feedback condition (FF), regions are drawn on screen using black boxes, with the specified region for a trial in grey (see Figure 2). Correct cursor location is indicated by turning the specified region green. In the Partial Feedback condition (PF), only the specified region is visible. There is no other regions for reference. The cursor will disappear once it moves across the threshold (the dotted line, see the right half of Figure 2).", "n_publication_ref": 1, "n_figure_ref": 3}, {"heading": "Design and Procedure", "text": "We employed a within-subjects full factorial design with repeated measures. Four independent variables were included: visual feedback condition (FF, PF), selection method (BC, DW, QR), the distance from the starting threshold to the target (D = 120, 305, 490, in pixel units, 576 is the maximum) and the number of clench force levels (N = 3, 4, 6, 8, corresponding target's height H, are 192, 144, 96 and 72 in pixel units). We choose between 3 and 8 based on a pilot study involving three lab members. We found that 2 levels are very naive to distinguish and two is a limited number if we want to support rich interactions, while 10 levels are extremely difficult. In both feedback conditions, we used a Latin square to balance the appearance order of the selection method. D and N appeared in a randomized order. Participants repeated each condition three times.\nIn order to have a balanced experiment, we took special cares when choosing D and H to appropriately distribute targets throughout the potential target space [24]. Figure 3 shows that D defines the target for a trial and indicates some location in the targets rather than the center of the target.", "n_publication_ref": 1, "n_figure_ref": 1}, {"heading": "Calibration.", "text": "Since clench force varies across people and clenching positions, calibration is needed every time users put the sensor into the mouth. Relative clench force indicates the extent of how hard a user clenches. At the beginning of each session, participants went through a calibration stage: a two-second relaxation to collect baseline and one isometric clench with the largest force to measure individual maximal clench force. Note that force of both sides of the mouth was recorded and the clench force used throughout Study 1 was the average of the two. In our study, the average maximum voluntary bite force was 189.2 N (SD = 65.2, Min = 97.8, Max = 290.1). We mapped 75% of the maximum force to the top of the interaction area to avoid fatigue from using an extreme position, based on the pilot study.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Performance Measures.", "text": "The dependent variables were: completion time: the time from when the cursor initially moved above the threshold until the acquisition was confirmed; success rate: the percentage of trials for a particular condition that resulted in successful acquisitions; number of crossings: the number of times the cursor cross the top or bottom edge of a target once the cursor has entered the target (minus 1 for all trials with QR); mean deviation: the average distance (relative to the height of the target) between the center of a target and the cursor position when the acquisition was confirmed. These measures complement each other. Completion time and success rate indicates the overall completeness of the tasks, while number of crossings and mean deviation reflects their force control performance.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Procedure.", "text": "Participants began with a warm-up stage. After they claimed that they understand the procedure, they went through two sessions in the order of FF and PF. A five-minute break was inserted between the sessions to relax their muscles. After each session, they filled out a simple questionnaire about their feeling of fatigue and success of the session and ranked the three selection methods according to their preference. Finally, the experimenter conducted a brief interview about participants' reactions to using the clench interaction. The duration of the study was about forty minutes. Participants 18 participants were recruited from a local university (Male = 11, Age = 22.3\u00b11.7, ranging from 20 -26). All participants reported having teeth in good condition and no previous disease or injury with their teeth.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Apparatus", "text": "We employed the thin-film pressure sensor TekScan Flexiforce (Model A201, Force range 0-440N) to accurately measure real-time clench force on occlusal surfaces. We used silicone sheets, steel flakes and rubber covers to protect the sensor. Figure 1 visualizes the layers. The diameter of the sensor was 15.00 mm. The thickness was 1.50 mm without pressure and reduced to 0.49 mm when clamped at 100 N  force, which is the typical adult force's during chewing [12]. All protective materials were sterilized and each participant used a new set of materials. During the study, two sensors were placed in users' mouths to measure the clench force on both sides. The clench force sensors were connected to a laptop with Windows 10 through an Arduino UNO board. The experiment was conducted in Unity 2018.2.0.", "n_publication_ref": 1, "n_figure_ref": 1}, {"heading": "Results", "text": "The experiment resulted in 216 trials (2\u00d73\u00d74\u00d73\u00d73) for each participant and 4320 data points overall.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Confirmation Techniques.", "text": "One of the goals of the user study was to find the best confirmation technique for clench interaction. We found a robust result: in most cases QR outperformed the other confirmation techniques in speed, success rate and clench force control, with statistical significance, in both feedback conditions. Moreover, QR was also ranked as the favorite by a majority of participants, in both visual feedback conditions (16 and 12, of 18 participants, respectively). These results were confirmed by Repeated Measure Analysis of Variances (RM-ANOVAs) of the performance measures. Table 1 summarized the results, together with the results of post hoc pairwise t-tests with Bonferroni adjustment.\nBased on these results, we focus on the trials with QR in the rest of the statistical analysis.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Number of Clench Force Levels.", "text": "The main goal of this study was to determine how many discrete levels of clench force users can discriminate comfortably and easily with decent performance. Not surprisingly, we found that fewer force levels led to better performance (see Figure 4). However, a small number of levels is not practical for interaction. Thus, our goal was to identify an appropriate maximum. Participant surveys suggest this number should be below 6 -they complained about the difficulty when N = 6 and 8 during the interview. \"I felt very tired to finish the tasks when levels were more than four. \" (P4).\nTo identify an appropriate number of levels, we consider success rate. The rate were 92.3% for N = 3 levels, where N = 4 levels only had a 78.4%. Moreover, participants noticed this difference. They self-rated their own performance best when N = 3 on a 7-point Likert scale (1:strongly disagree -7:strongly agree). Wilcoxon signed-rank post hoc tests showed significance, as summarized in Table 2. Therefore, we chose N = 3 as the \"safe\" number of discrete clench force levels that was easy for users to discriminate between.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Effect of Visual Feedback.", "text": "Participant performance on all measures was better in the Full Feedback condition. RM-ANOVAs showed significant main effect of visual feedback on all four performance measures. With full visual feedback, participants spent less time (F 1,17 = 6.66, p = 0.02), had higher success rate (F Study 1 mainly focused on force control, which is only one of the dimensions of clench interaction. There are other aspects to be explored in order to establish clench interaction techniques that can support a richer input space than the current state of the art in the literature. We developed a three-dimensional design space for clench interaction:\n\u2022 Force Level: Discretized Clench Force Three is a reasonable number of clench Force levels for users to distinguish easily and comfortably. Clench force at different levels can be mapped to different operations.\n\u2022 Time: Repetition and Duration A clench can either be transient or sustained. For a transient clench, it can also be one-off or performed repeatedly. We propose four different points on the Time dimension: single, double and triple clench, as well as sustained clench.\n\u2022 Location: Symmetry and Asymmetry Human have the ability to control the left and right clench separately. Hence a clench on the Location dimension can either be performed symmetrically or asymmetrically.\nTable 3 shows the design space as well as some potential applications of each point in the design space.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Evaluation", "text": "Knowing which clench actions in the design space users are willing to use without considering the specific interactions they are mapped to is fundamental to understanding the potential usage of clench interaction. We conducted a questionnaire survey to evaluate our clench interaction design space.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Material.", "text": "We created a questionnaire to evaluate three aspects of each action of this new interaction technique on a 7-point Likert Scale (1 -not at all, 7 -very much): 1) Simplicity: the physical and mental ease of performing the action; 2) Convenience: the compatibility of the action with daily life; 3) Preference: the willingness to use the action in daily routines, without worrying about sensing.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Procedure.", "text": "We delivered the questionnaire to random pedestrians in the street at our local university. Participants were asked to perform each clench action in the design space several times and then rate this action. The evaluation order of the actions was shuffled to avoid sequential effect and fatigue bias.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Results", "text": "Overall we delivered 64 questionnaires and 61 were completed (Male = 31, Age = 24.5\u00b14.8, ranging from 19 to 40). Figure 6 shows the results of the average scores on the three aspects of each action in the design space.\nWe ranked all actions according to the Preference score. Users preferred to use simple and easy clench actions. The top six actions have an average score over 4.5: symmetric single clench with level 1, symmetric single clench with level 2, symmetric double clench with level 1, symmetric sustained clench with level 1, asymmetric single clench with level 1, asymmetric sustained clench with level 1.\nThis provides insightful guidance on interaction design: these six clench actions have the potential to be employed as basic actions for clench interaction, and the design of clench interactions should be compatible with these actions. Note that although higher complexity or physical demand of other clench actions may reduce users' subjective preferences during the survey, there is a trade off between the sophistication of the interface and ability to complete tasks. We selected   the six actions to establish a basic set of clench interaction techniques, but we did not rule out the potential of the other actions to be added in future designs.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Clench Interaction Designs", "text": "Based on the survey results, we propose a mapping of operations to the six clench actions, as summarized in Table 4. Note that we added the Symmetric Single Clench L3 into our design in order to have a complete force dimension. We then devised three interaction patterns where the advantages of clench could be fully leveraged: gesture for discrete command input, clench for value control, and clench integrated with other interactions such as pointing.  Gesture for Discrete Command Input.\nOne of the most basic uses of clench actions is to interpret them as input commands. Clench holds the advantages of supporting hands-free and eyes-free interaction. Therefore, a user can issue a number of commands when both their hands or eyes are busy. One possible use case is when a user is riding a bicycle. Symmetric Single L1 Clench can be mapped to play/pause a music player (Click). Asymmetric Left/Right Single L1 Clench can be mapped to play the previous/next music (Discrete control). When a phone call comes in, Symmetric Single L1/2/3 clench can be mapped to accept/mute/reject an incoming phone call (Multiple Choice), and Symmetric Double L1 Clench can be used to hang up the call (Confirmation). Alternatively, clench gestures can also assist patients who may have difficulty moving their hands due to physical injuries, but retain the control of their face and mouth [13]. These gestures can be used as an assistive input method, e.g., menu selection [40], text entry [4] (Multiple Choice, Confirmation), smart home control (Click), etc. These examples show how clench gestures can improve interactions when one cannot fully use their hands or eyes.\nClench for Value Control.\nIn addition to discrete command inputs, clench can also be employed as a method to control discrete and continuous values without involving hands. Using the bicycling example again, when users enter a busy place where they may want to turn down the music volume to allow them to focus, or a quiet place where they might want to turn up the volume, Symmetric Single Clench with three force levels can be used to adjust the volume discretely, e.  as pointing in virtual/augmented reality (VR/AR) can expand the input space. For example, users can use Symmetric Single L1 Clench as a simple click operation in VR/AR with a headpointing cursor to support basic hands-free interactions on a GUI (Click). Symmetric Sustained L1 Clench can be employed as a holding or clutching operation together with the head cursor to drag the thumb on a GUI scrollbar (Hold). Clench has an even richer space for game design in VR/AR, where clench gestures can be mapped to various game effects. For instance, in a first-person-shooter game, a Symmetric Single Clench with L1-3 can be mapped to different skills to defeat enemies (Multiple Choices), and a Symmetric Sustained Clench can be mapped to a skill as \"becoming stronger temporarily\" (Hold). When coordinated with other interactions, clench can be employed to enhance user experience.", "n_publication_ref": 3, "n_figure_ref": 0}, {"heading": "USER STUDY 2: PERFORMANCE EVALUATION", "text": "From our design space evaluation, we obtained the six most preferred clench actions, however we still need to evaluate their usability. We conducted a second user study to evaluate their performance in supporting typical tasks. We compared the clench technique with two basic input methods: dwell and single button. We conducted the study on a VR platform where three types of clench interaction patterns and three techniques could be easily implemented. In this study, we mainly investigated scenarios where users are relatively static (i.e., sitting in a chair) to obtain initial results on a VR platform. Mobile scenarios are not involved. Note that we were focused on measuring the performance of clench interaction, rather than improving the results over the baselines.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Task", "text": "Figure 7 shows the six tasks from the six actions in Table 4.\nTask 1: Click -Symmetric Single L1 Clench. Users first need to move the head cursor (centered at the field of view) onto the target and use a Symmetric Single L1 Clench in clench method, click the button in button method, and keep the cursor on the target for 700 ms (same below) in dwell method (see Figure 7a). The next target will appear randomly, 500 pixels away.\nTask 2: Confirmation -Symmetric Single/Double L1 Clench. Users are asked to judge the correctness of a simple formula (see Figure 7b). They use Symmetric Single or Double L1 Clench/single or double button click to indicate to whether it is correct or not in clench/button method, and move the cursor onto the green/red widget and stay in dwell method.\nTask 3: Multiple Choice -Symmetric Single Clench at 3 Levels. Users have to choose the color for the white square to color it the same as the upper target square (see Figure 7c). Three Symmetric Single Clench force levels are mapped to the three colors: level 1, 2 and 3 to green, yellow and red respectively, for the clench method. Three color widgets are available for selection with the head cursor, and then a button click or dwell for the other conditions. Task 4: Clutch -Symmetric Sustained L1 Clench. Users need to move the white target onto the blue square (see Figure 7d). Users move the cursor on the target and then use a Symmetric Sustained L1 Clench, or press down the button, or stay to pick up and hold the target. They can drop it by releasing the clench, releasing the button or staying on the blue square for the three techniques, respectively.\nTask 5: Discrete Control -Asymmetric Single L1 Clench. A menu selection task is simulated. The blue square starts in the center, and users need to move it by five steps, each step being randomly chosen in the left or right direction, and then perform a confirm operation. Users use a left/right single L1 clench to move the blue square by one step and a Symmetric Single L1 Clench to confirm (clench). Three widgets are available to move the blue square (2 arrows) and to confirm the destination (square). The widgets can be selected with a button click for the button or using dwell when the cursor is on them.\nTask 6: Continuous Control -Asymmetric Sustained L1 Clench. Users need to adjust the slidebar thumb to the provided value (see Figure 7f). Sustained Single Left/Right L1 Clench decreases/increases the slidebar value at a constant rate (clench). For button/dwell, two arrows are and pressing down the button/staying on an arrow when the head cursor is on them will change the value at the same speed.\nA limitation when comparing gesture-and cursor-based techniques was that we did not vary the baselines, e.g., different button sizes and distances could lead to different results because cursor interaction is subject to Fitts' law effects [11].", "n_publication_ref": 1, "n_figure_ref": 6}, {"heading": "Design and Procedure", "text": "We use a within-subject study design to compare the three interaction techniques. The order of the six tasks are randomized for each subject. For each task, participants repeated three identical cycles. In each cycle, they use three techniques to finish the task 10 times, one technique after another. The order of the three techniques are counterbalanced to avoid a learning effect. Completion time was measured.\nParticipants were asked to keep the clench sensor in their mouth throughout the study in all three techniques for consistency. We used the same calibration procedure and mapping function as in Study 1. After each task, we asked participants to rank the three techniques according to their subjective preference. The experiment ended with a semistructured interview to gain additional feedback on clench interaction. The duration of the study was about 90 minutes. Participants and Apparatus 12 participants were recruited from our local university (Male = 7, Age = 22.8\u00b11.9, ranging from 20 to 28). All participants reported having good teeth condition and no previous disease or injury with their teeth.\nWe employed the same sensor in Study 1 to measure clench force. The study was run with an HTC Vive in Unity 2018.2.0.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Results", "text": "We collected data from 90 trials (3 \u00d7 3 \u00d7 10) for each task. All participants learned the interactions easily during the warmup stage and our system recognized the actions with low error rate throughout the study (average F1 score equaled 0.965). Figure 8 shows the performance for the three techniques. Table 5 summarizes the statistical results of the comparison between clench interaction and the two baselines.\nWe found that except for Task 1 and 2, clench was faster for all tasks, especially when the baselines' input channel was not as rich as clench. We note that a different design for dwell or button might require less time than the designs in this paper. Our results still revealed the advantages of clench interaction in that it has a larger input space.\nOther than Tasks 3 and 4, Friedman tests on the subjective rank data of all tasks showed significance. Nemenyi post-hoc tests on four tasks found that users mostly prefer clench over baselines (see the rank order column of Table 5). 4 out of 12 participants mentioned that clench has a stronger conceptual connection with one's mind to use clench alone versus button click. \"I prefer clench. When using button I have to consciously think about my hands.\" (P7) This can be explained by the different conceptual mouth-head/hands-head distances. in investigating the usability of clench interaction in a situation closer to daily use. We conducted a case study of simulated bicycling where users' hands and eyes were busy and they had to perform tasks to control the music player on their phone and receive phone calls. We compared clench interaction with two baselines: interacting directly with the mobile phone or using a wireless bluetooth earphone.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Design and Procedure", "text": "In our simulated bicycling scenario, users need to perform three tasks with each method: answer/mute/reject a phone call (clench gestures for command input), switch to previous/next songs (discrete value control), and turn down/up the volume (continuous value control). For the clench interface, users use a symmetric single L1/2/3 clench for three reactions to a phone call, left/right single L1 clench for switching between songs, and left/right sustained L1 clench for adjusting the volume. We used default operations on the phone: buttons and sliders shown on the screen to react to calls, switch songs and adjust volume; earphone: single/double/triple click on center button for call reactions, double/triple click on center button for previous/next songs, and clicks on volume buttons for volume adjustment. We used a within-subjects design. The independent variable is the method of interaction: clench, phone, earphone. Each task was repeated 10 times. Each time the specific operation was randomly chosen and the order of tasks was counterbalanced. The time for completing each task with different methods was measured. Each participant was briefly interviewed at the end. The study lasted about 15 minutes.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Participants and Apparatus", "text": "Among the 12 participants in Study 2, 10 of them joined Study 3 (Male = 7, Age = 23.2\u00b12.0, ranging from 20 to 28). Participants rode on an indoor exercise bike to simulate bicycling. An iPhone 8 (in the trouser pocket on side of the dominant hand) and Bose SoundSport Wireless Earphones were used to complete the tasks.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Results", "text": "The average F1 score of recognizing clench actions were 0.973. As expected, the average time of executing operations using a clench interaction was much less than for the baseline interactions, i.e., clench interaction was the fastest. Figure 9 shows the time for each method the three tasks. RM-ANOVA shows significance in all three tasks (F 2,18 = 34.89, 21.99, 58.97, p < 0.001) and post hoc t-tests showed all pairs are significantly different.\nUsers' subjective comments also reflected the high usability of clench interaction when both hands and eyes are busy. \"The clench obviously works better than other methods. I don't have to reach my hand to the phone or earphone anymore.\" ", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "DISCUSSION", "text": "Although the use of buttons has been a typical interaction paradigm for decades, clench might be able to serve as a more intuitive and convenient input channel. Participants in user studies mentioned a stronger conceptual connection with their mind from using clench alone versus button click (confirmation in Study 1 and interaction in Study 2). Although we did not rule out the possibility of a novelty effect, the different conceptual distances to the head might affect users' mental model of clench interaction.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Associating Clench Semantically", "text": "In order to make clench interaction applicable in daily use, clench actions need to be mapped to effects with reasonable semantics. For instance, a left/right single clench makes sense when mapped to the same conceptual direction as previous/next. Designers should make sure to connect the appropriate semantic meanings with clench actions as needed.\nIn fact, another approach for a design space evaluation could be an elicitation study where users are asked to choose the action they prefer in the design space to complete a given task. This may provide a mapping set between clench actions and effects that better reflects users' preference on specific tasks. This can be explored in the future.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Limitation and Future Work", "text": "Sensor. The thickness of the clench sensor is not completely negligible and it requires calibration each time the sensors are put in the mouth. Although we manufactured it as thin as 1.50 mm, it may still have some effect on the clench control in Study 1, and the user experience in Studies 2 and 3. Note that we also tested an EMG sensor attached around the temporal muscles, with pressure sensors in the mouth simultaneously. Similar to previous work, we found that fatigue greatly effects the linear relationship between EMG and clench force [31] (r 2 = 0.803, p < 0.001 from a five-minute test of three pilot users). In the future, better signal processing methods with EMG might be able to fully reflect the clench force and thus obviate an in-mouth sensor.\nDesign. In Study 2, we only investigated the six most preferred clench actions in the design space. There are still a number of actions to be evaluated in future work, such as users' ability to control clench asymmetrically and to use richer clenching patterns. In addition, there exist a number of potential modalities besides visual feedback. For example, Stewart et al. [30] investigated audio, and vibrotactile feedback and found that non-visual pressure input can be executed with similar speed but lower accuracy. Since clench interactions are essentially pressure-based, these modalities are worth further exploration when selection accuracy is not essential, especially in cases where visual feedback is not available.\nIn future work, we would like to test the device in the field. Although we tested its use on a stationary bike, this lacks the ecological validity of true mobile use.\nTeeth health. We consulted two dentists and they pointed out the potential effect of teeth grinding if the maximum clench force is maintained too long. Although none of the participants ran into extreme fatigue or teeth grinding during our study, this is a limitation and needs further exploration.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "CONCLUSION", "text": "In this paper, we propose clench interaction, which leverages isometric clench force. We first conducted a user study to investigate the ability to control clench force. Our results showed that three is a favorable number of force levels for users to distinguish easily and comfortably, and quick release outperforms other confirmation techniques. Based on the first user study, we developed a three-dimensional -Force Level, Time and Location -design space for clench interaction and evaluated it via a questionnaire survey, whose results helped select six user-preferred clench actions. We then devised three interaction patterns for clench interaction. We conducted a second user study to measure the performance of the six clench actions in controlled tasks, as well as a third user study to investigate the usability in a situation closer to daily use. Participants preferred the clench over the baselines and were willing to use clench as a novel interaction technique that can be performed easily and conveniently.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "ACKNOWLEDGEMENT", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "Analysis of Chewing Sounds for Dietary Monitoring", "journal": "", "year": "2005", "authors": "Oliver Amft; Mathias St\u00e4ger; Paul Lukowicz; Gerhard Tr\u00f6ster"}, {"title": "", "journal": "", "year": "", "authors": " Springer-Verlag"}, {"title": "CanalSense: Face-Related Movement Recognition System Based on Sensing Air Pressure in Ear Canals", "journal": "", "year": "2017", "authors": "Toshiyuki Ando; Yuki Kubo; Buntarou Shizuki; Shin Takahashi"}, {"title": "", "journal": "ACM", "year": "", "authors": ""}, {"title": "CanalSense+: Face-Related Movement Recognition and Identification System Based on Air Pressure in Ear Canals", "journal": "ACM", "year": "2018", "authors": "Toshiyuki Ando; Yuki Kubo; Buntarou Shizuki; Shin Takahashi"}, {"title": "Bitey: An Exploration of Tooth Click Gestures for Hands-free User Interface Control", "journal": "ACM", "year": "2016", "authors": "Daniel Ashbrook; Carlos Tejada; Dhwanit Mehta; Anthony Jiminez; Goudam Muralitharam; Sangeeta Gajendra; Ross Tallents"}, {"title": "Clinical significance of isometric bite force versus electrical activity in temporal and masseter muscles", "journal": "European Journal of Oral Sciences", "year": "1989", "authors": "Merete Bakke; Lars Michler; Eigild Han;  M\u00f6ller"}, {"title": "Toward Silent-Speech Control of Consumer Wearables", "journal": "Computer", "year": "2015-10", "authors": "A Bedri; H Sahni; P Thukral; T Starner; D Byrd; P Presti; G Reyes; M Ghovanloo; Z Guo"}, {"title": "Detecting Mastication: A Wearable Approach", "journal": "ACM", "year": "2015", "authors": "Abdelkareem Bedri; Apoorva Verlekar; Edison Thomaz; Valerie Avva; Thad Starner"}, {"title": "Unobtrusive electromyography-based eating detection in daily life: A new tool to address underreporting?", "journal": "Appetite", "year": "2017", "authors": "J Blechert;  Liedlgruber;  Lender; F H Reichenberger;  Wilhelm"}, {"title": "On the Tip of My Tongue: A Non-invasive Pressure-based Tongue Interface", "journal": "", "year": "2014", "authors": "Jingyuan Cheng; Ayano Okoso; Kai Kunze; Niels Henze; Albrecht Schmidt; Paul Lukowicz; Koichi Kise"}, {"title": "", "journal": "ACM", "year": "", "authors": ""}, {"title": "Maximal bite forces in healthy young adults as predicted by surface electromyography", "journal": "Journal of dentistry", "year": "2004", "authors": "Chiarella Virgilio F Ferrario; Gianfranco Sforza; Gianluca M Zanotti;  Tartaglia"}, {"title": "The information capacity of the human motor system in controlling the amplitude of movement", "journal": "Journal of experimental psychology", "year": "1954", "authors": "M Paul;  Fitts"}, {"title": "Occlusal forces during chewing and swallowing as measured by sound transmission", "journal": "Journal of Prosthetic Dentistry", "year": "1981", "authors": "H Charles; Parker E Gibbs;  Mahan; C Harry; Kenneth Lundeen;  Brehnan; K Edward; William B Walsh;  Holbrook"}, {"title": "Tongue-in-Cheek: Using Wireless Signals to Enable Non-Intrusive and Flexible Facial Gestures Detection", "journal": "", "year": "2015", "authors": "Mayank Goel; Chen Zhao; Ruth Vinisha; Shwetak N Patel"}, {"title": "", "journal": "ACM", "year": "", "authors": ""}, {"title": "Biomechanical analysis of jaw-closing movements", "journal": "Journal of dental research", "year": "1995", "authors": "J H Koolstra;  Van Eijden"}, {"title": "Evaluation of tooth-touch sound and expiration based mouse device for disabled persons", "journal": "IEEE", "year": "2012", "authors": "Koichi Kuzume"}, {"title": "Buccal: Low-cost Cheek Sensing for Inferring Continuous Jaw Motion in Mobile Virtual Reality", "journal": "ACM", "year": "2018", "authors": "Richard Li; Gabriel Reyes"}, {"title": "MouthType: Text Entry by Hand and Mouth", "journal": "ACM", "year": "2004", "authors": "J Michael; Chi-Ho Lyons; Nobuji Chan;  Tetsutani"}, {"title": "The mouthesizer: a facial gesture musical interface", "journal": "", "year": "0230", "authors": "J Michael; Michael Lyons; Nobuji Haehnel;  Tetsutani"}, {"title": "EMG, bite force, and elongation of the masseter muscle under isometric voluntary contractions and variations of vertical dimension", "journal": "The Journal of prosthetic dentistry", "year": "1979", "authors": "Arturo Manns; Rodolfo Miralles; Carmen Palazzi"}, {"title": "Appropriateness of Foot Interaction for Non-accurate Spatial Tasks", "journal": "ACM", "year": "2004", "authors": "Toni Pakkanen; Roope Raisamo"}, {"title": "A Novel Chewing Detection System Based on PPG, Audio, and Accelerometry", "journal": "IEEE Journal of Biomedical and Health Informatics", "year": "2017-05", "authors": "V Papapanagiotou; C Diou; L Zhou; J Van Den; M Boer; A Mars;  Delopoulos"}, {"title": "Method and apparatus for controlling a device or process with vibrations generated by tooth clicks", "journal": "US Patent", "year": "2005", "authors": "Arthur Prochazka"}, {"title": "BodyBeat: A Mobile System for Sensing Non-speech Body Sounds", "journal": "ACM", "year": "2014", "authors": "Tauhidur Rahman; Alexander T Adams; Mi Zhang; Erin Cherry; Bobby Zhou; Huaishu Peng; Tanzeem Choudhury"}, {"title": "Pressure Widgets", "journal": "ACM", "year": "2004", "authors": "Gonzalo Ramos; Matthew Boulos; Ravin Balakrishnan"}, {"title": "The Tongue and Ear Interface: A Wearable System for Silent Speech Recognition", "journal": "ACM", "year": "2014", "authors": "Himanshu Sahni; Abdelkareem Bedri; Gabriel Reyes; Pavleen Thukral; Zehua Guo; Thad Starner; Maysam Ghovanloo"}, {"title": "An Isometric Tongue Pointing Device", "journal": "ACM", "year": "1997", "authors": "Chris Salem; Shumin Zhai"}, {"title": "The Pipe: explorations with breath control", "journal": "", "year": "2003", "authors": "P Gary;  Scavone"}, {"title": "Evaluation of tooth-click triggering and speech recognition in assistive technology for computer access", "journal": "Neurorehabilitation and neural repair", "year": "2010", "authors": "Tyler Simpson; Michel Gauthier; Arthur Prochazka"}, {"title": "BreathVR: Leveraging Breathing As a Directly Controlled Interface for Virtual Reality Games", "journal": "ACM", "year": "2018", "authors": "Misha Sra; Xuhai Xu; Pattie Maes"}, {"title": "Characteristics of Pressure-based Input for Mobile Devices", "journal": "ACM", "year": "2010", "authors": "Craig Stewart; Michael Rohs; Sven Kratz; Georg Essl"}, {"title": "Fatigue and pain in human jaw muscles during a sustained, low-intensity clenching task", "journal": "Archives of oral biology", "year": "2001", "authors": "Peter Svensson; S Burgaard;  Schlosser"}, {"title": "Bite force and electromyograpy during maximum unilateral and bilateral clenching", "journal": "European journal of oral sciences", "year": "2008-01", "authors": "Andries Van Der; Anneke Bilt;  Tekamp"}, {"title": "Wearable Food Intake Monitoring Technologies: A Comprehensive Review", "journal": "Computers", "year": "2017", "authors": "Tri Vu; Feng Lin; Nabil Alshurafa; Wenyao Xu"}, {"title": "A novel bite force recorder and maximal isometric bite force values for healthy young adults", "journal": "European Journal of Oral Sciences", "year": "1993", "authors": "Antti Waltimo; Mauno K\u00f6n\u00f6nen"}, {"title": "Eating Detection and Chews Counting through Sensing Mastication Muscle Contraction", "journal": "Smart Health", "year": "2018", "authors": "Shuangquan Wang; Gang Zhou; Yongsen Ma; Lisha Hu; Zhenyu Chen; Yiqiang Chen; Hongyang Zhao; Woosub Jung"}, {"title": "Influence of sustained submaximal clenching fatigue test on electromyographic activity and maximum voluntary bite forces in healthy subjects and patients with temporomandibular disorders", "journal": "Journal of oral rehabilitation", "year": "2017", "authors": "L Xu;  Fan; Z Cai; X Fang;  Jiang"}, {"title": "Bite Glasses: Measuring Chewing Using Emg and Bone Vibration in Smart Eyeglasses", "journal": "ACM", "year": "2016", "authors": "Rui Zhang; Oliver Amft"}, {"title": "Monitoring Chewing and Eating in Free-Living Using Smart Eyeglasses", "journal": "IEEE Journal of Biomedical and Health Informatics", "year": "2018-01", "authors": "R Zhang; O Amft"}, {"title": "Typing with eye-gaze and tooth-clicks", "journal": "ACM", "year": "2012", "authors": "Amy Xiaoyu; Elias D Zhao; Dimitry Guestrin; Tyler Sayenko; Michel Simpson; Milos R Gauthier;  Popovic"}, {"title": "OsteoConduct: Wireless bodyarea communication based on bone conduction", "journal": "", "year": "2007", "authors": "Lin Zhong; Dania El-Daye; Brett Kaufman; Nick Tobaoda"}], "figures": [{"figure_label": "1", "figure_type": "", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: Left) Sketch of Teeth Anatomy and Terminology. Middle) The sketch sensor's position in mouth and its layers. Right) The prototype of the sensor.", "figure_data": ""}, {"figure_label": "2", "figure_type": "", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: Visual Feedback Conditions. Left) Full Feedback (FF ): cursor, target and other rectangles are visible. Right) Partial Feedback (PF ): only target is visible, cursor will disappear once across the threshold.", "figure_data": ""}, {"figure_label": "3", "figure_type": "", "figure_id": "fig_2", "figure_caption": "Figure 3 :3Figure 3: Experiment Set Up for Study 1.Colored area indicate targets to be reached. Two independent variables are reflected: 1) Force Levels. N is the number of levels; H is the corresponding height of a target; 2) Target Positions. D is the distance of some place in the target to the starting threshold, which implies the target to be reached in a trial.", "figure_data": ""}, {"figure_label": "4", "figure_type": "", "figure_id": "fig_3", "figure_caption": "Figure 4 :4Figure 4: Performance Measures of Clench Force Control with Visual Feedback Across Different Level Number. The left and right half in each figure represent FF and PF condition respectively. Error bars indicate the standard error.", "figure_data": ""}, {"figure_label": "5", "figure_type": "", "figure_id": "fig_4", "figure_caption": "Figure 5 :5Figure 5: Success rate and mean deviation across different distances to the target.", "figure_data": ""}, {"figure_label": "6", "figure_type": "", "figure_id": "fig_5", "figure_caption": "Figure 6 :6Figure 6: Heatmaps of The Evaluation Results of Clench Design Space. \"L\" indicates clench force level. The upper half are results for symmetric actions, while the lower half are results for asymmetric actions. For each single heatmap, the x-axis is for Force Level dimension and the y-axis is for Time dimension. Blue/white implies favorable/unfavorable.", "figure_data": ""}, {"figure_label": "7", "figure_type": "", "figure_id": "fig_6", "figure_caption": "Figure 7 :7Six Tasks for Clench Interaction Evaluation", "figure_data": ""}, {"figure_label": "38", "figure_type": "", "figure_id": "fig_7", "figure_caption": "6 USER STUDY 3 :Figure 8 :38Figure 8: Completion Time for Each Task in Study 2", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "1,17 =", "figure_data": "Mea-sures TFull Feedback AOV (F 2,34 ) Post Hoc T-test 2.99, p = 0.063. QR < DW \u223c BC 18.04, p < 0.001  : Statistical Results of Confirmation Partial Feedback AOV (F 2,34 ) Post Hoc T-test Techniques. T : Completion Time, R: Success Rate, C: Number of Crossing, D: Mean Devi-ation. Symbol Explanation (the same below):. < 0.1,"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Statistical Results of Level Number on QR data only. Additional G: subject rating score of the performance goodness.21.91, p < 0.001), fewer crossings (F 1,17 = 7.99, p = 0.01), and less deviation (F 1,17 = 25.37, p < 0.001).Control at Different Clench Force Level. Figure5reveals interesting trends when QR was the selection technique: participants made more mistakes (F 2,34 = 3.97, p = 0.03) and had higher deviation (F 2,34 = 10.88, p < 0.001) when using low clench force. This was also reflected in participants' comments: 5 of 18 participants mentioned oversensitivity of the clench control system at low force level. \"I was easy to overshoot when a target was low... I had a relatively better control when a target require larger clench force.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Short Triple Disc. Volume up/down Disc. Zoom in/out Disc. Shrink/Enlarge Disc. Value Control Sustained Cont. Volume up/down Cont. Zoom in/out Cont. Shrink/Enlarge Cont. Value Control", "figure_data": "Time DimensionLocation Dimension: Symmetric Force Level Dimension Level 1 -Light Level 2 -MediumLevel 3 -HeavyPotential Widget TypeShort SingleSingle selectionAnswer callPlay or PauseSelectionShort DoubleOpenHang-up callMenu accessConfirmShort TripleDeleteCloseQuitSerious ConfirmSustainedMoveDuplicate and moveBox selectionHold/ClutchTime DimensionLocation Dimension: Asymmetric Left/Right Force Level Dimension Level 1 -Light Level 2 -Medium Level 3 -HeavyPotential Widget TypeShort SingleLeft/RightPrevious/NextScroll up/downNavigationShort DoubleAccept/RejectReply/ForwardUndo/RedoEither-or"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Three-Dimension Design Space for Clench Interaction: Force Level, Time and Location.", "figure_data": "The right-"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "", "figure_data": ""}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "Statistical Results of Three Techniques in Six Tasks. c: Clench, b: Button click, d: Dwell.", "figure_data": "Performance MeasuresCompletion Time AOV (F 2,22 ) Post Hoc T-Test Friedman test (\u03c7 2 ) Post hoc Nemenyi Test Rank OrderTask 1: Click0.59, p = 0.564\u22126.00, p = 0.05  *c > b \u223c dTask 2: Confirmation21.95, p < 0.001  *  *  *b < c < d10.17, p = 0.006  *  *c \u223c b > dTask 3: Multiple Choice 3.44, p = 0.05  *c < d \u223c b3.50, p = 0.174\u2212Task 4: Clutch14.58, p < 0.001  *  *  *\u223c c < d3.50, p = 0.174\u2212Task 5: Disc. Control14.05, p < 0.001  *  *  *c < b < d8.17, p = 0.02  *c > b \u223c dTask 6: Cont. Control8.99, p = 0.001  *  *c < d \u223c b10.17, p = 0.006  *  *c > b \u223c d6ClenchEarphonePhoneTime / s2 40Phone CallSwitch SongsAdjust VolumeFigure 9: Completion Time for Each Task in Study 3(P2) \"I would like to use clench since it has less distraction.\"(P9) Participants liked clench interaction because of its sim-plicity and convenience, even at a cost of a certain amount ofphysical demand. \"Clenching repeatedly would cause fatigue.But I anticipated that it would not be used in such a frequentway. So I don't think it would cause any problem. ' (P6)"}], "doi": "10.1145/3290605.3300505"}