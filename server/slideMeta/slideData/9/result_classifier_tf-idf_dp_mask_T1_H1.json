{"title": "tempTitle", "slideCnt": 42, "groundTruthOutline": [{"sectionTitle": "title", "startSlideIndex": 1, "endSlideIndex": 1}, {"sectionTitle": "1 INTRODUCTION", "startSlideIndex": 2, "endSlideIndex": 5}, {"sectionTitle": "2 BACKGROUND", "startSlideIndex": 6, "endSlideIndex": 6}, {"sectionTitle": "1 INTRODUCTION", "startSlideIndex": 7, "endSlideIndex": 7}, {"sectionTitle": "4 GENERAL METHODS", "startSlideIndex": 8, "endSlideIndex": 8}, {"sectionTitle": "3 CONDITIONS AND HYPOTHESES", "startSlideIndex": 9, "endSlideIndex": 17}, {"sectionTitle": "5 SHAPE AND COLOR", "startSlideIndex": 18, "endSlideIndex": 24}, {"sectionTitle": "6 SHAPE AND SIZE", "startSlideIndex": 25, "endSlideIndex": 30}, {"sectionTitle": "7 DISCUSSION", "startSlideIndex": 31, "endSlideIndex": 37}, {"sectionTitle": "8 CONCLUSION", "startSlideIndex": 38, "endSlideIndex": 40}, {"sectionTitle": "end", "startSlideIndex": 41, "endSlideIndex": 41}], "annotations": {"daa47aa73f3942a394f09b6423e7aa93": [{"sectionTitle": "Title", "startSlideIndex": 1, "endSlideIndex": 1}, {"sectionTitle": "Introduction", "startSlideIndex": 2, "endSlideIndex": 5}, {"sectionTitle": "conventional approaches", "startSlideIndex": 6, "endSlideIndex": 7}, {"sectionTitle": "Experimental Design", "startSlideIndex": 8, "endSlideIndex": 14}, {"sectionTitle": "Hypotheses", "startSlideIndex": 15, "endSlideIndex": 17}, {"sectionTitle": "Detail 1", "startSlideIndex": 18, "endSlideIndex": 24}, {"sectionTitle": "Detail 2", "startSlideIndex": 25, "endSlideIndex": 30}, {"sectionTitle": "Detail 3", "startSlideIndex": 31, "endSlideIndex": 31}, {"sectionTitle": "Discussion", "startSlideIndex": 32, "endSlideIndex": 40}, {"sectionTitle": "end", "startSlideIndex": 41, "endSlideIndex": 41}], "201e37e6f0b24effb28ac3768d4009b9": [{"sectionTitle": "Title", "startSlideIndex": 1, "endSlideIndex": 1}, {"sectionTitle": "end", "startSlideIndex": 2, "endSlideIndex": 41}], "ceed8baac0e944f6805df24d4f575b76": [{"sectionTitle": "Title", "startSlideIndex": 1, "endSlideIndex": 1}, {"sectionTitle": "23", "startSlideIndex": 2, "endSlideIndex": 3}, {"sectionTitle": "1234", "startSlideIndex": 4, "endSlideIndex": 41}], "0ab2b02a64714f4e8b7d83a7875f537e": [{"sectionTitle": "Title", "startSlideIndex": 1, "endSlideIndex": 1}, {"sectionTitle": "NO_LABEL", "startSlideIndex": 2, "endSlideIndex": 22}, {"sectionTitle": "NO_LABEL", "startSlideIndex": 23, "endSlideIndex": 30}, {"sectionTitle": "end", "startSlideIndex": 31, "endSlideIndex": 41}], "91cf22f25c3742f0ac742c0e51c62d68": [{"sectionTitle": "Title", "startSlideIndex": 1, "endSlideIndex": 1}, {"sectionTitle": "asdfasdfasdf", "startSlideIndex": 2, "endSlideIndex": 18}, {"sectionTitle": "asdfasdf", "startSlideIndex": 19, "endSlideIndex": 40}, {"sectionTitle": "end", "startSlideIndex": 41, "endSlideIndex": 41}]}, "slideInfo": [{"index": 0, "startTime": 0, "endTime": 4.0, "script": "", "ocrResult": ""}, {"index": 1, "startTime": 4.0, "endTime": 17.33, "script": "- Hello everyone. So I'm gonna present a set of experiments that show how our traditional notions of separability, essential tendon in visualization design falls short, and how we can fix them.", "ocrResult": ""}, {"index": 2, "startTime": 17.33, "endTime": 53.33, "script": "So consider this simple scatter plot where I've encoded two data dimensions using position. We can encode additional data into this scatter plot using visual channels such as color, size, and shape. But how do these visual channels interact with one another perceptually? For example, if I encode one data dimension using shape, will it change the way I perceive color or size differences between marks? So this work models the perceptual interplay between these channels. And using these models, we can anticipate and account for potential errors that people might make when interpreting multi-variant visualizations.", "ocrResult": ""}, {"index": 3, "startTime": 53.33, "endTime": 60.67, "script": "So we can encoded data dimensions using various visual channels, such as position, size, shape, and others.", "ocrResult": ""}, {"index": 4, "startTime": 60.67, "endTime": 101.33, "script": "of separable versus integral channels. So separable channels is when one channel can be attended to without any interference from the other. So for example, if I encode data using position as the first channel, and encode additional data using color as the second channel, I can determine the position of these marks, no matter what color they are. And I can determine the color of these marks, no matter where they are in the scatter plot. So there's no interference.", "ocrResult": ""}, {"index": 5, "startTime": 101.33, "endTime": 112.0, "script": "Conversely, integral channels is when encoding a data attribute using a visual channel interferes with selectively attending to the other. For example, if I encode data using lightness as the first channel,", "ocrResult": ""}, {"index": 6, "startTime": 112.0, "endTime": 154.0, "script": "So here I have an ordered list of visual channel pairs where pairs at the top are known to be more integral, and pairs at the bottom are known to be more separable. But the specific ordering of this list is primarily derived from intuition and experience with limited empirical support. And these heuristics have been widely used by visualization designers, but their actual utility is poorly grounded, leaving users open to potentially significant data interpretation errors.", "ocrResult": ""}, {"index": 7, "startTime": 154.0, "endTime": 174.0, "script": "So we aim to provide designers with more concrete guidelines about reasoning, about separability. And we do this by empirically measuring the amount of separability between channels, and then constructing actionable models that we can use to support visualization design by automatically adjusting encodings to account for perceptual interference.", "ocrResult": ""}, {"index": 8, "startTime": 174.0, "endTime": 195.33, "script": "We constructed these models using data collected from 1,930 participants on Mechanical Turk, across four different experiments. And I'm gonna discuss two of these experiments in detail, and I'll also discuss how we can use the results from these experiments to craft more effective multi-variant visualizations. Okay, so getting into the experimental design,", "ocrResult": ""}, {"index": 9, "startTime": 195.33, "endTime": 208.67, "script": "here's an example stimuli from one of our experiments. And for each data plot, participants were asked to compare two target marks and indicate whether they were the same or different on some specified dimension.", "ocrResult": ""}, {"index": 10, "startTime": 208.67, "endTime": 222.0, "script": "We tested 16 different shapes gathered from common vis tools like Tablo, and MATLAB, and Python, and others. And these shapes can be broken up into three major categories: filled, unfilled, and open shapes.", "ocrResult": ""}, {"index": 11, "startTime": 222.0, "endTime": 230.0, "script": "We tested six different mark sizes ranging from six pixels to 50 pixels in diameter based on those used from prior experiments in this area.", "ocrResult": ""}, {"index": 12, "startTime": 230.0, "endTime": 239.33, "script": "And we tested a variety of colors that differ along the lightness axis, the red-green axis, and the yellow-blue axis in the CIELAB color space.", "ocrResult": ""}, {"index": 13, "startTime": 239.33, "endTime": 275.33, "script": "CIELAB is commonly used in visualizations because it's approximately perceptually uniform, meaning one unit in Euclidean distance, equates to one just noticeable difference, or JND for short. And we define a JND as the minimal amount of distance that two colors need to be apart for 50% of people to actually perceive a difference. Now this point about one unit of Euclidean distance equating to one JND, actually doesn't hold in practice, because CIELAB assumes specific conditions for comparing colors, like very large isolated marks. And that's just often not the case in visualizations.", "ocrResult": ""}, {"index": 14, "startTime": 275.33, "endTime": 303.33, "script": "For example here, I've encoded a scatter plot using seven different colors that are each separated by one Euclidean distance in this color space. Theoretically we should be able to discern small differences in these colors that would equate to small differences in the data. But as you can see, it's hard to determine these differences, it's hard to discern these color differences from marks of this shape and size. This means any meaningful small scale differences in the data that these colors in code are lost.", "ocrResult": ""}, {"index": 15, "startTime": 303.33, "endTime": 321.33, "script": "So drawing from prior work and visualization and vision science. We derived three general hypotheses related to these experiments. First, we expect colors to be more discriminable on denser shapes. And this hypothesis stems from prior experiments that have shown that color discriminability is proportional to mark size.", "ocrResult": ""}, {"index": 16, "startTime": 321.33, "endTime": 335.33, "script": "Secondly we expect denser shapes to appear larger. And this hypothesis stems from the idea that when comparing the size of two marks, users might resort to other aspects of the marks, such as density, which could alter perceived size.", "ocrResult": ""}, {"index": 17, "startTime": 335.33, "endTime": 351.33, "script": "between these channels to be asymmetric. In other words, we expect shape to more strongly influence color and size perceptions. Then either color or size would influence one's ability to perceive a marked shape.", "ocrResult": ""}, {"index": 18, "startTime": 351.33, "endTime": 356.0, "script": "Okay, so let's get into the first experiment, which explores interactions between shape and color.", "ocrResult": ""}, {"index": 19, "startTime": 356.0, "endTime": 382.67, "script": "So this experiment specifically looks at how using different shapes in a scatter plot might affect color difference perception. Here's an example stimuli from the experiment. And the scatter plot consists of a field of gray distractor shapes with two color shapes that are either the same color or slightly different colors. And we asked participants to indicate whether these colored marks were the same or different colors, which allows us to model JND values for different marks, sizes, and shapes.", "ocrResult": ""}, {"index": 20, "startTime": 382.67, "endTime": 388.0, "script": "We used a full factorial mixed factors design for this experiment where we tested 16 different shapes,", "ocrResult": ""}, {"index": 21, "startTime": 388.0, "endTime": 409.33, "script": "We tested all three axes at CIELAB between.", "ocrResult": ""}, {"index": 22, "startTime": 409.33, "endTime": 417.33, "script": "And we recruited 606 participants for this study. And if I didn't mention it before, we're using Amazon Mechanical Turk.", "ocrResult": ""}, {"index": 23, "startTime": 417.33, "endTime": 476.67, "script": "So getting into the results, what we're looking at here is color discriminability results associated with three of our 16 tested shapes. Where the X axis denotes mark size and pixels, and the Y axis shows us the mean 50% JND for lightness differences. And we're gonna focus on lightness for the purpose of this talk because lightness is the most important aspect of color discriminability for numerical encodings. And to remind you, a JND is the minimal amount of distance that two colors need to be apart such that that difference is detected half the time. So looking at this graph, we can see that colors become more discriminable as mark size increases, because a lower value means more discriminable. But we can also see that depending on the mark's shape, the JND values are different. For example, we see a 50% reduction in discriminability for six pixel Y crossings, compared with filled squares, suggesting that the shape of a mark also influences color discriminability.", "ocrResult": ""}, {"index": 24, "startTime": 476.67, "endTime": 547.33, "script": "So the primary takeaways from this first experiment are that shape does significantly affect color difference perception, where, for example, the filled diamond had a mean JND of about 6 1/2, while the Y crossing had one of over 10 which is a substantial difference. And also, this experiment replicates results from prior studies that show that color discriminability is proportional to mark size.", "ocrResult": ""}, {"index": 25, "startTime": 547.33, "endTime": 564.67, "script": "So our first experiment showed that color discriminability varies with shape. And we hypothesized that this variation may be explained by a variation in perceived size. So shapes that are perceived as larger, might be more discriminable. So we ran another experiment to test this hypothesis that looks at shape and size.", "ocrResult": ""}, {"index": 26, "startTime": 564.67, "endTime": 574.67, "script": "Participants in this experiment saw a scatter plot like this with two target marks highlighted in blue. And they were asked to determine which of the two highlighted shapes appears larger.", "ocrResult": ""}, {"index": 27, "startTime": 574.67, "endTime": 582.67, "script": "We again, used the full factorial design, where each participant completed 123 trials. And we tested the same set of shapes and sizes from the previous experiment.", "ocrResult": ""}, {"index": 28, "startTime": 582.67, "endTime": 594.67, "script": "We recruited 489 participants for this study.", "ocrResult": ""}, {"index": 29, "startTime": 594.67, "endTime": 671.33, "script": "So this graph summarizes the results of our study using the mean size bias for each tested shape. The X axis here shows the percentage of the time that a particular shape was perceived as larger than other shapes of the exact same size. So if there was no bias due to shape, we would expect these values to hover around 50%. But we see significant variation from this threshold. Now if we look at the mean size bias for the filled shapes and compare that to the unfilled shapes, we generally see that the filled shapes are perceived as larger than their unfilled counterparts. For example, the filled circle is perceived as larger in 67% of trials, while the unfilled circle is only perceived as larger in 49% of trials. So this pattern supports our hypothesis that denser shapes would be perceived as larger. But we don't see the same pattern in open shapes. For example, the T crossing is seen as larger in 82% of trials, while the denser 8 prong asterisk is seen as larger in only 54% of trials. And overall we see no evidence that denser shapes, denser open shapes appear larger. Also we found that the patterns in perceived size don't well explain the patterns in color discriminability that we saw from experiment one, suggesting something more complex is at play here.", "ocrResult": ""}, {"index": 30, "startTime": 671.33, "endTime": 689.33, "script": "So the main takeaways from this second experiment is first that shape does significantly affect size perception where some shapes are perceived as larger more than 80% of the time when compared to other shapes of the same size. And color discriminability for our tested shapes is not well explained by the perceived size of the shape.", "ocrResult": ""}, {"index": 31, "startTime": 689.33, "endTime": 722.67, "script": "So we also ran a pair of experiments that explore the symmetry of these relationships. And we care about symmetry because if perceptional interference functions asymmetrically, then we can adjust encodings to account for interference in one direction without worrying about it altering perceptions in the other direction. But for the sake of time, I'm not gonna go into detail about these experiments. So I'll just tell you that we found that color and size have much less of an effect on shape perception than we have seen shape have on size and color perception.", "ocrResult": ""}, {"index": 32, "startTime": 722.67, "endTime": 732.0, "script": "So lastly, I wanna close by summarizing our results and showing how we might use this data to construct more affective visualizations.", "ocrResult": ""}, {"index": 33, "startTime": 732.0, "endTime": 744.67, "script": "that colors would be more discriminable on denser shapes like with the filled shapes compared to the unfilled shapes. But we also found evidence contrary to this hypothesis among the open shapes.", "ocrResult": ""}, {"index": 34, "startTime": 744.67, "endTime": 763.33, "script": "And we found some support for our hypothesis that denser shapes would appear larger. For example, the filled shapes compared with their unfilled counterparts. But again we found some evidence contrary to this hypothesis. And in general, the perceived size of a shape didn't well explain the color discriminability results from the first experiment.", "ocrResult": ""}, {"index": 35, "startTime": 763.33, "endTime": 779.33, "script": "that shows an asymmetry between these channels. Shape had a much stronger affect on color and size perceptions than color or size had on shape perceptions. But again, see the paper for more details on these experiments.", "ocrResult": ""}, {"index": 36, "startTime": 779.33, "endTime": 810.67, "script": "Okay, so we can use the models constructed from the results to build more effective multi-variant visualizations. And if we revisit our example earlier from the talk that used one Euclidean distance JNDs, which is standard in CIELAB. We lost differences in our data, because we should, theoretically, be able to see seven values here. But we can instead adjust to these color steps based on the modeled perceptual interference between shape, size, and color, and compute new JND values.", "ocrResult": ""}, {"index": 37, "startTime": 810.67, "endTime": 886.0, "script": "So future directions for this work include running additional experiments to better understand the precise perceptual mechanisms at play here with shape, size, and color. Because our results suggest that there are a number of perceptual factors that determine how a shape influences size and color perceptions. And we wanna borrow from techniques used in vision science to better disentangle these factors and generate a more generalizable set of intuitions about shape separability. Also, simultaneous contrast effects can affect color perception, and to some extent, may affect size perceptions as well. So we'd like to study how separability between these channels might change using different background colors.", "ocrResult": ""}, {"index": 38, "startTime": 886.0, "endTime": 894.67, "script": "So the main takeaways from this work are that shape does significantly affect color difference perception and significantly affect size perception.", "ocrResult": ""}, {"index": 39, "startTime": 894.67, "endTime": 904.67, "script": "allowing us to adjust encodings for perceptual interference in one direction, without worrying about altering perceptions in the other.", "ocrResult": ""}, {"index": 40, "startTime": 904.67, "endTime": 920.67, "script": "is a little less understood than we previously thought, but separability can be modeled. And these models can be used to automatically adjust encodings, and improve visualization design, and thus increase interpretation accuracy.", "ocrResult": ""}, {"index": 41, "startTime": 920.67, "endTime": 1151.33, "script": "So thank you all for listening to this talk. And thanks to my advisor, Danielle Safer for her support on this project. And thanks to the NSF for funding this work. And I'd be happy to take any questions. (audience applauding) - [Moderator] Thank you. We have time for a couple questions. Over there, yes? Please remember to state your name. - [Dan] Hi, Dan Russel from Google. I'm wondering in your Mechanical Turk studies, to what extent you controlled for different conditions of the displays, because you don't know who you're getting really. They could have an ancient display. They could be running on a CRT for all you know. And so I've noticed when I've done my own studies like this, that there's huge variation between monitors, and I worry that that might affect some of these results, because for example, in some of the whiter colors we've seen, they just disappear if the monitor is not tilted at exactly correct angle. So how did you account for that kind of differences? - So that's a great point, and it is a trade-off for sure. It's a trade-off basically between control over viewing conditions. And I should say we didn't really apply strict control over viewing conditions through this study. But it's a trade-off of control over viewing conditions for more ecological validity, because our goal here is to not necessarily to learn the precise perceptual mechanisms at play with some of these interactions, but to really give visualization designers a more practical guide to use to improve their encodings. And so visualization designers also do not know the hardware setups of their users. And so it's definitely a trade-off and a limitation of the study, but we think that basically we recruited a very large number of participants to help mitigate that a little bit, and also we wanna just focus on the more practical guidelines to help real world designers. - [Audience Member] (mumbles) from the University of St Andrews. I was wondering, 'cause there's potentially a lot of combinations here, of visual variables that affect other variables. And just by showing the non-symmetry, you just multiply the whole thing by two. I was wondering whether you had any thoughts about how we can deal, not individually as researchers, but as a community to come up with models that are a little bit more comprehensive. How are we gonna build up this knowledge so that we get better, and it's not one individual study after another that we cannot combine? - Yeah, that's a great point. Basically, if we're able to get sort of an intuition as to the deeper causes of some of these interferences in perceptions, then we perhaps can run more control like vision-science-oriented experiments, kind of related to this previous question where we maybe strap people's heads in and get a real solid intuition of what's happening with the visual system. Then maybe we can run sort of a broader experiment that allows us to build more generalizable models, instead of, like you're saying, having to run specific experiment after specific experiment so I think, experiments like these might give us insight into how we can design future experiments to help address that. But I think it's a great point, yeah. - [Audience Member] Thank you. - [Moderator] And that's (coughs), excuse me, that's time. So let's thank Steve one more time and all of our presenters from this segment. (audience applauding)", "ocrResult": ""}], "topSections": [[["4 GENERAL METHODS", 0], ["5 SHAPE AND COLOR", 0], ["6 SHAPE AND SIZE", 0], ["7 DISCUSSION", 0], ["8 CONCLUSION", 0]], [["8 CONCLUSION", 0], ["6 SHAPE AND SIZE", 0.11571428571428571], ["4 GENERAL METHODS", 0.13], ["2 BACKGROUND", 0.24], ["7 DISCUSSION", 0.31]], [["5 SHAPE AND COLOR", 0.12], ["6 SHAPE AND SIZE", 0.14], ["7 DISCUSSION", 0.18], ["1 INTRODUCTION", 0.24], ["2 BACKGROUND", 0.24]], [["8 CONCLUSION", 0], ["7 DISCUSSION", 0.14], ["1 INTRODUCTION", 0.2], ["6 SHAPE AND SIZE", 0.21375], ["2 BACKGROUND", 0.28]], [["6 SHAPE AND SIZE", 0.1], ["1 INTRODUCTION", 0.19], ["5 SHAPE AND COLOR", 0.2], ["7 DISCUSSION", 0.2], ["2 BACKGROUND", 0.22]], [["8 CONCLUSION", 0], ["5 SHAPE AND COLOR", 0.105], ["7 DISCUSSION", 0.13], ["1 INTRODUCTION", 0.23], ["2 BACKGROUND", 0.45]], [["1 INTRODUCTION", 0.11], ["5 SHAPE AND COLOR", 0.11], ["2 BACKGROUND", 0.14], ["6 SHAPE AND SIZE", 0.19], ["7 DISCUSSION", 0.32]], [["6 SHAPE AND SIZE", 0.1], ["1 INTRODUCTION", 0.12], ["5 SHAPE AND COLOR", 0.15], ["2 BACKGROUND", 0.2], ["7 DISCUSSION", 0.33]], [["2 BACKGROUND", 0.16], ["4 GENERAL METHODS", 0.162], ["5 SHAPE AND COLOR", 0.17383333333333334], ["6 SHAPE AND SIZE", 0.21416666666666667], ["7 DISCUSSION", 0.22]], [["6 SHAPE AND SIZE", 0.13], ["2 BACKGROUND", 0.15], ["7 DISCUSSION", 0.16], ["4 GENERAL METHODS", 0.19], ["5 SHAPE AND COLOR", 0.32]], [["8 CONCLUSION", 0], ["3 CONDITIONS AND HYPOTHESES", 0.11], ["6 SHAPE AND SIZE", 0.1725], ["5 SHAPE AND COLOR", 0.1925], ["7 DISCUSSION", 0.38]], [["8 CONCLUSION", 0], ["4 GENERAL METHODS", 0.16], ["6 SHAPE AND SIZE", 0.20233333333333334], ["5 SHAPE AND COLOR", 0.21766666666666665], ["7 DISCUSSION", 0.25]], [["4 GENERAL METHODS", 0], ["6 SHAPE AND SIZE", 0], ["8 CONCLUSION", 0], ["7 DISCUSSION", 0.17], ["5 SHAPE AND COLOR", 0.585]], [["8 CONCLUSION", 0], ["2 BACKGROUND", 0.17], ["6 SHAPE AND SIZE", 0.21], ["5 SHAPE AND COLOR", 0.22], ["7 DISCUSSION", 0.31]], [["8 CONCLUSION", 0], ["6 SHAPE AND SIZE", 0.14833333333333332], ["2 BACKGROUND", 0.17], ["5 SHAPE AND COLOR", 0.2316666666666667], ["7 DISCUSSION", 0.32]], [["8 CONCLUSION", 0], ["2 BACKGROUND", 0.15], ["5 SHAPE AND COLOR", 0.19], ["3 CONDITIONS AND HYPOTHESES", 0.2], ["7 DISCUSSION", 0.27]], [["8 CONCLUSION", 0], ["3 CONDITIONS AND HYPOTHESES", 0.1], ["5 SHAPE AND COLOR", 0.16], ["7 DISCUSSION", 0.27], ["6 SHAPE AND SIZE", 0.31]], [["2 BACKGROUND", 0.12], ["5 SHAPE AND COLOR", 0.13], ["3 CONDITIONS AND HYPOTHESES", 0.14], ["6 SHAPE AND SIZE", 0.15], ["7 DISCUSSION", 0.28]], [["1 INTRODUCTION", 0.1], ["7 DISCUSSION", 0.14], ["6 SHAPE AND SIZE", 0.1435], ["2 BACKGROUND", 0.16], ["5 SHAPE AND COLOR", 0.39649999999999996]], [["2 BACKGROUND", 0.11], ["4 GENERAL METHODS", 0.15], ["7 DISCUSSION", 0.18], ["6 SHAPE AND SIZE", 0.21], ["5 SHAPE AND COLOR", 0.28]], [["8 CONCLUSION", 0], ["2 BACKGROUND", 0.1], ["7 DISCUSSION", 0.22], ["6 SHAPE AND SIZE", 0.29933333333333334], ["5 SHAPE AND COLOR", 0.3306666666666667]], [["8 CONCLUSION", 0], ["4 GENERAL METHODS", 0.122], ["7 DISCUSSION", 0.18], ["6 SHAPE AND SIZE", 0.25788095238095243], ["5 SHAPE AND COLOR", 0.2901190476190476]], [["8 CONCLUSION", 0], ["7 DISCUSSION", 0.17], ["5 SHAPE AND COLOR", 0.24175000000000002], ["6 SHAPE AND SIZE", 0.24625], ["4 GENERAL METHODS", 0.252]], [["4 GENERAL METHODS", 0], ["8 CONCLUSION", 0], ["6 SHAPE AND SIZE", 0.12], ["7 DISCUSSION", 0.3], ["5 SHAPE AND COLOR", 0.43]], [["8 CONCLUSION", 0], ["6 SHAPE AND SIZE", 0.15416666666666667], ["2 BACKGROUND", 0.17], ["7 DISCUSSION", 0.27], ["5 SHAPE AND COLOR", 0.32583333333333336]], [["4 GENERAL METHODS", 0], ["8 CONCLUSION", 0], ["5 SHAPE AND COLOR", 0.2], ["7 DISCUSSION", 0.23], ["6 SHAPE AND SIZE", 0.34]], [["4 GENERAL METHODS", 0], ["8 CONCLUSION", 0], ["7 DISCUSSION", 0.21], ["5 SHAPE AND COLOR", 0.2333333333333333], ["6 SHAPE AND SIZE", 0.42666666666666664]], [["8 CONCLUSION", 0], ["4 GENERAL METHODS", 0.12], ["7 DISCUSSION", 0.14], ["6 SHAPE AND SIZE", 0.2725], ["5 SHAPE AND COLOR", 0.4275]], [["8 CONCLUSION", 0], ["7 DISCUSSION", 0.11], ["4 GENERAL METHODS", 0.132], ["6 SHAPE AND SIZE", 0.3170833333333334], ["5 SHAPE AND COLOR", 0.3509166666666667]], [["4 GENERAL METHODS", 0], ["8 CONCLUSION", 0], ["5 SHAPE AND COLOR", 0.18], ["6 SHAPE AND SIZE", 0.29], ["7 DISCUSSION", 0.42]], [["4 GENERAL METHODS", 0], ["8 CONCLUSION", 0], ["5 SHAPE AND COLOR", 0.2025], ["6 SHAPE AND SIZE", 0.2575], ["7 DISCUSSION", 0.31]], [["8 CONCLUSION", 0], ["6 SHAPE AND SIZE", 0.13], ["5 SHAPE AND COLOR", 0.15], ["2 BACKGROUND", 0.16], ["7 DISCUSSION", 0.36]], [["6 SHAPE AND SIZE", 0], ["8 CONCLUSION", 0], ["5 SHAPE AND COLOR", 0.2115], ["2 BACKGROUND", 0.24], ["7 DISCUSSION", 0.32]], [["4 GENERAL METHODS", 0], ["8 CONCLUSION", 0], ["6 SHAPE AND SIZE", 0.15571428571428572], ["5 SHAPE AND COLOR", 0.2042857142857143], ["7 DISCUSSION", 0.46]], [["4 GENERAL METHODS", 0], ["8 CONCLUSION", 0], ["6 SHAPE AND SIZE", 0.168], ["5 SHAPE AND COLOR", 0.302], ["7 DISCUSSION", 0.38]], [["8 CONCLUSION", 0], ["5 SHAPE AND COLOR", 0.105], ["2 BACKGROUND", 0.17], ["6 SHAPE AND SIZE", 0.175], ["7 DISCUSSION", 0.3]], [["6 SHAPE AND SIZE", 0.11800000000000001], ["2 BACKGROUND", 0.13], ["3 CONDITIONS AND HYPOTHESES", 0.13], ["5 SHAPE AND COLOR", 0.172], ["7 DISCUSSION", 0.32]], [["6 SHAPE AND SIZE", 0.11], ["5 SHAPE AND COLOR", 0.15], ["2 BACKGROUND", 0.17], ["7 DISCUSSION", 0.22], ["1 INTRODUCTION", 0.23]], [["8 CONCLUSION", 0], ["1 INTRODUCTION", 0.12], ["7 DISCUSSION", 0.19], ["6 SHAPE AND SIZE", 0.21375], ["5 SHAPE AND COLOR", 0.33625]], [["6 SHAPE AND SIZE", 0.11875], ["5 SHAPE AND COLOR", 0.12525], ["4 GENERAL METHODS", 0.156], ["2 BACKGROUND", 0.16], ["7 DISCUSSION", 0.37]], [["6 SHAPE AND SIZE", 0], ["8 CONCLUSION", 0], ["2 BACKGROUND", 0.16], ["5 SHAPE AND COLOR", 0.16375], ["7 DISCUSSION", 0.41]], [["4 GENERAL METHODS", 0], ["5 SHAPE AND COLOR", 0], ["6 SHAPE AND SIZE", 0], ["7 DISCUSSION", 0], ["8 CONCLUSION", 0]]], "outline": [{"sectionTitle": "title", "startSlideIndex": 1, "endSlideIndex": 1}, {"sectionTitle": "2 BACKGROUND", "startSlideIndex": 2, "endSlideIndex": 7}, {"sectionTitle": "5 SHAPE AND COLOR", "startSlideIndex": 8, "endSlideIndex": 24}, {"sectionTitle": "6 SHAPE AND SIZE", "startSlideIndex": 25, "endSlideIndex": 28}, {"sectionTitle": "7 DISCUSSION", "startSlideIndex": 29, "endSlideIndex": 40}, {"sectionTitle": "end", "startSlideIndex": 41, "endSlideIndex": 41}], "weights": [-1, 10.14, 10.68, 11.517285714285714, 11.661785714285713, 11.649952380952382, 11.44995238095238, 11.30995238095238, -1], "similarityTable": [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.24, 0.0, 0.13, 0.0, 0.11571428571428571, 0.31, 0.0], [0.24, 0.24, 0.0, 0.0, 0.12, 0.14, 0.18, 0.0], [0.2, 0.28, 0.0, 0.0, 0.0, 0.21375, 0.14, 0.0], [0.19, 0.22, 0.0, 0.0, 0.2, 0.1, 0.2, 0.0], [0.23, 0.45, 0.0, 0.0, 0.105, 0.0, 0.13, 0.0], [0.11, 0.14, 0.0, 0.0, 0.11, 0.19, 0.32, 0.0], [0.12, 0.2, 0.0, 0.0, 0.15, 0.1, 0.33, 0.0], [0.0, 0.16, 0.0, 0.162, 0.17383333333333334, 0.21416666666666667, 0.22, 0.0], [0.0, 0.15, 0.0, 0.19, 0.32, 0.13, 0.16, 0.0], [0.0, 0.0, 0.11, 0.0, 0.1925, 0.1725, 0.38, 0.0], [0.0, 0.0, 0.0, 0.16, 0.21766666666666665, 0.20233333333333334, 0.25, 0.0], [0.0, 0.0, 0.0, 0.0, 0.585, 0.0, 0.17, 0.0], [0.0, 0.17, 0.0, 0.0, 0.22, 0.21, 0.31, 0.0], [0.0, 0.17, 0.0, 0.0, 0.2316666666666667, 0.14833333333333332, 0.32, 0.0], [0.0, 0.15, 0.2, 0.0, 0.19, 0.0, 0.27, 0.0], [0.0, 0.0, 0.1, 0.0, 0.16, 0.31, 0.27, 0.0], [0.0, 0.12, 0.14, 0.0, 0.13, 0.15, 0.28, 0.0], [0.1, 0.16, 0.0, 0.0, 0.39649999999999996, 0.1435, 0.14, 0.0], [0.0, 0.11, 0.0, 0.15, 0.28, 0.21, 0.18, 0.0], [0.0, 0.1, 0.0, 0.0, 0.3306666666666667, 0.29933333333333334, 0.22, 0.0], [0.0, 0.0, 0.0, 0.122, 0.2901190476190476, 0.25788095238095243, 0.18, 0.0], [0.0, 0.0, 0.0, 0.252, 0.24175000000000002, 0.24625, 0.17, 0.0], [0.0, 0.0, 0.0, 0.0, 0.43, 0.12, 0.3, 0.0], [0.0, 0.17, 0.0, 0.0, 0.32583333333333336, 0.15416666666666667, 0.27, 0.0], [0.0, 0.0, 0.0, 0.0, 0.2, 0.34, 0.23, 0.0], [0.0, 0.0, 0.0, 0.0, 0.2333333333333333, 0.42666666666666664, 0.21, 0.0], [0.0, 0.0, 0.0, 0.12, 0.4275, 0.2725, 0.14, 0.0], [0.0, 0.0, 0.0, 0.132, 0.3509166666666667, 0.3170833333333334, 0.11, 0.0], [0.0, 0.0, 0.0, 0.0, 0.18, 0.29, 0.42, 0.0], [0.0, 0.0, 0.0, 0.0, 0.2025, 0.2575, 0.31, 0.0], [0.0, 0.16, 0.0, 0.0, 0.15, 0.13, 0.36, 0.0], [0.0, 0.24, 0.0, 0.0, 0.2115, 0.0, 0.32, 0.0], [0.0, 0.0, 0.0, 0.0, 0.2042857142857143, 0.15571428571428572, 0.46, 0.0], [0.0, 0.0, 0.0, 0.0, 0.302, 0.168, 0.38, 0.0], [0.0, 0.17, 0.0, 0.0, 0.105, 0.175, 0.3, 0.0], [0.0, 0.13, 0.13, 0.0, 0.172, 0.11800000000000001, 0.32, 0.0], [0.23, 0.17, 0.0, 0.0, 0.15, 0.11, 0.22, 0.0], [0.12, 0.0, 0.0, 0.0, 0.33625, 0.21375, 0.19, 0.0], [0.0, 0.16, 0.0, 0.156, 0.12525, 0.11875, 0.37, 0.0], [0.0, 0.16, 0.0, 0.0, 0.16375, 0.0, 0.41, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], "scriptSentences": [[" Visualizations leverage a variety of visual channels to encode data and often combine channels to encode multiple data attributes at once.", " However, data represented using one channel may interfere with interpreting data along another.", " For example, visualizing one attribute using chroma and a second using lightness may degrade analysts\u2019 abilities to accurately interpret either attribute independently: shifting lightness makes it more difficult to estimate chroma and varying chroma may complicate lightness perceptions [30].", " Two visual channels are considered to be integral if encoding a data attribute using one channel interferes with selectively attending to the", " other.", " Conversely, two visual channels are considered to be separable if one channel can be attended to without interference from the other [48].", " Multivariate visualizations often leverage separable channels to design visualizations that allow analysts to accurately disentangle data along different dimensions.", " Channels such as size and color have conventionally been considered largely separable [70].", " However, recent research [19, 64, 65] challenges the separability of color and size, suggesting a need for a deeper understanding of the interplay between different visual channels to inform effective visualization.", " In this paper, we quantify the amount of perceptual interference between shape, size, and color.", " All three channels commonly encode values in many visualizations including maps and scatterplots.", " We measure how the interplay of shape, size, and color encodings influence our ability to distinguish data values along each channel and the symmetry of these effects.", " Understanding and quantifying the perceptual interference between these channels is vital to crafting visualizations that support accurate interpretation across multiple data dimensions.", " Our goal is to inform visualization designers and improve visualization effectiveness in the real world.", " We aim to achieve this by constructing actionable probabilistic models based on empirical evidence that can help predict how these visual channels interact with one another to recognize and account for potential biases in data analysis.", " Our experiments look at three major categories of shapes used in existing commercial tools: filled geometries, unfilled geometries, and open shapes inspired by quantitative texton sequences (QTonS) [71] modified based on designs employed in existing tools.", " Our experiments leverage empirically validated methods to construct actionable probabilistic models of value difference perceptions [64, 66].", " We apply these methods to model both color and size differences as a function of mark shape.", " Our findings suggest that mark shape significantly affects perceptions of both mark size and color.", " For example, people more readily discriminate colors mapped to filled shapes compared to unfilled shapes, and shapes such as \u22a4, \u25b2, and \u25a0 appear larger than equally sized +, \u25b3, and A shapes.", " Our results also indicate that these relationships are asymmetric: shape has a pronounced impact on size and color perception, while size and color have a smaller impact on shape perception for our tested ranges.", " We implemented the models constructed from our results as a D3 [6] extension that scales these channels based on known parameters of a visualization.", " Contributions: The primary contributions of this work are empirical measures and models that predict how perceived differences in color and size vary depending on mark shape.", " Our models replicate prior work showing the interdependence of size and color [65] and provide an in-depth quantitative", " analysis of the interplay between shape, size, and color in multivariate scatterplots.", " Our results allow for a more principled understanding of the separability of size, shape, and color for visualization design, providing empirically-grounded metrics for selecting between different encodings.", " These findings challenge current guidelines on separable and integral dimensions which we hope will spark future research around these principles rooted in empirical evidence from visualizations."], [" Shapes frequently encode categorical data in scatterplots.", " However, little empirical understanding exists to inform visualization designers about the effects of shape on interpreting data encoded using additional channels, such as color and size.", " We survey current empirical studies of separability from visualization and vision science to inform our work.", " Graphical perception measures the effectiveness of different visual channels for encoding data.", " These studies have explored how different visual channels might support a broad variety of tasks [57].", " For example, they rank how well various channels support value comparison [2, 18, 21, 27], estimating quantities from specific visualization types [33, 62], investigating biases in particular channels [7, 23], and exploring certain statistical quantities like correlation [31, 55].", " This work focuses on three visual channels\u2014shape, color, and size\u2014that prior studies have explored in isolation.", " For example, Skau & Kosara [62] measured how shapes factors in pie and donut charts affect interpretation accuracy.", " Ware [71] demonstrated how shape could encode ordinal data through Quantitative Texton Sequences (QTonS).", " We focus on shape encodings in scatterplots, where prior studies have primarily evaluated shape encodings for category discrimination tasks [39, 40, 68].", " For example, Burlinson et al.", " [12] found that closed shapes support faster comparison than open shapes and that combining open and closed shapes may introduce perceptual interference in selection tasks.", " These studies provide preliminary insight into how the visual system processes shape information in visualizations in order to effectively leverage shape to support multiple analysis tasks.", " Like shape, color is commonly used in a wide variety of visualizations.", " However, color perception is sensitive to viewing conditions [8, 36, 44, 46, 56, 58, 63] and visualization context [14, 52, 64, 65].", " In visualizations, color can encode both qualitative and quantitative patterns.", " Quantitative color encodings rely on mapping data differences to sufficiently visible perceptual differences.", " As a result, developers often use either designer-crafted tools such as ColorBrewer [9] to select robust encodings or interpolate between differences using color spaces like CIELAB [24].", " Additional features of", " a color encoding affect interpretation accuracy, such as semantic alignment with the data [41, 60] and colormap design [4, 5, 42, 47] (see Zhou & Hansen [72] and Bujack et.", " al.", " [11] for surveys).", " However, most studies of color encodings focus on color as an isolated cue.", " Color\u2019s sensitivity to mark geometries suggests that such an isolation assumption may provide only limited insight into how to effectively leverage color in visualizations [52, 64, 65].", " Size is conventionally considered a more robust channel for encoding data values.", " For example, Cleveland & McGill [20] demonstrated that size is more accurate than color for value comparison tasks.", " Heer et al.", " [33] studied the effect of chart size on comparing values in time series visualizations.", " In text visualizations, size may also introduce biases due to the mark shapes created by word structures [3, 23].", " We further explore how size-induced biases might influence separability in scatterplots.", " Many graphical perception studies have explicitly explored graphical perception in scatterplots.", " For example, several studies measured people\u2019s abilities to estimate correlation [31, 54, 61] and to detect (and even be primed to) value clusters [26, 59, 69].", " Several recent techniques leverage findings from graphical perception studies of scatterplots to automate scatterplot design for legibility [15, 43] and to predict perceptual attributes associated with scatterplot analysis such as similarity [49] or class separability [59].", " However, these investigations focus on analyses over either an entire design or a single channel.", " Multiclass and other multivariate scatterplots require designers to understand how different channels might interfere with data analysis across different subsets of dimensions.", " For example, mean position estimation is robust to multiple channels, but task performance varies with the salience of the channel employed [29].", " In this work, we extend recent efforts in graphical perception for scatterplots to explore perceptual interactions between task-relevant and task-irrelevant channels to quantify potential biases in multivariate scatterplots.", " Vision science traditionally describes separability as whether or not a dimension can be selectively attended to without interference from another dimension [28, 48].", " Such studies related to integral and separable channels generally center on conjunctive search [67]\u2014the process of identifying an object defined by multiple features, such as searching for a red X among a collection of blue X\u2019s and red O\u2019s.", " These studies aim to understand how the visual system processes an object\u2019s feature information.", " For example, Jenkins et al.", " [34] found that attentional selection in searching for targets of a specified shape and size operates in parallel, allowing people to search for shape and size simultaneously.", " Alternatively, color tends", " to attract attention more strongly than shape when searching for color-shape conjunctions [37].", " Research in psychology has shown an interdependence between visual channels such as hue and brightness [8, 13, 30].", " Pomerantz & Sager [51] found an interdependence between spatial configurations and symbol identification; however, the effect was asymmetric\u2014symbol shape affected perceptions of spatial arrangements significantly more than arrangement affected symbol recognition.", " Cheng & Pachella [17] challenged the definitions of integral and separable dimensions and instead argued that channels corresponding to psychological attributes (i.e., an attribute that can be selectively attended to) are separable and channels that do not are integral.", " Understanding of integral and separable channels in visualization has largely centered around expert heuristics [45, 70], with channels defined using terms like \u201cfully separable\u201d and \u201cno significant interference.\u201d Few studies have empirically explored interactions between separable channels in data visualizations.", " Acevedo & Laidlaw [1] found that people more precisely detect brightness differences than differences in other visual elements such as size or spacing in multivariate icon-based visualizations.", " Other studies have shown that quantity estimation is affected by both size and color [19, 23] with size perceptions being biased by specific hues.", " Spatial frequency and other factors of data complexity may influence the effectiveness of different color schemes depending on the target analysis task [52].", " Kim & Heer found that size may interfere with positional data encodings [35].", " More recent work has attempted to quantify such interactions between channels.", " For example, Stone et al.", " [64] and Szafir [65] modeled how mark size influences color perception, finding that larger and elongated marks increase our abilities to discriminate encoding colors.", " Demiralp et al.", " [25] studied the perceptual interactions between shape, size, and color similar to our study.", " They developed distance matrices based on Likert ratings, triplet comparison, and spatial arrangement tasks to help optimize visual encodings of color, shape, and size for discriminibility, quantifying categorical and ordinal differences along these channels.", " We instead leverage psychophysical methods to capture smaller shifts in numeric perception at the scale of just noticeable differences and also evaluate how specific facets of a mark\u2019s shape may systematically influence separability."], [" Our understanding of the separability of color, shape, and size encodings stems primarily from ordering tasks where participants compare large differences along each dimension [25, 70].", " However, many visualization tasks require analysts to analyze small variations, such as value differences in continuous data.", " Prior work [64, 65] quantified interactions between size and color using probabilistic models that predict", " viewer perception based on visualization parameters.", " In this work, we construct similar models quantifying interactions between size, shape, and color through four crowdsourced experiments: two primary experiments to study the effect of mark shape on color and size perception and two measuring the symmetry of these effects.", " We contextualize our investigation using scatterplots, which often use shape to distinguish categories of data points and color and size to encode continuous attributes.", " We tailor our experimental designs to reflect this scenario using the methodology from Szafir [65]\u2014a binary forced-choice comparison of two target marks analogous to comparing two data points in a visualization.", " We constructed a candidate set of 16 mark shapes sampled from common visualization tools, including D3, Tableau, Excel, and Matlab (Figure 2).", " These shapes form three categories: filled shapes, unfilled shapes, and open shapes inspired by quantitative texton sequences (QTonS) [71] modified based on designs used in existing commercial tools.", " For simplicity, we refer to these open shapes as modified QTons or mQTons.", " Our experiments tested shape, size, and color difference perceptions over six different mark sizes (6, 12, 18, 25, 37, and 50 pixels).", " All shapes were sized by filling a square box in either height or width as appropriate.", " We used these conditions to evaluate three hypotheses related to the separability of mark shape, size, and color:", " We anticipate that colors will be more discriminable on filled shapes than equivalent unfilled shapes (e.g., \u25a0 vs. \u25a1) and that mQTons having angles less than 90\u00b0 (e.g., B and \u2734) will perform comparable to filled shapes, while other mQTons will perform comparable to unfilled shapes.", " This hypothesis stems from prior work that shows colors become more discriminable as mark size increases.", " Filled shapes and mQTons such as B and \u2734 generally use a larger number of pixels compared to unfilled shapes and the other mQTons due to their density.", " We anticipate that density will exhibit similar gains.", " When two shapes are close in diameter, the viewer might integrate other attributes such as area or visual density, privileging filled shapes and dense QTons.", " Additionally, unfilled shapes indirectly produce a slightly smaller negative shape by enclosing an area within its border [16].", " This negative shape could interfere with size comparisons by directing viewer focus to the enclosed area.", " H3\u2014Interference between channels will be asymmetric: shape will more significantly affect color and size than either will affect shape.", " Based on our observations and results from prior studies [25], unless the shapes are too small or too close to the background color to be readily identified, we anticipate that people will reliably compare shapes regardless of color or size."], [" Our goal is to understand separability in ways that inform visualization designers working in the context of real-world displays.", " Display conditions such as ambient illumination, display gamma, and resolution mean that a single design may look different on different displays.", " As the number of potential conditions is too large to feasibly account for each independently, prior studies have used crowdsourcing to attain large numbers of real world samples that help account for this variance in aggregate [32, 53, 65, 66].", " These models, while limited in their abilities to account for the precise visual mechanisms at play, allow designers to predict perceptions in the real world with significantly higher precision than traditional laboratory models.", " Our experiments use a binary forced-choice design, asking participants to compare either the color, size, or shape of the two target marks.", " Participants saw a series of scatterplots rendered using D3 on a 375 x 250 pixel white background with 1 pixel gray axes without labels or numbers as shown in Figure 1.", " Each scatterplot contained two vertically aligned colored shapes embedded in a set of randomly selected gray distractor shapes.", " As the distance between marks can affect color perception [10], the two colored shapes were always rendered 125 pixels apart, approximating the width of foveal vision at arm\u2019s length.", " Marks in visualizations are not always evenly spaced, but fixing the distance between the compared shapes allows us to control for potential confounding effects.", " Marks differed on one tested dimension (shape, size, or color) by a fixed amount.", " We selected a set of six fixed sizes (6, 12, 18, 25, 37, and 50 pixels) based on those used in prior experiments [64, 65].", " As designers have no methods to estimate aspects of", " display resolution or viewing distance necessary for precise psychophysical calculations of visual angle, we present our results in terms of pixel sizes.", " We convert to visual angle for modeling, assuming a default pixel resolution of 96 PPI and a D65 whitepoint.", " according to a random sampling of a normal distribution (\u00b5 = 0.5, \u03c3 = 1.0).", " Distractor shapes intersecting any other shape in the scatterplot were removed.", " We adjusted each distractor\u2019s size by a random value between [\u221220%,20%] of the tested shape size to prevent distractor shapes from providing an anchoring size that might inadvertently support size comparisons.", " Distractor shapes add visual complexity to the scatterplots being rendered which helps us address the Isolation Assumption made in prior studies [65], increasing the ecological validity of our results.", " Each experiment consisted of four phases (1) informed consent and screening, (2) tutorial, (3) formal study, and (4) demographics questionnaire.", " The specific question phrasings will be given in each experiment\u2019s relevant sections.", " Participants first provided informed consent for their participation and, for studies involving color perception, completed an Ishihara test to screen for color vision deficiencies [38].", " While an online Ishihara test is limited due to variations in color representation across displays, it successfully caught color vision deficiencies in piloting.", " We additionally asked participants to self-report color vision deficiencies at the end of the study and excluded any participants self-reporting CVD.", " Upon successfully completing the screening, participants completed a series of tutorial questions to clarify any possible ambiguities in the experimental instructions.", " Participants had to answer all tutorial questions correctly to begin the formal study.", " During the formal study, each participant completed a fixed number of trials sequentially in random order to mitigate transfer (e.g., learning or fatigue) effects.", " Participants recorded their responses for each trial using the \u2019f\u2019 and \u2019j\u2019 keys, as in Stone et al.", " [64].", " Each scatterplot rested in the center of the page with the instructions, a reminder of keypress mappings, and a request to complete each trial as quickly and accurately as possible above the scatterplot.", " After each trial, a gray box covered the scatterplot for 0.5 seconds to mitigate potential contrast effects between subsequent trials.", " To ensure honest participation, each experiment contained several control trials with large differences between target marks.", " After completing all trials, participants reported basic demographic information and were compensated for their participation.", " We recruited 1,930 participants across four experiments using Amazon\u2019s Mechanical Turk.", " All participants were from the United States, between the age of 18 and 65 years old, and had an approval rating of 95% or greater.", " 181 of these participants (9.4%) were excluded from our analyses for either failing to correctly answer a majority of the engagement checks (trials that were considerably easier to get correct than regular trials), self reporting a color vision deficiency or abnormal vision, or having a mean response time less than 0.5 seconds (mean overall response time: 2.05 seconds).", " Across all our experiments, we collected equal numbers of samples for all combinations of our independent variables.", " Several of our independent variables were mixed-participants factors: they are counterbalanced between-participants with each participant seeing multiple settings of each variable.", " This allows us to balance statistical power with potential transfer effects.", " We analyzed effects from our independent variables using an ANCOVA treating interparticipant variation as a random covariate.", " All post-hoc analyses used Tukey\u2019s Honest Significant Difference Test (HSD, \u03b1 = .05)."], [" Our first pair of experiments measured the separability of shape and color by modeling color perception as a function of size for different shapes.", " The first experiment focuses on participants\u2019 abilities to accurately discern color differences for various mark shapes while the second leverages the same experimental paradigm to instead quantify the effects of color on shape perceptions, allowing us insight into the perceptual symmetry of this relationship.", " We conducted a 16 (mark shape, mixed) \u00d7 5 (color difference, within) \u00d7 3 (CIELAB axis, between) \u00d7 6 (mark size, within) mixed-factors study to measure the effects of mark shape on color difference perceptions in scatterplots.", " The general procedure for this experiment is outlined in the General Methods section.", " Stimuli.", " Our stimuli consisted of a series of fixed size scatterplots with two colorful marks (one mapped to a fixed color and the second to an adjusted color) embedded in a set of mid-grey (L\u2217 = 50) distractor marks.", " We generated a set of fixed colors by uniformly sampling the CIELAB gamut using 12.5 step increments along the L* axis and 12 step increments along both the a* and b* axes.", " We removed any colors from our sample that, when adjusted, fell outside of the CIELAB gamut or that fell too close to grey to avoid confusion with our distractor marks.", " This sampling process yielded 79 fixed", " colors where L* ranged from 30 to 65, a* ranged from -36 to 48, and b* ranged from -48 to 48.", " We mapped one of these fixed colors to one mark and adjusted the color of the second mark by a fixed color difference step along one axis of CIELAB.", " Steps corresponded to the size-adjusted JNDs tested in Szafir [65]: no difference, 0.5ND(50), 0.75ND(50), 1ND(50), 1.25ND(50), 1.5ND(50), and 2ND(50).", " Each participant saw target marks corresponding to two shapes rendered at six different sizes (6, 12, 18, 25, 37, and 50 pixels).", " Experimental Design.", " Participants were asked to compare two colorful marks of the same shape and report whether they were the same color or different.", " We used discriminability rate (the proportion of correctly identified color differences) as our primary dependent measure.", " Adjusted color axis was a between-participants factor, while mark size (measured as the shape diameter) and color difference were within-participants factors.", " Mark shape was a mixed-participants factor.", " We chose to vary size and color difference within-subjects to help account for variance from display configurations.", " Each participant saw two different tested shapes and each combination of shape \u00d7 size \u00d7 color difference (along either L*, a*, or b*) once.", " Shapes were pseudorandomly assigned to participants such that combinations of shape, size, and color difference were counterbalanced across all participants.", " Fixed color was randomly mapped to each trial, with each color tested once per participant.", " Each participant completed 79 trials, including 7 engagement checks to ensure honest participation.", " Results.", " We recruited 683 total participants for this experiment.", " We excluded 77 particiants from our analysis for either failing to correctly answer a majority of the engagement checks, self reporting a color vision deficiency or abnormal", " vision, or having a mean response time less than 0.5 seconds.", " We analyzed data from the remaining 606 participants (\u00b5age = 35.5,\u03c3age = 9.5, 296 male, 304 female, 6 DNR), resulting in 43,632 trials.", " We analyzed the effect of shape on color difference perception across experimental factors (shape, color axis, color difference, and size) using a four-factor mixed-factors ANCOVA with interparticipant variation treated as a random covariate.", " We report significant effects relative to our primary research questions and include full data tables and analysis scripts at https://bit.ly/2prjuRu.", " We found a significant effect of shape on color difference perception across all three axes in CIELAB (FL (15,590) = 7.5, p < .001, Fa (15,590) = 14.3, p < .001, Fb (15,590) = 19.6, p < .001).", " We found partial support for H1: in general, colors were significantly more discriminible for filled shapes than for unfilled shapes.", " For example, \u25a0 (\u00b5L = 56.5% \u00b1 3.0%,\u00b5a = 53.8%\u00b1 3.3%,\u00b5b = 58.4%\u00b1 3.0%) and \u25b2 (\u00b5L = 51.1%\u00b1 3.3%,\u00b5a = 48.7%\u00b1 3.3%,\u00b5b = 49.2%\u00b1 3.2%) significantly outperformed their unfilled counterparts, \u25a1 (\u00b5L = 46.1%\u00b1 3.3%,\u00b5a = 40.0%\u00b1 3.2%,\u00b5b = 41.8%\u00b1 3.3%) and \u25b3.", " (\u00b5L = 42.1%\u00b1 3.2%,\u00b5a = 34.4%\u00b1 3.2%,\u00b5b = 37.7%\u00b1 3.2%).", " mQTons, however, performed contrary to our expectations.", " Comparisons showed \u22a4 and + enabled significantly greater discriminability than unfilled shapes.", " For example, we found that color differences were perceived either significantly or marginally better across all three color axes when \u22a4 (\u00b5L = 48.5%\u00b1 3.3%,\u00b5a = 41.1%\u00b1 3.1%,\u00b5b = 37.8%\u00b1 3.2%) and+ (\u00b5L = 53.0%\u00b1 3.3%,\u00b5a = 39.4%\u00b1 3.2%,\u00b5b = 41.7%\u00b1 3.3%) were used compared to \u25b3 (\u00b5L = 42.1%\u00b1 3.2%,\u00b5a = 34.4%\u00b1 3.2%,\u00b5b = 37.7%\u00b1 3.2%) despite using fewer pixels.", " These mQTons provided comparable discriminability to", " filled shapes despite the lower density of colored pixels associated with the same size mark.", " Additionally, we found a significant effect of size on color difference perception across all three color axes (FL (5,600) = 34.3, p < .003,Fa (5,600) = 18.7, p < .001,Fb (5,600) = 21.9, p < .001).", " Colors were generally more discrimible when larger sizes were used (e.g., 50 pixels) compared to smaller sizes (e.g., 6 pixels) which replicates previous experimental results [65].", " Modeling Results.", " We used our data to construct a set of models using the methodology established in Stone et al.", " [64].", " Our models predict color discriminibility rates based on a mark\u2019s size and shape by computing 50% JNDs for each combination of shape \u00d7 size.", " We first used linear regression to fit a linear model through the origin to the mean discriminibility rate as a function of color difference for each combination of shape, size, and tested axis, resulting in 96 models for each color axis.", " All of these models provided significant fits to our experimental data (p < .05).", " We then computed 50% just noticeable color differences (JNDs) for each linear model and fit a second linear regression to these JNDs to model JND variation for each shape and axis as a function of inverse mark size, resulting in 48 total models (p < .05 for all models).", " We can normalize each axis in the CIELAB \u2206E metric according to the outputs of these models in order to generate a specific difference model for each tested shape.", " All of our models can be found at https://bit.ly/2prjuRu.", " Figure 3 summarizes the mean JNDs derived from our data for each combination of shape and axis aggregated over size, with error bars corresponding to the standard error of that mean to indicate each shape\u2019s sensitivity to size variation.", " We found that both the means and variance varied across different shapes.", " For L*, the mean JND in the least discriminable shape, (\u00b5JND = 10.07L*\u00b13.1%) was 54.7% larger than the most discriminable shape, \u2666 (\u00b5JND = 6.51L*\u00b13.2%).", " These results suggest that mark shape and color are not readily separable: a mark\u2019s shape can significantly shift our abilities to discriminate fine-scale color differences, providing preliminary evidence of significant perceptual interference of shape on color encoding perception.", " As in prior studies, color perceptions were sensitive to size variation.", " For example, the mean JND value for L* across all 16 shapes at our smallest fixed size (6 pixels) is 11.30\u2206L\u2217 but only 6.48\u2206L\u2217 for our largest fixed size (50 pixels).", " Our first experiment compared identical shapes to gauge the effect of shape on color perception and found evidence that color may not be strongly separable from mark shape.", " To evaluate the symmetry of our results, we repeated our experiment", " using an inverted experimental paradigm: we mapped two differing target shapes to a fixed color to measure the influence of mark color on shape perception.", " We conducted a 16 (shape, within) \u00d7 3 (CIELAB axis, between) \u00d7 6 (mark size, within) mixed-factors study following the general procedure outlined in the General Methods section.", " Stimuli.", " Shapes and sizes matched those from the first experiment.", " Each pair of target marks were mapped to a pair of shapes sampled with replacement from our candidate set, leading to 128 possible combinations of shape (112 differing pairs and 16 same-shape pairs).", " We sampled colors uniformly from the CIELAB gamut.", " We mapped each pair of marks to a single fixed color and one of our 128 shape pairs.", " However, because we did not vary colors within each trial, we were able to sample a larger proportion of the gamut.", " This sampling resulted in 168 total colors where L* ranged from 50 to 96 using 3.8 step increments, a* ranged from -80 to 80 using 20 step increments, and b* ranged from -60 to 80 using 20 step increments.", " We chose lighter colors (L* from 50 to 96) because in piloting, error rates were highest when colors were close to the background luminance.", " Experimental Design.", " Our experiment again used a binary forced-choice task measuring perceived shape difference across different mark colors.", " Participants were asked to compare the two colorful marks and report whether they were the same shape or different.", " We used the discriminability rate (the proportion of correctly identified shape differences) as our primary dependent measure.", " Fixed color was randomly mapped to each trial, with each color tested once per participant.", " Each participant completed 168 trials: one trial for each size and shape pair, four engagement checks, and 44 additional same-shape pairs to help balance the distribution of correct responses.", " Combinations of size, color, and shape were counterbalanced between participants.", " Results.", " We recruited 219 total participants for this experiment.", " 8 were excluded from analysis for either failing to correctly answer a majority of the engagement checks, self reporting a color vision deficiency or abnormal vision, or having a mean response time less than 0.5 seconds.", " We analyzed data from the remaining 211 participants (\u00b5age = 36.4,\u03c3age = 11.5, 63 male, 147 female, 1 DNR) resulting in 35,448 total trials.", " We analyzed the effect of color on shape difference perception across experimental factors (shape pair, color axis, and size) using a three-factor mixed-factors ANCOVA with interparticipant variation treated as a random covariate.", " We found a significant effect of L* on accuracy of perceived shape differences (F (1,209) = 1.7, p < .03).", " However, Figure 4a shows that the magnitude of this effect is small, and significant variation in accuracies were only seen for colors with extremely high L* values: the accuracy difference between", " the highest and lowest L\u2217 values was 4.4%.", " However, this behavior was asymptotic: we saw only observed degradation in shape perception beyond L\u2217 = 92.", " As we measured these perceptions against a white background, this lightness value is near the threshold where the shapes will become difficult to distinguish from the background.", " We also found a significant interaction between shape and L* on shape perception (F (15,195) = 3.5, p < .01), with pairs integrating B generating slightly lower overall accuracy (\u00b5L = 93.3%\u00b1 2.2%).", " We anticipate that the fine features on this shape are especially sensitive to the observed lightness threshold.", " While the two dimensions (color and shape) are not immediately comparable, the large difference in the magnitude of the observed effects coupled with the asymptotic behavior we find in shape discrimination suggests that the effect of shape on color perceptions is significantly stronger than that of color on shape perceptions, indicating an asymmetry in the separability of these two channels (H3)."], [" Our first study showed that mark shape, color, and size may not be separable: changing shapes can dramatically influence both perceived color difference and its sensitivity to changes in size.", " This interaction may be a result of mark shape biasing perceived size.", " To further explore the relationship between mark shape and size, we conducted a second pair of experiments measuring the separability of shape and size directly.", " Experiment Three measures how accurately participants can discern size differences for our 16 mark shapes to measure size perception biases between different shapes, while Experiment Four inverts Experiment Three to explore the effects of size on shape perception.", " We conducted a 16 (shape, within) x 6 (fixed size, within) x 4 (size difference, within) mixed-factors study to measure", " the effects of shape on size difference perceptions in scatterplots.", " While our independent variables were tested withinparticipants, combinations of these variables were counterbalanced mixed-participants factors to avoid fatigue affects given the large number of possible combinations.", " Stimuli.", " For this experiment, participants were shown a series of scatterplots as described in the General Methods section with two bright blue shapes embedded within a field of gray distractor shapes.", " We chose a bright blue (L* = 32, a* = 79, b* = -107) to highlight the two tested shapes and ease visual search.", " Shape pairs were drawn from the combinations of our 16 tested mark shapes resulting in 120 shape pairs.", " Fixed sizes mirrored those in Experiment One, with one shape rendered at the fixed size and the second adjusted by adding 5%, 10%, or 15% to its diameter.", " These thresholds ranged from approximately one to two 50% JNDs for sameshape pairs in piloting.", " We elected to vary diameter rather than area as our size differences are small, and the geometries of tested shapes complicate normalizing areas between shape pairs.", " Diameter variation for continuous values in scatterplots is currently employed in tools like Tableau.", " To mitigate potential effects from aliasing, the actual adjusted differences in pixels were rounded to the nearest whole pixel.", " We reduced the set of adjusted sizes for our smallest marks as to remove any duplicate sizes caused by rounding errors.", " Experimental Design.", " The general procedure for this experiment is outlined in the General Methods section.", " Participants reported which of the two blue shapes appeared to be greater in size.", " Our primary dependent measure was the accuracy rate (how often the larger of two shapes was correctly identified as largest).", " For equal sized pairs, an unbiased percept should lead to a 50% response rate.", " The tutorial instructed participants to consider size the greater of a mark\u2019s height or width to clarify potentially ambiguous conditions (e.g., those where size may disagree on any single dimension, such as \u2212 and \u2666).", " While this clarification does add complexity to the task, participants had to correctly answer five tutorial questions", " to ensure they understood how size was being defined in the experiment before proceeding to the main study.", " In the formal study, each participant saw each shape combination once and each combination of fixed size and size difference five times, with combinations of shape pair, fixed size, and size difference mapped pseudorandomly and counterbalanced between participants.", " Each participant completed 123 trials including three engagement checks (trials where the shapes differed in length by 50%) to ensure honest participation.", " Results.", " We recruited 548 total participants for this experiment.", " 59 participants were excluded from analysis for either failing to correctly answer a majority of the engagement checks, self reporting a color vision deficiency or abnormal vision, or having a mean response time less than 0.5 seconds.", " We analyzed data from the remaining 489 participants (\u00b5age = 36.5,\u03c3age = 11.6, 192 male, 293 female, 4 DNR) for a total of 60,147 trials.", " We analyzed the effect of shape on size difference perception across our experimental factors (shape, fixed size, and size difference) using a four-factor ANCOVA.", " Shape was broken up into two factors: bigger shape (bs) and smaller shape (ss) based on the size differences discussed above.", " We found a significant effect of shape on size perception (Fbs (15,473) = 943.9, p < .001,Fss (15,473) = 940.2, p < .001).", " Post-hoc comparisons showed that shapes having greater visual density along the top or bottom of the shape were generally perceived as having greater diameter (e.g., \u22a4, \u25a0, \u25a1, \u00b5 = 78.68%\u00b19.90%).", " Additionally, filled shapes were generally perceived as larger than their unfilled counterparts, partially supporting H2.", " Contrary to H2, higher-order mQTons (e.g., \u2734, B, +, \u00b5 = 46.93%\u00b1 7.16%) in general were consistently perceived as smaller than less dense shapes.", " We also found a significant effect of fixed size on difference perception (F (5,483) = 19.8, p < .001).", " Participants compared sizes more accurately for larger fixed sizes (e.g., 50 pixels: \u00b5 = 69.7%\u00b1 1.0%) than for smaller fixed sizes (e.g., 6 pixels: \u00b5 = 64.9%\u00b1 1.1%).", " We also found a significant interaction effect between bigger shape and smaller shape (F (209,279) = 11.9, p < .001).", " This effect shows that certain pairs of shapes can also skew size perception.", " Modeling Results.", " We fit our data to a set of psychometric functions that predict size perception based on the two shapes being compared, the fixed size, and size difference to model relative size perceptions as a function of the signed size difference between the two shapes.", " We elected not to include data involving our smallest fixed size (6 pixels) in our modeling because only three total size differences (compared to five and seven for our other fixed sizes) could be rendered within the desired range (-16.7%, 0%, and 16.7% corresponding to 5, 6, and 7 pixels).", " After removing our smallest fixed size, we", " constructed 600 models corresponding to each shape pair \u00d7 fixed size combination, excluding same shape pairs.", " Of these 600 models, 558 (93%) of them provided significant fits to the data (p < .05).", " We can use the y-intercept of these models to estimate the likelihood that one shape will be perceived as larger than another for any pair of shapes.", " Figure 5 shows the mean bias for each tested shape computed using our models.", " This figure shows biases consistent with our inferential observations: shapes with visual mass near the top or bottom of the shape tend to be seen as larger overall (e.g., \u25a0 compared to +).", " By seeding our functions according to target visualization parameters, we can use the well-fit models generated from this data to normalize our size computations between encoding shapes to help account for potential biases in size perceptions due to shape.", " Our results suggest that this bias can be quite substantial: for example, \u22a4 shapes were perceived as larger than any other tested shape in 82% of trials whereas \u22c6 shapes were only reported as larger in 27% of trials.", " This bias suggests that separability between data attributes encoded using shape and size is limited as certain shapes are likely to be perceived as significantly larger even if rendered at comparable sizes.", " A full list of models is available at https://bit.ly/2prjuRu.", " Due to the substantial biases in perceived size differences between tested shapes, we conducted a 16 (shape, within) \u00d7 6 (fixed size, within) \u00d7 4 (size difference, within) mixedfactors study to measure the symmetry of these effects of", " size on shape perception in scatterplots.", " While our independent variables were tested within-participants, combinations of these variables were counterbalanced mixed-participants factors to avoid fatigue affects given the large number of possible combinations.", " Our primary dependent measure was the discriminability rate (how frequently participants correctly reported shape differences).", " Experimental Design.", " The general procedure for this experiment is outlined in the General Methods section.", " Participants again saw a series of scatterplots containing two bright blue shapes within a field of gray distractor shapes.", " Shape sizes matched those tested in Experiment Three, with each scatterplot mapping shapes to a single target size.", " Similar to Experiment Two, participants were asked if the two blue shapes in the scatterplot were the same shape or different.", " Each participant saw 168 trials corresponding to 120 shape pairs plus an additional 48 same-shape pairs.", " Trials that rendered shapes at the largest size (50 pixels) were used as engagement checks.", " Shape, fixed size, and size difference were distributed across trials identically to Experiment Three.", " Results.", " We recruited 480 total participants for this experiment.", " 37 were excluded from analysis for either failing to correctly answer a majority of the engagement checks, self reporting a color vision deficiency or abnormal vision, or having a mean response time less than 0.5 seconds.", " We analyzed data from the remaining 443 participants (\u00b5age = 37.2,\u03c3age = 12.5, 167 male, 275 female, 1 DNR), resulting in 74,424 total trials.", " We analyzed the effect of size on shape perception across our experimental factors (shape, fixed size, and size difference) using a four-factor mixed effects ANCOVA.", " Shape was again broken up into two factors: bigger shape (bs) and smaller shape (ss) based on the size differences discussed above.", " We found a significant effect of size (F (5,437) = 47.3, p < .001) as well as size difference (F (3,437) = 8.5, p <", " .001) on the rate of perceived shape differences.", " Similar to Experiment Two however, the magnitude of this effect is small, and significant variation in accuracies are only seen for our smallest fixed size (6 pixels, Fbs (75,367) = 1.5, p < .01,Fss (75,367) = 1.9, p < .001).", " The difference in shape discriminability between 50 pixel shapes and 6 pixel shapes was 4.5%.", " As with color, the observed behavior again appears to be asymptotic for small shapes.", " One possible explanation for this effect is that the shapes have become sufficiently small that fine resolution details can no longer be efficiently rendered or detected.", " However, further testing is needed to confirm this hypothesis.", " Our results again suggest an asymmetry between effects of shape on size and size on shape for our tested mark parameters: accuracy differences for size perceptions across shapes were much larger than those for shape perceptions at varying sizes.", " We are limited in our abilities to directly compare shape and size as differences along these two encoding vectors as our sampled sizes and shapes are not necessarily aligned in their difficulty; however, as with color, we see that these asymmetries hold across even large size differences.", " The two experiments also use the same set of parameters and stimuli, but generate significantly different results, further indicating an asymmetry in the separability of size and shape."], [" We measured the separability of shape, size, and color in multiclass scatterplots to understand the perceptual interplay of these encodings.", " Our results show:", " \u2022 Shape significantly affects color difference perception: Colors were more discriminible when filled shapes were used compared to unfilled shapes.", " Shapes such as \u22a4 and + performed comparably to denser shapes.", " \u2022 Color has some effect on shape perception: Extremely light colors complicated shape perceptions but the magnitude of the effect was small.", " \u2022 Shape significantly affects size perception: Sizes were perceived to be greater for shapes that contain more visual density on the top or bottom of the shape (e.g., \u22a4, \u25a0, \u25a1).", " Filled shapes were perceived as larger than their unfilled counterparts.", " \u2022 Size has some effect on shape perception: Extremely small sizes complicated shape perceptions but the magnitude of the effect was small.", " Color difference perception accuracy was generally highest when filled shapes were used, partially supporting H1.", " Our results also replicated results from previous experiments (Szafir [65] and Stone et al.", " [64]), showing that color difference perception varies proportionally to mark size.", " However, contrary to our expectations, color difference perceptions in open shapes were not well explained by shape density.", " We", " expected the less dense mQTons (\u2212, \u22a4, , and +) to perform similar to unfilled shapes, and the denser mQTons (B and \u2734) to perform similar to filled shapes.", " However, we found no clear patterns in mQTon shape and color perceptions.", " For example, our fourth mQTon (+) outperformed other mQTons for the L* and b* axes in CIELAB and had similarly high discriminability for a*.", " This shape uses fewer pixels than B and \u2734, and uses a comparable number of pixels to \u22a4 and , yet consistently supported higher discriminability.", " This preliminary evidence suggests that there may be alternative mechanisms that cause the biases observed in our data.", " One phenomenon that could be affecting color perceptions for mQTons is illusory contours [50].", " For example, viewers could be perceiving an illusory unfilled cube when looking at , or an illusory circular border around B and \u2734.", " These illusory contours may cause our visual system to blend the shape color with the background color.", " However, we would need to further test these hypotheses in a laboratory environment to ascertain the precise factors involved in mQTon perception.", " Our second experiment demonstrated an asymmetry in the perceptual interdependence of color and shape: only extremely light colors that are rarely used in practice significantly degraded shape perceptions.", " This effect is likely caused by participants either not being able to find target shapes or not being able to resolve the details of the target shapes because the background color of the scatterplot (white) and the light-colored target shapes are not sufficiently discriminable.", " This limited effect suggests an asymmetric relationship exists between shape and color: shape much more strongly affects color perception than vice versa, supporting H3.", " We anticipated some of the variation we saw in our first pair of experiments may be explained by variations in size perceptions across shapes: if some shapes appear larger, they may also support greater discriminability.", " Our results showed that filled shapes are generally perceived as larger than unfilled shapes, partially supporting H2.", " Holes created by unfilled shapes may cause people to attend to the negative shape created by the hole and causing unfilled shapes to appear smaller.", " However, if we group shapes generally perceived as larger (e.g., \u22a4, \u25a0, and \u25a1), only one of these shapes is filled.", " Our results suggest that visual density along the top or bottom of a shape is a more significant determinant of perceived size biases.", " The two target shapes in our stimuli were always vertically aligned, which may partially explain these results; however, shapes like \u2666 also span the full vertical mark space.", " Our results also suggest that the variations seen in Experiment One cannot be explained by mark size biases.", " For example, \u2666 generally provided high discriminability; however, it was perceived as smaller than 12 of our 15 tested marks.", " Similarly, + provided the best color discriminability of all mQTons, but was perceived as smaller than 4 of the 5 tested mQTons.", " Future studies in laboratory environments would help us better", " understand the perceptual mechanisms behind shape, color, and size interference to evaluate these hypotheses.", " We found a limited effect of size on shape perception; like Experiment Two, the magnitude of this effect was substantially smaller than the effect of shape on size and only present for the smallest tested mark sizes, again supporting H3.", " When mark size is extremely small (smaller than any practical visualization would use), shapes may not render accurately due to the limited amount of pixel space.", " This would lead to a decrease in shape perception accuracy as the geometry of the shape itself would change.", " As our goal is to improve visualization effectiveness in the real world, it is important to consider how these results might also affect higher level tasks such as correlation or average.", " While we evaluate binary comparisons, these shifts likely affect higher level tasks.", " Errors while performing higher level tasks are likely to be as high as those for comparison tasks as the perception of each individual mark is skewed, which skews the overall distribution.", " For example, scatterplots using \u25a0 and B to categorize datapoints and using a color encoding could potentially skew correlation or average interpretations because colors are more discriminable on \u25a0 compared to B which would skew the overall distribution of color differences perceived.", " Our modeling approach allows us to approximate these errors and shift encodings appropriately.", " Separable versus integral channels have always been important guidelines for visualization designers because understanding how viewers will perceive the information being presented is critical for maximizing visualization effectiveness.", " Our results collectively suggest that shape, size, and color are significantly less separable than conventionally thought.", " These results show strong asymmetries among these visual channels.", " This work offers quantified empirical guidance for reasoning about and accounting for integrality in multivariate visualizations.", " While crowdsourcing allows us to model visualization perception in real-world contexts, it represents a trade-off of control for ecological validity.", " This trade-off is well-studied in graphical perception [22, 25, 32, 42, 52], but does limit our results in notable ways.", " For example, hardware settings could cause colors to appear brighter or more discriminable for some participants.", " We recruited a large number of participants to account for this limitation, and our results from Experiment One closely replicate results from prior studies that show an interdependence between color and size, including both laboratory studies [14] and our own work with web-based visualizations [64, 65].", " Variation in screen resolution could cause marks to appear different in size for different participants.", " While we use absolute pixel sizes in our experiments, our models emphasize the relative difference in mark sizes", " which are consistent despite variation in screen resolution and consistent with visualization encodings.", " Because of this, our results focus on the ordinal nature of our tested sizes rather than the absolute pixel size.", " Additionally, anti-aliasing could cause some lines to be rendered slightly differently for different participants since anti-aliasing is based on browser configuration.", " To help mitigate the influence of this, we use D3 [6], one of the most popular visualization libraries, which renders SVGs that leave rasterization to the browser and beyond a visualization designer\u2019s control.", " Anti-aliasing would substantially impact shapes containing lines less than a pixel wide which would only affect our smallest tested size (6 pixels).", " We elected to remove samples involving 6-pixel marks from our models constructed from Experiment Three.", " The primary goal of this work is to inform visualization designers and improve visualization effectiveness in the real world.", " Designers rarely know the hardware settings and environment of the viewer, so the choice to use crowdsourcing for these experiments simulates what designers work with in the real world.", " Our experiments used a limited sample of shapes, sizes, and colors but generally kept the samples within the range of practical visualizations.", " Future work could use different backgrounds and more carefully controlled mark shapes.", " Further, we used limited samples to control for the large number of conditions.", " Future work could increase the number of samples integrated into our models to reduce model variance and to allow for a more in-depth statistical evaluation of model variation across each condition.", " Conventional guidelines around size encoding often recommend using area rather than diameter.", " We chose to use diameter to encode size to provide consistency in how we normalized and adjusted shapes with very different geometries and because our size manipulations were sufficiently small that we anticipate the differences in diameter and area encodings were negligible.", " This decision is well-grounded in common visualization tools: several visualization tools used in the real world, such as Tableau, encode size using diameter.", " However, future experiments should confirm these results hold for other size encodings such as area.", " While our results show disadvantages to using unfilled shapes with respect to color and size biases, unfilled shapes can help disambiguate marks that are overlapping.", " For example, Tableau uses unfilled shapes by default to avoid overdraw in scatterplots.", " Extending these studies to consider scatterplots with overdraw would further illuminate trade-offs in using filled versus unfilled shapes in multivariate visualizations.", " The lack of an easily discernable mapping between mark geometry, size perceptions, and color perceptions make it", " difficult for people to account for potential biases created in multidimensional scatterplots and other visualizations combining these encodings.", " The measures and models constructed in this work can be used to make adjustments to the color and size ranges used in these visualizations as a function of mark shape in order to improve visualization effectiveness.", " To support the use of these models in practice, we have implemented the models constructed from Experiment One as a D3 extension (which can be found here: https://bit.ly/2prjuRu) to normalize color encoding scales according to the size and shape parameters of a target visualization.", " This package takes parameters such as mark size and shape and returns the minimum distance (\u2206E in CIELAB) that mark colors need to be apart so that 50% of the population will perceive a difference to support perceptually corrected color interpolation.", " By integrating these models into a common visualization tool, we hope to allow developers to fluidly account for interference between these channels to generate more effective multidimensional visualizations."], [" In this paper, we measure how the interplay of shape, size, and color encodings influence our ability to distinguish data values along each channel and measure the symmetry of these effects.", " Our results suggest that shape, size, and color are less separable than conventionally thought and that some of this variation can be readily modeled.", " We found that colors are generally more discriminible when filled shapes are used compared to unfilled shapes and shapes such as + and \u22a4 performed comparably to denser shapes despite using fewer pixels.", " We also found preliminary evidence that shapes containing more visual density along the top or bottom edges (e.g., \u22a4, \u25a0, \u25a1) are perceived as larger than shapes that do not (e.g., \u2212, +, \u22c6).", " These effects appear asymmetric\u2014shape more strongly affects color and size difference perception than color or size affect shape perception.", " From our experimental results, we constructed models that predict viewer perception based on what shapes are being used in a scatterplot and implemented these models as an extension in D3.", " We hope that this work can be used to spark future research to construct new guidelines for separable and integral visual channels grounded in empirical evidence."]], "paperSentences": ["", "- Hello everyone. So I'm gonna present a set of experiments that show how our traditional notions of separability, essential tendon in visualization design falls short, and how we can fix them. ", "So consider this simple scatter plot where I've encoded two data dimensions using position. We can encode additional data into this scatter plot using visual channels such as color, size, and shape. But how do these visual channels interact with one another perceptually? For example, if I encode one data dimension using shape, will it change the way I perceive color or size differences between marks? So this work models the perceptual interplay between these channels. And using these models, we can anticipate and account for potential errors that people might make when interpreting multi-variant visualizations. ", "So we can encoded data dimensions using various visual channels, such as position, size, shape, and others. ", "of separable versus integral channels. So separable channels is when one channel can be attended to without any interference from the other. So for example, if I encode data using position as the first channel, and encode additional data using color as the second channel, I can determine the position of these marks, no matter what color they are. And I can determine the color of these marks, no matter where they are in the scatter plot. So there's no interference. ", "Conversely, integral channels is when encoding a data attribute using a visual channel interferes with selectively attending to the other. For example, if I encode data using lightness as the first channel, ", "So here I have an ordered list of visual channel pairs where pairs at the top are known to be more integral, and pairs at the bottom are known to be more separable. But the specific ordering of this list is primarily derived from intuition and experience with limited empirical support. And these heuristics have been widely used by visualization designers, but their actual utility is poorly grounded, leaving users open to potentially significant data interpretation errors. ", "So we aim to provide designers with more concrete guidelines about reasoning, about separability. And we do this by empirically measuring the amount of separability between channels, and then constructing actionable models that we can use to support visualization design by automatically adjusting encodings to account for perceptual interference. ", "We constructed these models using data collected from 1,930 participants on Mechanical Turk, across four different experiments. And I'm gonna discuss two of these experiments in detail, and I'll also discuss how we can use the results from these experiments to craft more effective multi-variant visualizations. Okay, so getting into the experimental design, ", "here's an example stimuli from one of our experiments. And for each data plot, participants were asked to compare two target marks and indicate whether they were the same or different on some specified dimension. ", "We tested 16 different shapes gathered from common vis tools like Tablo, and MATLAB, and Python, and others. And these shapes can be broken up into three major categories: filled, unfilled, and open shapes. ", "We tested six different mark sizes ranging from six pixels to 50 pixels in diameter based on those used from prior experiments in this area. ", "And we tested a variety of colors that differ along the lightness axis, the red-green axis, and the yellow-blue axis in the CIELAB color space. ", "CIELAB is commonly used in visualizations because it's approximately perceptually uniform, meaning one unit in Euclidean distance, equates to one just noticeable difference, or JND for short. And we define a JND as the minimal amount of distance that two colors need to be apart for 50% of people to actually perceive a difference. Now this point about one unit of Euclidean distance equating to one JND, actually doesn't hold in practice, because CIELAB assumes specific conditions for comparing colors, like very large isolated marks. And that's just often not the case in visualizations. ", "For example here, I've encoded a scatter plot using seven different colors that are each separated by one Euclidean distance in this color space. Theoretically we should be able to discern small differences in these colors that would equate to small differences in the data. But as you can see, it's hard to determine these differences, it's hard to discern these color differences from marks of this shape and size. This means any meaningful small scale differences in the data that these colors in code are lost. ", "So drawing from prior work and visualization and vision science. We derived three general hypotheses related to these experiments. First, we expect colors to be more discriminable on denser shapes. And this hypothesis stems from prior experiments that have shown that color discriminability is proportional to mark size. ", "Secondly we expect denser shapes to appear larger. And this hypothesis stems from the idea that when comparing the size of two marks, users might resort to other aspects of the marks, such as density, which could alter perceived size. ", "between these channels to be asymmetric. In other words, we expect shape to more strongly influence color and size perceptions. Then either color or size would influence one's ability to perceive a marked shape. ", "Okay, so let's get into the first experiment, which explores interactions between shape and color. ", "So this experiment specifically looks at how using different shapes in a scatter plot might affect color difference perception. Here's an example stimuli from the experiment. And the scatter plot consists of a field of gray distractor shapes with two color shapes that are either the same color or slightly different colors. And we asked participants to indicate whether these colored marks were the same or different colors, which allows us to model JND values for different marks, sizes, and shapes. ", "We used a full factorial mixed factors design for this experiment where we tested 16 different shapes, ", "We tested all three axes at CIELAB between. ", "And we recruited 606 participants for this study. And if I didn't mention it before, we're using Amazon Mechanical Turk. ", "So getting into the results, what we're looking at here is color discriminability results associated with three of our 16 tested shapes. Where the X axis denotes mark size and pixels, and the Y axis shows us the mean 50% JND for lightness differences. And we're gonna focus on lightness for the purpose of this talk because lightness is the most important aspect of color discriminability for numerical encodings. And to remind you, a JND is the minimal amount of distance that two colors need to be apart such that that difference is detected half the time. So looking at this graph, we can see that colors become more discriminable as mark size increases, because a lower value means more discriminable. But we can also see that depending on the mark's shape, the JND values are different. For example, we see a 50% reduction in discriminability for six pixel Y crossings, compared with filled squares, suggesting that the shape of a mark also influences color discriminability. ", "So the primary takeaways from this first experiment are that shape does significantly affect color difference perception, where, for example, the filled diamond had a mean JND of about 6 1/2, while the Y crossing had one of over 10 which is a substantial difference. And also, this experiment replicates results from prior studies that show that color discriminability is proportional to mark size. ", "So our first experiment showed that color discriminability varies with shape. And we hypothesized that this variation may be explained by a variation in perceived size. So shapes that are perceived as larger, might be more discriminable. So we ran another experiment to test this hypothesis that looks at shape and size. ", "Participants in this experiment saw a scatter plot like this with two target marks highlighted in blue. And they were asked to determine which of the two highlighted shapes appears larger. ", "We again, used the full factorial design, where each participant completed 123 trials. And we tested the same set of shapes and sizes from the previous experiment. ", "We recruited 489 participants for this study. ", "So this graph summarizes the results of our study using the mean size bias for each tested shape. The X axis here shows the percentage of the time that a particular shape was perceived as larger than other shapes of the exact same size. So if there was no bias due to shape, we would expect these values to hover around 50%. But we see significant variation from this threshold. Now if we look at the mean size bias for the filled shapes and compare that to the unfilled shapes, we generally see that the filled shapes are perceived as larger than their unfilled counterparts. For example, the filled circle is perceived as larger in 67% of trials, while the unfilled circle is only perceived as larger in 49% of trials. So this pattern supports our hypothesis that denser shapes would be perceived as larger. But we don't see the same pattern in open shapes. For example, the T crossing is seen as larger in 82% of trials, while the denser 8 prong asterisk is seen as larger in only 54% of trials. And overall we see no evidence that denser shapes, denser open shapes appear larger. Also we found that the patterns in perceived size don't well explain the patterns in color discriminability that we saw from experiment one, suggesting something more complex is at play here. ", "So the main takeaways from this second experiment is first that shape does significantly affect size perception where some shapes are perceived as larger more than 80% of the time when compared to other shapes of the same size. And color discriminability for our tested shapes is not well explained by the perceived size of the shape. ", "So we also ran a pair of experiments that explore the symmetry of these relationships. And we care about symmetry because if perceptional interference functions asymmetrically, then we can adjust encodings to account for interference in one direction without worrying about it altering perceptions in the other direction. But for the sake of time, I'm not gonna go into detail about these experiments. So I'll just tell you that we found that color and size have much less of an effect on shape perception than we have seen shape have on size and color perception. ", "So lastly, I wanna close by summarizing our results and showing how we might use this data to construct more affective visualizations. ", "that colors would be more discriminable on denser shapes like with the filled shapes compared to the unfilled shapes. But we also found evidence contrary to this hypothesis among the open shapes. ", "And we found some support for our hypothesis that denser shapes would appear larger. For example, the filled shapes compared with their unfilled counterparts. But again we found some evidence contrary to this hypothesis. And in general, the perceived size of a shape didn't well explain the color discriminability results from the first experiment. ", "that shows an asymmetry between these channels. Shape had a much stronger affect on color and size perceptions than color or size had on shape perceptions. But again, see the paper for more details on these experiments. ", "Okay, so we can use the models constructed from the results to build more effective multi-variant visualizations. And if we revisit our example earlier from the talk that used one Euclidean distance JNDs, which is standard in CIELAB. We lost differences in our data, because we should, theoretically, be able to see seven values here. But we can instead adjust to these color steps based on the modeled perceptual interference between shape, size, and color, and compute new JND values. ", "So future directions for this work include running additional experiments to better understand the precise perceptual mechanisms at play here with shape, size, and color. Because our results suggest that there are a number of perceptual factors that determine how a shape influences size and color perceptions. And we wanna borrow from techniques used in vision science to better disentangle these factors and generate a more generalizable set of intuitions about shape separability. Also, simultaneous contrast effects can affect color perception, and to some extent, may affect size perceptions as well. So we'd like to study how separability between these channels might change using different background colors. ", "So the main takeaways from this work are that shape does significantly affect color difference perception and significantly affect size perception. ", "allowing us to adjust encodings for perceptual interference in one direction, without worrying about altering perceptions in the other. ", "is a little less understood than we previously thought, but separability can be modeled. And these models can be used to automatically adjust encodings, and improve visualization design, and thus increase interpretation accuracy. ", ""], "evaluationData": {"boundariesAccuracy": 77.36, "timeAccuracy": 9.64, "structureAccuracy": 61.54, "mappingAccuracy": 99.76}}