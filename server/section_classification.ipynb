{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d67a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd18f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_json_path = \"./paperData/1.json\"\n",
    "script_data_path = \"./slideMeta/slideData/0/scriptData.txt\"\n",
    "ocr_data_path = \"./slideMeta/slideData/0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02985c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paper_json_path, \"r\") as json_file :\n",
    "    paper_json_obj = json.load(json_file)\n",
    "    \n",
    "print(paper_json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49921dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from string import digits\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# kjnltk.download()\n",
    "\n",
    "def preprocess(t) :\n",
    "    t=re.sub(\"\\[.*?\\]\",\"\",t)\n",
    "    \n",
    "    sentences = nltk.tokenize.sent_tokenize(t)\n",
    "    \n",
    "    # sentences = [ ' '.join(re.sub(r'[^\\w]', ' ', s).split()) for s in sentences ]\n",
    "    \n",
    "    return sentences\n",
    "    \n",
    "def isAllowedSection(t) :\n",
    "    if t == \"REFERENCES\" :\n",
    "        return False\n",
    "    else :\n",
    "        return True\n",
    "\n",
    "every_sentences = []\n",
    "every_labels = []\n",
    "\n",
    "def fixSectionTitles(section_titles):\n",
    "    ret_titles = []\n",
    "    title_num = 0\n",
    "    last_section = None\n",
    "    def is_main_section(title):\n",
    "        if title[0] in digits or title.isupper() is True:\n",
    "            return True\n",
    "        return False\n",
    "    for title in section_titles:\n",
    "        if is_main_section(title) or last_section is None:\n",
    "            ret_titles.append(title)\n",
    "            last_section = title\n",
    "        else:\n",
    "            ret_titles.append(last_section)\n",
    "    return ret_titles\n",
    "\n",
    "for i in range(len(paper_json_obj['sections'])) :\n",
    "    if 'title' in paper_json_obj['sections'][i] and 'text' in paper_json_obj['sections'][i]['title'] :\n",
    "        sectionTitle = paper_json_obj['sections'][i]['title']['text']\n",
    "    \n",
    "        if not isAllowedSection(sectionTitle) :\n",
    "            continue\n",
    "            \n",
    "        for p in range(len(paper_json_obj['sections'][i]['paragraphs'])) :\n",
    "            bodyText = paper_json_obj['sections'][i]['paragraphs'][p]['text']\n",
    "            \n",
    "            bodyText = preprocess(bodyText.lower())\n",
    "            \n",
    "            every_labels.append(sectionTitle)\n",
    "            every_sentences.append(sectionTitle.lower() + '.')\n",
    "\n",
    "            every_labels = [*every_labels, *[sectionTitle for i in range(len(bodyText)) ] ]\n",
    "            every_sentences = [*every_sentences, *bodyText]\n",
    "            \n",
    "            \n",
    "every_labels = fixSectionTitles(every_labels)\n",
    "\n",
    "__every_labels = []\n",
    "__every_sentences = []\n",
    "\n",
    "for i in range(len(every_labels)) :\n",
    "    if every_labels[i].split(' ')[0].isdigit() :\n",
    "        __every_labels.append(every_labels[i])\n",
    "        __every_sentences.append(every_sentences[i])\n",
    "        \n",
    "every_labels = __every_labels\n",
    "every_sentences = __every_sentences\n",
    "\n",
    "for i, sentence in enumerate(every_sentences):\n",
    "    if every_labels[i].startswith('7'):\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(every_sentences)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1255b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_dict = sorted(list(set(every_labels)))\n",
    "label_categories = [ label_dict.index(s) for s in every_labels ]\n",
    "\n",
    "Y = np.array(*[label_categories])\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# define dataset\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X, Y)\n",
    "\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# model = LogisticRegression()\n",
    "\n",
    "# model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d57b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_predictions(t, k):\n",
    "    pre = ' '.join(preprocess(t))\n",
    "    X2 = vectorizer.transform([pre])\n",
    "    all_probs = model.predict_proba(X2)[0]\n",
    "    args = np.argsort(all_probs)[-k:][::-1]\n",
    "    ret = {}\n",
    "    \n",
    "    for arg in args:\n",
    "        ret[label_dict[arg]] = all_probs[arg]\n",
    "        \n",
    "    return ret\n",
    "\n",
    "def makePrediction(t) :\n",
    "    pre = ' '.join(preprocess(t))\n",
    "    \n",
    "    X2 = vectorizer.transform([pre])\n",
    "    \n",
    "    return [ label_dict[s] for s in model.predict(X2) ]\n",
    "\n",
    "def makePredictionProbability(t) :\n",
    "    pre = ' '.join(preprocess(t))\n",
    "    \n",
    "    X2 = vectorizer.transform([pre])\n",
    "    \n",
    "    return model.predict_proba(X2)[0]\n",
    "    \n",
    "p = \"how people use career mentoring relevant to their careers, and we will be focusing on the online communities as a source of mentoring. And the main research question we're asking is how people seek and receive advice.\"\n",
    "\n",
    "result = makePredictionProbability(p)\n",
    "\n",
    "print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e452249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "scriptDataFile = open(script_data_path, \"r\")\n",
    "cnt = 0\n",
    "\n",
    "scriptList = []\n",
    "\n",
    "while True:\n",
    "    line = scriptDataFile.readline()\n",
    "    \n",
    "    if not line: \n",
    "        break\n",
    "        \n",
    "    raw = line.strip()\n",
    "    scriptList.append(raw)\n",
    "    # print(raw)\n",
    "    # print('')\n",
    "\n",
    "ocrResult = []\n",
    "for i in range(len(scriptList)) :\n",
    "    ocrFile = open(os.path.join(ocr_data_path, \"ocr\", str(i) + \".jpg.txt\"), \"r\")\n",
    "    ocrResult.append('')\n",
    "    firstLine = True\n",
    "    while True :\n",
    "        line = ocrFile.readline()\n",
    "        if not line :\n",
    "            break\n",
    "        if firstLine:\n",
    "            firstLine = False\n",
    "            continue\n",
    "        res = line.split('\\t')[-1].strip()\n",
    "        if len(res) > 0:\n",
    "            ocrResult[-1] = ocrResult[-1] + ' ' + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bdb5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "__cnt = 0\n",
    "\n",
    "thresh = 3\n",
    "val_thresh = 0.1\n",
    "\n",
    "probTable = []\n",
    "topSections = []\n",
    "\n",
    "# print(scriptList)\n",
    "\n",
    "for i in range(len(scriptList)):\n",
    "    scriptList[i] = scriptList[i] + \" \" + ocrResult[i]\n",
    "\n",
    "for i in range(len(scriptList)) :\n",
    "    tokens = nltk.tokenize.word_tokenize(scriptList[i])\n",
    "    \n",
    "    ### BLURRING\n",
    "\n",
    "    # sent = ''\n",
    "    \n",
    "    # if len(tokens) < 25 :\n",
    "    #     sent = '.'.join(scriptList[max(-2+i, 0):i])\n",
    "    # else :\n",
    "    #     sent = scriptList[i]\n",
    "        \n",
    "    # preds = top_k_predictions(sent, len(label_dict))\n",
    "\n",
    "    # topSections.append(preds)\n",
    "    # probTable.append(makePredictionProbability(sent))\n",
    "\n",
    "\n",
    "    # ### THRESHOLDING, BLURRING with PREVIOUS\n",
    "    # preds = top_k_predictions(scriptList[i], len(label_dict))\n",
    "    # if len(tokens) < 25 and len(topSections) > 0:\n",
    "    #     topSections.append(topSections[-1])\n",
    "    # else:\n",
    "    #     vals = list(preds.values())\n",
    "    #     prob = vals[np.argsort(vals)[-thresh]]\n",
    "    #     prob = max(prob, val_thresh)\n",
    "    #     for k in preds.keys():\n",
    "    #         if preds[k] < prob:\n",
    "    #             preds[k] = 0\n",
    "    #     topSections.append(preds)\n",
    "    # probTable.append(makePredictionProbability(scriptList[i]))\n",
    "\n",
    "    # ### BLURRING with PREVIOUS\n",
    "    # preds = top_k_predictions(scriptList[i], len(label_dict))\n",
    "    # if len(tokens) < 25 and len(topSections) > 0:\n",
    "    #     topSections.append(topSections[-1])\n",
    "    # else:\n",
    "    #     # vals = list(preds.values())\n",
    "    #     # prob = vals[np.argsort(vals)[-thresh]]\n",
    "    #     # prob = max(prob, val_thresh)\n",
    "    #     # for k in preds.keys():\n",
    "    #     #     if preds[k] < prob:\n",
    "    #     #         preds[k] = 0\n",
    "    #     topSections.append(preds)\n",
    "    # probTable.append(makePredictionProbability(scriptList[i]))\n",
    "\n",
    "\n",
    "    ### NO BLURRING\n",
    "    preds = top_k_predictions(scriptList[i], len(label_dict))\n",
    "    # vals = list(preds.values())\n",
    "    # prob = vals[np.argsort(vals)[-thresh]]\n",
    "    # prob = max(prob, val_thresh)\n",
    "    # for k in preds.keys():\n",
    "    #     if preds[k] < prob:\n",
    "    #         preds[k] = 0\n",
    "    topSections.append(preds)\n",
    "    probTable.append(makePredictionProbability(scriptList[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ed962",
   "metadata": {},
   "outputs": [],
   "source": [
    "__topSections = []\n",
    "for topSection in topSections:\n",
    "    __topSection = []\n",
    "    for i, (k, v) in enumerate(topSection.items()):\n",
    "        __topSection.append([k, i, v])\n",
    "    __topSections.append(__topSection)\n",
    "\n",
    "topSections = __topSections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a3c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIPPED_SECTIONS = [\n",
    "    \"CCS CONCEPTS\",\n",
    "    \"KEYWORDS\",\n",
    "    \"ACM Reference Format:\",\n",
    "    \"REFERENCES\",\n",
    "    \"ACKNOWLEDGMENTS\"\n",
    "]\n",
    "\n",
    "def is_section_skipped(section):\n",
    "    for skipped_section in SKIPPED_SECTIONS:\n",
    "        if skipped_section in section:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def getOutlineHyungyu(sectionData, topSections, script_sentence_range):\n",
    "    uniqueSections = []\n",
    "    for section in sectionData:\n",
    "        if is_section_skipped(section) or section in uniqueSections:\n",
    "            continue\n",
    "        uniqueSections.append(section)\n",
    "\n",
    "    INF = (len(script_sentence_range) + 1) * 100\n",
    "    n = len(uniqueSections)\n",
    "\n",
    "    Table = [ [ (-INF, n, -1) for j in range(len(script_sentence_range))] for i in range(len(script_sentence_range)) ]\n",
    "\n",
    "    def getSegment(start, end):\n",
    "        if end - start < 2:\n",
    "            return (-INF, n)\n",
    "\n",
    "        scores = [0 for i in range(n)]\n",
    "        for i in range(start, end):\n",
    "            innerScores = [-INF for i in range(n)]\n",
    "            for topSection in topSections[i]:\n",
    "                pos = uniqueSections.index(topSection[0])\n",
    "                innerScores[pos] = max(innerScores[pos], topSection[2])\n",
    "            for j in range(n):\n",
    "                if innerScores[j] > 0:\n",
    "                    scores[j] += innerScores[j]\n",
    "        result_section = -1\n",
    "        for i in range(n):\n",
    "            if result_section == -1 or scores[result_section] < scores[i]:\n",
    "                result_section = i\n",
    "\n",
    "        return (scores[result_section], result_section)\n",
    "\n",
    "    Table[0][0] = (0, n, 0)\n",
    "\n",
    "    for i in range(1, len(script_sentence_range)):\n",
    "        segResult = getSegment(i, i + 1)\n",
    "\n",
    "        Table[i][i] = (max(Table[i-1][i-1][0] + segResult[0], Table[i][i][0]), segResult[1], i)\n",
    "\n",
    "        for j in range(i+1, len(script_sentence_range)) :\n",
    "            for k in range(i-1, j) :\n",
    "                cost = getSegment(k+1, j+1)\n",
    "                if Table[i][j][0] < Table[i-1][k][0] + cost[0]:\n",
    "                    Table[i][j] = (Table[i-1][k][0] + cost[0], cost[1], k + 1)\n",
    "\n",
    "    weight = []\n",
    "    for i in range(len(script_sentence_range)) :\n",
    "        weight.append(Table[i][len(script_sentence_range) - 1][0])\n",
    "\n",
    "    myMaxValue = -INF\n",
    "    optSegs = -1\n",
    "\n",
    "    for i in range(len(Table)) :\n",
    "        if myMaxValue < Table[i][len(script_sentence_range) - 1][0]:\n",
    "            myMaxValue = Table[i][len(script_sentence_range) - 1][0]\n",
    "            optSegs = i\n",
    "\n",
    "    finalResult = [ 0 for i in range(len(script_sentence_range)) ]\n",
    "\n",
    "    curSlide = len(script_sentence_range) - 1\n",
    "    print(myMaxValue, optSegs)\n",
    "\n",
    "    while optSegs > 0:\n",
    "        start = Table[optSegs][curSlide][2]\n",
    "        curSection = Table[optSegs][curSlide][1]\n",
    "\n",
    "        for i in range(start, curSlide + 1) :\n",
    "            finalResult[i] = curSection\n",
    "        \n",
    "        curSlide = start - 1\n",
    "        optSegs = optSegs - 1\n",
    "\n",
    "        if curSlide < 0 :\n",
    "            print(\"WHAT???? ERROR ERROR ERROR ERROR\")\n",
    "            break\n",
    "\n",
    "    outline = []\n",
    "\n",
    "    outline.append({\n",
    "        'section': \"NO_SECTION\",\n",
    "        'startSlideIndex': 0,\n",
    "        'endSlideIndex': 0\n",
    "    })\n",
    "\n",
    "    for i in range(1, len(finalResult)) :\n",
    "        if outline[-1]['section'] != uniqueSections[finalResult[i]]:\n",
    "            outline.append({\n",
    "                'section': uniqueSections[finalResult[i]],\n",
    "                'startSlideIndex': i,\n",
    "                'endSlideIndex': i\n",
    "            })\n",
    "        else :\n",
    "            outline[-1]['endSlideIndex'] = i\n",
    "    return outline, weight\n",
    "\n",
    "def getOutlineMaskDP(sectionData, topSections, script_sentence_range, target_mask = None):\n",
    "    uniqueSections = []\n",
    "    for section in sectionData:\n",
    "        if is_section_skipped(section) or section in uniqueSections:\n",
    "            continue\n",
    "        uniqueSections.append(section)\n",
    "\n",
    "    for i, section in enumerate(uniqueSections):\n",
    "        print(i, \":\", section)\n",
    "\n",
    "    n = len(uniqueSections)\n",
    "    m = len(script_sentence_range)\n",
    "    INF = (m + 1) * 100\n",
    "\n",
    "    dp = [[(-INF, n, -1) for j in range(m)] for i in range(1 << n)]\n",
    "    dp[0][0] = (0, n)\n",
    "\n",
    "    for i in range(m):\n",
    "        scores = [0 for k in range(n)]\n",
    "        for j in range(i + 1, m):\n",
    "            for topSection in topSections[j]:\n",
    "                pos = uniqueSections.index(topSection[0])\n",
    "                scores[pos] += topSection[2]\n",
    "\n",
    "            for mask in range(0, (1 << n)):\n",
    "                if dp[mask][i][0] < 0:\n",
    "                    continue\n",
    "                for k in range (n):\n",
    "                    if mask & (1 << k) > 0:\n",
    "                        continue\n",
    "                    nmask = mask | (1 << k)\n",
    "                    if (dp[nmask][j][0] < dp[mask][i][0] + scores[k]):\n",
    "                        dp[nmask][j] = (dp[mask][i][0] + scores[k], k, i)\n",
    "\n",
    "    recoverMask = target_mask\n",
    "    recoverSlideId = m - 1\n",
    "\n",
    "\n",
    "    if recoverMask is None or dp[recoverMask][recoverSlideId][0] < 0:\n",
    "        recoverMask = 0\n",
    "        for mask in range(1 << n):\n",
    "            #print(mask, dp[mask][recoverSlideId])\n",
    "            if dp[mask][recoverSlideId][0] > dp[recoverMask][recoverSlideId][0] \\\n",
    "                or (bin(mask).count('1') < bin(recoverMask).count('1') and dp[mask][recoverSlideId][0] == dp[recoverMask][recoverSlideId][0]\n",
    "            ):\n",
    "                recoverMask = mask\n",
    "\n",
    "    if target_mask is not None:\n",
    "        print (bin(target_mask), bin(recoverMask), dp[target_mask][recoverSlideId][0])\n",
    "    \n",
    "    outline = []\n",
    "    while recoverSlideId > 0:\n",
    "        print(recoverMask, recoverSlideId, dp[recoverMask][recoverSlideId])\n",
    "        sectionId = dp[recoverMask][recoverSlideId][1]\n",
    "        nextRecoverMask = recoverMask ^ (1 << sectionId)\n",
    "        nextRecoverSlideId = dp[recoverMask][recoverSlideId][2]\n",
    "        outline.append({\n",
    "            \"section\": uniqueSections[sectionId],\n",
    "            \"startSlideIndex\": nextRecoverSlideId + 1,\n",
    "            \"endSlideIndex\": recoverSlideId,\n",
    "        })\n",
    "        recoverMask = nextRecoverMask\n",
    "        recoverSlideId = nextRecoverSlideId\n",
    "    \n",
    "    return outline[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a11905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_mask = int('0b00011111', 2)\n",
    "target_mask = None\n",
    "\n",
    "outline = (getOutlineMaskDP(label_dict, topSections, scriptList, target_mask))\n",
    "\n",
    "for single in outline:\n",
    "    print(single)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b959efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outline, weights = (getOutlineHyungyu(label_dict, topSections, scriptList))\n",
    "\n",
    "for bullet in outline:\n",
    "    print(bullet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8862f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(probTable[47:51:1])\n",
    "\n",
    "print(47, 48, 49, 50, 51)\n",
    "for i in range(47, 51):\n",
    "    print(probTable[i])\n",
    "\n",
    "plt.title('Annoteat cell with numeric value', fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for e in enumerate(label_dict) :\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f945b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixSectionTitles(section_titles):\n",
    "    ret_titles = []\n",
    "    title_num = 0\n",
    "    last_section = None\n",
    "    def is_main_section(title):\n",
    "        if title[0] in digits or title.isupper() is True:\n",
    "            return True\n",
    "        return False\n",
    "    for title in section_titles:\n",
    "        if is_main_section(title) or last_section is None:\n",
    "            ret_titles.append(title)\n",
    "            last_section = title\n",
    "        else:\n",
    "            ret_titles.append(last_section)\n",
    "    print(ret_titles)\n",
    "    return ret_titles\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
